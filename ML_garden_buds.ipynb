{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML garden buds.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GNN - Graph Neural Netowrks"
      ],
      "metadata": {
        "id": "V1ojSqeBAhE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220219.10-[Graph Neural Networks in Python](https://medium.com/towards-data-science/graph-neural-networks-in-python-c310c7c18c83) (rating, LvL, WIP) = (0.7, 0.6, 0.1)\n",
        "  - An introduction and step-by-step implementation.  [gnn_python.ipynb](https://colab.research.google.com/drive/17eRoYIBxlgxAMKHV4qmXmBYL2-Wkl3Xx?usp=sharing#scrollTo=8F1Lp6aDKZkT)"
      ],
      "metadata": {
        "id": "vyho8C3QApDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--- [Michael Bronstein GNN series](https://towardsdatascience.com/graph-deep-learning/home)\n",
        "\n",
        "220125.44-[What does 2022 hold for Geometric & Graph ML?](https://medium.com/towards-data-science/predictions-and-hopes-for-geometric-graph-ml-in-2022-aa3b8b79f5cc) (Rating, LvL, WIP) = (0.95, 0.95, 0)\n",
        "\n",
        "220204.06-[Feature Propagation is a surprisingly efficient for learning graphs with missing node features](https://medium.com/towards-data-science/learning-on-graphs-with-missing-features-dd34be61b06) (Rating, LvL, WIP) = (0.7, 0.8, 0)\n",
        "\n",
        "211221.14-[Using Subgraphs for More Expressive GNNs](https://medium.com/towards-data-science/using-subgraphs-for-more-expressive-gnns-8d06418d5ab)  (Rating, LvL, WIP) = (0.8, 0.9, 0)\n",
        "\n",
        "211118.11-[Graph Neural Networks through the lens of Differential Geometry and Algebraic Topology](https://medium.com/towards-data-science/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f)  (Rating, LvL, WIP) = (0.8, 0.9, 0)\n",
        "\n",
        "210619.14-[Graph Neural Networks as Neural Diffusion PDEs](https://medium.com/towards-data-science/graph-neural-networks-as-neural-diffusion-pdes-8571b8c0c774) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "210428.13-[Geometric foundations of Deep Learning](https://medium.com/towards-data-science/geometric-foundations-of-deep-learning-94cdd45b451d) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "210106.17-[What does 2021 hold for Graph ML?](https://medium.com/towards-data-science/predictions-and-hopes-for-graph-ml-in-2021-6af2121c3e3d)  (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "201230.08-[Geometric ML becomes real in fundamental sciences](https://medium.com/towards-data-science/geometric-ml-becomes-real-in-fundamental-sciences-3b0d109883b5) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200915.14-[AI-designed “hyperfoods” can possibly help prevent cancer](https://towardsdatascience.com/hyperfoods-9582e5d9a8e4) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200910.12-[Latent graph neural networks: Manifold learning 2.0?](https://towardsdatascience.com/manifold-learning-2-99a25eeb677d) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200808.12-[Simple scalable graph neural networks](https://medium.com/towards-data-science/simple-scalable-graph-neural-networks-7eb04f366d07)  (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200627.09-[Temporal Graph Networks](https://medium.com/towards-data-science/temporal-graph-networks-ab8f327f2efe)  (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200720.09-[Do we need deep graph neural networks?](https://towardsdatascience.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200615.07-[Deep learning on graphs: successes, challenges, and next steps](https://medium.com/towards-data-science/deep-learning-on-graphs-successes-challenges-and-next-steps-7d9ec220ba8) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200726.09-[Deriving convolution from first principles](https://towardsdatascience.com/deriving-convolution-from-first-principles-4ff124888028) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "\n",
        "--- "
      ],
      "metadata": {
        "id": "pdp_t4XJH5lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220218.9-[Graph Embeddings: How nodes get mapped to vectors](https://medium.com/towards-data-science/graph-embeddings-how-nodes-get-mapped-to-vectors-2e12549457ed) (rating, LvL, WIP) = (0.4, 0.3, 0.5)"
      ],
      "metadata": {
        "id": "phUR9yc9D8nl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210526.6-[Graph Representation Learning — The Encoder-Decoder Model (Part 2)](https://medium.com/towards-data-science/graph-representation-learning-the-encoder-decoder-model-part-2-ed8b505af447) (rating, LvL, WIP) = (0.6, 0.7, 0)"
      ],
      "metadata": {
        "id": "3dTxpMIWDqo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210607.8-[Node2vec explained graphically](https://medium.com/towards-data-science/node2vec-explained-graphically-749e49b7eb6b) (rating, LvL, WIP) = (0.7, 0.7, 0)"
      ],
      "metadata": {
        "id": "VXCo1cwREzu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210816.13-[Complete guide to understanding Node2Vec algorithm](https://medium.com/towards-data-science/complete-guide-to-understanding-node2vec-algorithm-4e9a35e5d147) (rating, LvL, WIP) = (0.8, 0.8, 0)"
      ],
      "metadata": {
        "id": "4pp33ff1NwG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "211231.16-[Implement Your Own Music Recommender with Graph Neural Networks (LightGCN)](https://medium.com/@benalex/implement-your-own-music-recommender-with-graph-neural-networks-lightgcn-f59e3bf5f8f5) (rating, LvL, WIP) = (0.8, 0.8, 0)"
      ],
      "metadata": {
        "id": "cUC6bQGZM6sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220111.13-[Scalable graph representation learning with Graph Neural Networks](https://medium.com/@pantelis.elinas/scalable-graph-representation-learning-with-graph-neural-networks-a2ab67e06f9) (rating, LvL, WIP) = (0.8, 0.8, 0)"
      ],
      "metadata": {
        "id": "RmfV2EfzLOJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210621.8-[Network Learning — from Network Propagation to Graph Convolution](https://medium.com/towards-data-science/network-learning-from-network-propagation-to-graph-convolution-eb3c62d09de8) (rating, LvL, WIP) = (0.7, 0.7, 0)"
      ],
      "metadata": {
        "id": "LdIuR3NrImp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220111.7-[Knowledge Graph Embedding — A Simplified Version](https://medium.com/towards-data-science/knowledge-graph-embedding-a-simplified-version-e6b0a03d373d) (rating, LvL, WIP) = (0.4, 0.5, 0)"
      ],
      "metadata": {
        "id": "gfZsJkhyKz4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "181231.9-[Graph Embeddings — The Summary](https://medium.com/towards-data-science/graph-embeddings-the-summary-cc6075aba007) (rating, LvL, WIP) = (0.8, 0.6, 0)"
      ],
      "metadata": {
        "id": "xYcj5GhtMNmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O5daZ1dEBeDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers"
      ],
      "metadata": {
        "id": "dJR05u8iBNFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "211014.13-[An out-and-out view of Transformer Architecture](https://medium.com/mlearning-ai/an-out-and-out-view-of-transformer-architecture-6926da4c8080) (Rating, LvL, WIP) = (0.8, 0.8, 0)"
      ],
      "metadata": {
        "id": "ZlZyInHX-iWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jay Alammar series"
      ],
      "metadata": {
        "id": "JDUSpM6P-Q7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) [-Chinese-](https://blog.csdn.net/yujianmin1990/article/details/85221271)(Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "[Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) [-Chinese-](https://blog.csdn.net/qq_41664845/article/details/84245520) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n"
      ],
      "metadata": {
        "id": "hK8oMvNW9Ykk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Building Blocks"
      ],
      "metadata": {
        "id": "l2CoMtw6BX82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "210818.10-[Understanding the building blocks of transformers](https://medium.com/analytics-vidhya/understanding-the-building-blocks-of-transformers-c28484788d5a) (rating, LvL, WIP) = (0.8, 0.7, 0)\n",
        "\n",
        "201004.09-[What Exactly Is Happening Inside the Transformer](https://medium.com/swlh/what-exactly-is-happening-inside-the-transformer-b7f713d7aded) (Rating, LvL, WIP) = (0.9, 0.8, 0)\n",
        "\n",
        "200825.13-[Transformer Neural Network: Step-By-Step Breakdown of the Beast](https://medium.com/towards-data-science/transformer-neural-network-step-by-step-breakdown-of-the-beast-b3e096dc857f) (rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6PPZBFG9OW_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Explained (by Ketan Doshi)"
      ],
      "metadata": {
        "id": "FAmC_Un-AOoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. 201213.10-[Transformers Explained Visually (Part 1): Overview of Functionality](https://medium.com/towards-data-science/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) (rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "2. 210102.11-[Transformers Explained Visually (Part 2): How it works, step-by-step](https://medium.com/towards-data-science/transformers-explained-visually-part-2-how-it-works-step-by-step-b49fa4a64f34) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "3. 210117.11-[Transformers Explained Visually (Part 3): Multi-head Attention, deep dive](https://medium.com/towards-data-science/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "4. 210603.10-[Transformers Explained Visually — Not Just How, but Why They Work So Well](https://medium.com/towards-data-science/transformers-explained-visually-not-just-how-but-why-they-work-so-well-d840bd61a9d3) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I7BRoOEICATH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vision Transformer"
      ],
      "metadata": {
        "id": "P3De7OvpCTul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 220209.12-[Understand and Implement Vision Transformer with TensorFlow 2.0](https://medium.com/towards-data-science/understand-and-implement-vision-transformer-with-tensorflow-2-0-f5435769093) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "- 220204.11-[Vision Transformers from Scratch (PyTorch): A step-by-step guide](https://medium.com/mlearning-ai/vision-transformers-from-scratch-pytorch-a-step-by-step-guide-96c3313c2e0c) (Rating, LvL, WIP) = (0.8, 0.75, 0)"
      ],
      "metadata": {
        "id": "xXebB8co4apj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "QIKnavrRCWrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210723.10-[Node embeddings for Beginners](https://medium.com/towards-data-science/node-embeddings-for-beginners-554ab1625d98) (Rating, LvL, WIP) = (0.5, 0.5, 0)"
      ],
      "metadata": {
        "id": "ABBrdwhF49dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naoki & m0nads explains Transformers"
      ],
      "metadata": {
        "id": "I2KxDM8tCwA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 211114.10-[Self-Attention](https://medium.com/@naokishibuya/transformers-self-attention-1dc3a2719e0a)  (Rating, LvL, WIP) = (0.6, 0.6, 0)\n",
        "- 211030.11-[Positional Encoding](https://medium.com/@naokishibuya/positional-encoding-286800cce437)(Rating, LvL, WIP) = (0.6, 0.6, 0)\n",
        "- 211030.11-[Encoder-Decoder](https://medium.com/@naokishibuya/transformers-encoder-decoder-434603d19e1)(Rating, LvL, WIP) = (0.6, 0.6, 0)\n",
        "-220127.05-[Multi-Head Attention](https://medium.com/@monadsblog/multi-head-attention-f2cfb4060e9c)(Rating, LvL, WIP) = (0.6, 0.6, 0)\n"
      ],
      "metadata": {
        "id": "eojOnDEXC3o9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NAS - Network Architecture Search"
      ],
      "metadata": {
        "id": "E2OJR4veLvKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210618.12-[A 2021 Guide to improving CNNs-Network architectures: Network Architecture Search](https://medium.com/geekculture/a-2021-guide-to-improving-cnns-network-architectures-network-architecture-search-815f01289aba) (rating, LvL, WIP) = (0.8, 0.6, 0)"
      ],
      "metadata": {
        "id": "849VwcY7LzKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning"
      ],
      "metadata": {
        "id": "c09PqNidE7uX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. 201017.19-[Reinforcement Learning Made Simple (Part 1): Intro to Basic Concepts and Terminology](https://medium.com/towards-data-science/reinforcement-learning-made-simple-part-1-intro-to-basic-concepts-and-terminology-1d2a87aa060) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "2. 201024.8-[Reinforcement Learning Made Simple (Part 2): Solution Approaches](https://medium.com/towards-data-science/reinforcement-learning-made-simple-part-2-solution-approaches-7e37cbf2334e) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "3. 201031.13-[Reinforcement Learning Explained Visually (Part 3): Model-free solutions, step-by-step](https://medium.com/towards-data-science/reinforcement-learning-explained-visually-part-3-model-free-solutions-step-by-step-c4bbb2b72dcf) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "4. 201128.13-[Reinforcement Learning Explained Visually (Part 4): Q Learning, step-by-step](https://medium.com/towards-data-science/reinforcement-learning-explained-visually-part-4-q-learning-step-by-step-b65efb731d3e) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "5. 201220.12-[Reinforcement Learning Explained Visually (Part 5): Deep Q Networks, step-by-step](https://medium.com/towards-data-science/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n",
        "6. 210110.10-[Reinforcement Learning Explained Visually (Part 6): Policy Gradients, step-by-step](https://medium.com/towards-data-science/reinforcement-learning-explained-visually-part-6-policy-gradients-step-by-step-f9f448e73754) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ueqEDNhZE_2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Math, Stats, Prob, Stochastic"
      ],
      "metadata": {
        "id": "NSunf7OuBRqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220103.7-[Decomposing Eigendecomposition.](https://medium.com/towards-data-science/decomposing-eigendecomposition-f68f48470830) (Rating, LvL, WIP) = (0.5, 0.5, 0)"
      ],
      "metadata": {
        "id": "SCLJQQnSz1eU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science Fundations"
      ],
      "metadata": {
        "id": "wQmkLcHa0Ul0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA - Principal Component Analysis"
      ],
      "metadata": {
        "id": "znfbg0kX1rhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "170418.16-[A One-Stop Shop for Principal Component Analysis.](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c) (Rating, LvL, WIP) = (0.8, 0.7, 0)\n",
        "\n",
        "190706.10-[Understanding PCA (Principal Components Analysis).](https://medium.com/towards-data-science/understanding-pca-fae3e243731d) (Rating, LvL, WIP) = (0.8, 0.7, 0)\n",
        "\n",
        "191029.10-[Visualising high-dimensional datasets using PCA and t-SNE in Python](https://medium.com/towards-data-science/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b) (Rating, LvL, WIP) = (0.8, 0.7, 0)\n",
        "\n",
        "211227.05-[Implementing PCA From Scratch.](https://towardsdatascience.com/implementing-pca-from-scratch-fb434f1acbaa) (Rating, LvL, WIP) = (0.5, 0.5, 0)\n",
        "\n",
        "190307.16-[Machine Learning — Singular Value Decomposition (SVD) & Principal Component Analysis (PCA).](https://medium.com/@jonathan-hui/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491) (Rating, LvL, WIP) = (0.8, 0.7, 0)\n",
        "\n",
        "171205.08-[PCA using Python (scikit-learn).](https://medium.com/towards-data-science/pca-using-python-scikit-learn-e653f8989e60) (Rating, LvL, WIP) = (0.8, 0.6, 0)\n",
        "\n",
        "180420.07-[機器/統計學習:主成分分析(Principal Component Analysis, PCA)](https://medium.com/@chih-sheng-huang821/%E6%A9%9F%E5%99%A8-%E7%B5%B1%E8%A8%88%E5%AD%B8%E7%BF%92-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-principle-component-analysis-pca-58229cd26e71) (Rating, LvL, WIP) = (0.7, 0.6, 0)"
      ],
      "metadata": {
        "id": "ca5Pc6Iu09UU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applications"
      ],
      "metadata": {
        "id": "lztT9z_rzOE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio"
      ],
      "metadata": {
        "id": "INa6tNMDzRN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "210905.09-[Audio Classification using Wavelet Transform and Deep Learning.](https://medium.com/mlearning-ai/audio-classification-using-wavelet-transform-and-deep-learning-f9f0978fa246) (Rating, LvL, WIP) = (0.8, 0.6, 0) "
      ],
      "metadata": {
        "id": "1CZ5YmySzTgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video"
      ],
      "metadata": {
        "id": "Vw_1bxIi4sTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision Transformer"
      ],
      "metadata": {
        "id": "tv62Hl8Y9c9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "220209.12-[Understand and Implement Vision Transformer with TensorFlow 2.0](https://medium.com/towards-data-science/understand-and-implement-vision-transformer-with-tensorflow-2-0-f5435769093) (Rating, LvL, WIP) = (0.8, 0.8, 0)\n",
        "\n"
      ],
      "metadata": {
        "id": "ETvxK1wC4ylJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pose Estimation"
      ],
      "metadata": {
        "id": "KwzasLoULFA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "190429.09-[An Overview of Human Pose Estimation with Deep Learning](https://medium.com/beyondminds/an-overview-of-human-pose-estimation-with-deep-learning-d49eb656739b) (Rating, LvL, WIP) = (0.8, 0.9, 0)\n",
        "\n",
        "171003.06-[Human pose estimation using OpenPose with TensorFlow (Part 1)](https://medium.com/ar-vr-journey/human-pose-estimation-using-openpose-with-tensorflow-part-1-7dd4ca5c8027) (Rating, LvL, WIP) = (0.5, 0.5, 0)\n",
        "\n",
        "171121.09-[Human pose estimation using OpenPose with TensorFlow (Part 2)](https://medium.com/ar-vr-journey/human-pose-estimation-using-openpose-with-tensorflow-part-2-e78ab9104fc8) (Rating, LvL, WIP) = (0.5, 0.5, 0)\n",
        "\n",
        "190326.10-[Human Pose Estimation : Simplified](https://medium.com/towards-data-science/human-pose-estimation-simplified-6cfd88542ab3) (Rating, LvL, WIP) = (0.8, 0.9, 0)\n",
        "\n",
        "200725.06-[Real-Time Head Pose Estimation in Python](https://medium.com/towards-data-science/real-time-head-pose-estimation-in-python-e52db1bc606a) (Rating, LvL, WIP) = (0.6, 0.7, 0)\n",
        "\n",
        "190805.16-[A 2019 Guide to Human Pose Estimation](https://medium.com/fritzheartbeat/a-2019-guide-to-human-pose-estimation-c10b79b64b73) (Rating, LvL, WIP) = (0.6, 0.7, 0)\n",
        "\n",
        "* Github - [CMU-Perceptual-Computing-Lab](https://github.com/CMU-Perceptual-Computing-Lab/openpose) \n",
        "* Github - [Open Pose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)"
      ],
      "metadata": {
        "id": "hvnMQJQ2LJdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Super-Resolution"
      ],
      "metadata": {
        "id": "8eawLaYnOY1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "190702.11-[An Introduction to Super Resolution using Deep Learning](https://medium.com/beyondminds/an-introduction-to-super-resolution-using-deep-learning-f60aff9a499d) (Rating, LvL, WIP) = (0.7, 0.7, 0)\n",
        "\n",
        "190224.26-[Deep learning based super resolution, without using a GAN](https://medium.com/towards-data-science/deep-learning-based-super-resolution-without-using-a-gan-11c9bb5b6cd5) (Rating, LvL, WIP) = (0.8, 0.9, 0)\n",
        "\n",
        "181108.09-[Single Image Super Resolution Using GANs — Keras](https://medium.com/@birla.deepak26/single-image-super-resolution-using-gans-keras-aca310f33112) (Rating, LvL, WIP) = (0.8, 0.8, 0) [Github: Keras-SRGAN]( https://github.com/deepak112/Keras-SRGAN)"
      ],
      "metadata": {
        "id": "JQ2eIya4OcGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmentation"
      ],
      "metadata": {
        "id": "DnWl23au9h0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[YOLACT++ Instance Segmentation (Google Colab Tutorial)](https://www.youtube.com/watch?v=x9PZ1xjIkng)  [  Colab - TOLACT++](https://colab.research.google.com/drive/1ncRxvmNR-iTtQCscj2UFSGV8ZQX_LN0M)"
      ],
      "metadata": {
        "id": "raLaoWwZ9kqi"
      }
    }
  ]
}