{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/lin3372/252_ML.tutorial/blob/main/RL/03_Hands_on_RL_Tabular_SARSA_220801.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"shDuXa02vOv7"},"source":["[Hands-On Reinforcement Learning Course: Part 5 - Deep Q learning](https://medium.com/towards-data-science/hands-on-reinforcement-learning-course-part-5-bdb2e7fa243c)\n","\n","by [Pau Labarta Bajo](https://pau-labarta-bajo.medium.com/?source=post_page-----269b50e39d08--------------------------------), Feb 10, 2022.  [[github repo for this lesson]](https://github.com/Paulescu/hands-on-rl)\n","\n","Summarized and Revised by Ivan H.P. Lin"]},{"cell_type":"markdown","metadata":{"id":"oSr57Pouv33d"},"source":["Previous RL courses:\n","1. Part 1: Introduction to Reinforcement Learning - [datSci](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08), [Ivan's colab](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08)\n","2. Part 2: Tabular Q-learning - [datSci](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08), [Ivan's colab](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08)\n","3. Part 3: Tabular SARSA - [datSci](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08), [Ivan's colab](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-1-269b50e39d08)\n","4. Part 4: Linear Q-learning [datSci](https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-4-55da5eae851f) [Ivan's colab](https://drive.google.com/file/d/1Q1CWVOjmH46Gf_Xb_u4Ht13U55LsQina/view?usp=sharing)\n","\n","5. üëâüèª Part 5: Deep Q-learning (today) [datSci](https://medium.com/towards-data-science/hands-on-reinforcement-learning-course-part-5-bdb2e7fa243c) [Ivan's colab](https://medium.com/towards-data-science/hands-on-reinforcement-learning-course-part-5-bdb2e7fa243c)\n","\n","In part 4 we built an okay-ish agent for the Cart Pole environment. We used **parametric $Q$ learning** with a linear model.\n","\n","Today we will replace this linear model with a neural network.\n","\n","And we will kick-ass-solve the Cart Pole environment üòé\n","\n","Today‚Äôs lesson is a bit longer, as it includes a mini crash course on training neural network models. Unless you are an expert in deep learning, I highly recommend you do not skip it.\n","\n","All the code for this lesson is in [this Github repo](https://github.com/Paulescu/hands-on-rl). Git clone it to follow along with today‚Äôs problem.\n","\n","And if you like the course, please give it a ‚≠ê in Github!\n","\n","<img src=\"https://i.makeagif.com/media/9-30-2015/3TntUH.gif\" width=\"60%\">"]},{"cell_type":"markdown","metadata":{"id":"Hjvm2GlHwLk6"},"source":["# 0. Contents\n","\n","1. Let‚Äôs go deep!\n","2. Hands-on Introduction to Deep Learning\n","3. Deep Q learning to solve the Cart Pole\n","4. Recap ‚ú®\n","5. Homework üìö\n","6. What‚Äôs next? ‚ù§Ô∏è"]},{"cell_type":"markdown","metadata":{"id":"1_7Bw6Y9x4sB"},"source":["#1.. Let‚Äôs go deep! üïπÔ∏è\n","\n","In the previous lesson, we used this linear parameterization to represent the optimal $q$ function.\n","\n","<figure><center>\n","<img src=\"https://miro.medium.com/max/711/0*ziABdoI655gxHn3H.jpeg\" width=\"60%\">\n","<figcaption>linear q function (Image by the author)</figcaption>\n","</center></figure>\n","\n","The success (or failure) of a **parametric $Q$-learning** agent strongly depends on the parameterization we use to approximate the optimal $q$ value function.\n","\n","Linear models are conceptually simple, fast to train, and fast to run. However, they are not very flexible. Given a set of inputs and outputs, linear layers struggle to map inputs to outputs.\n","\n","And this is when neural networks enter into the game.\n","\n","Neural network models are the most powerful function approximations we have. They are extremely flexible and can be used to uncover complex patterns between the input features and the target labels.\n","\n","\n","  > **The Universal Approximation Theorem** üìò is a mathematical result that essentially says\n","\n","  > Neural networks are as flexible as you want them to be. If you design a sufficiently large neural network (i.e. with enough parameters), you will find an accuracte mapping between the input features and the target values.\n","\n","<img src=\"https://miro.medium.com/max/1465/1*Z_0zd9ld4CaSptmAlrYcdw.png\" width=\"50%\">"]},{"cell_type":"markdown","source":["Today we are going to replace the linear model from part 4 with the most simple neural network architecture out there: a **feed-forward neural network**.\n","\n","<figure><center>\n","<img src=\"https://miro.medium.com/max/1539/1*Ibtr60PwTe51yyJqUqh8Eg.jpeg\" width=\"50%\">\n","<figcaption>Feed-forward neural network (Image by the author)</figcaption>\n","</center></figure>\n","\n","Later in the course, we will use other neural networks to deal with more complex states spaces (e.g. **convolutional neural networks**).\n","\n","Let us warm up our deep learning mastery with the following imitation learning problem I created for today.\n","\n","There is quite a lot to cover, so arm yourself with deep focus.\n","\n","\n"],"metadata":{"id":"ixT1lbe2IkU7"}},{"cell_type":"markdown","metadata":{"id":"Jooa8hBACVxY"},"source":["### display setup for colab\n","reference stackoverflow - [How to render OpenAI gym in google Colab? ](https://stackoverflow.com/questions/50107530/how-to-render-openai-gym-in-google-colab)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"FrE91jSr9xri","executionInfo":{"status":"ok","timestamp":1660211774891,"user_tz":-480,"elapsed":27079,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"outputs":[],"source":["!apt-get install x11-utils > /dev/null 2>&1 \n","!pip install pyglet > /dev/null 2>&1 \n","!apt-get install -y xvfb python-opengl > /dev/null 2>&1"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tcLgsqn_BaQY","executionInfo":{"status":"ok","timestamp":1660211779985,"user_tz":-480,"elapsed":5101,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"outputs":[],"source":["!pip install gym pyvirtualdisplay > /dev/null 2>&1"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"99aS6NAYBgXZ","executionInfo":{"status":"ok","timestamp":1660211780665,"user_tz":-480,"elapsed":683,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"outputs":[],"source":["# then import all your libraries, including *matplotlib* & *ipythondisplay*:\n","\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display as ipythondisplay"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzqB92XfBwEi","outputId":"b9f756db-f3e9-4614-9e76-2431a4917690","executionInfo":{"status":"ok","timestamp":1660211781266,"user_tz":-480,"elapsed":603,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f756cd45150>"]},"metadata":{},"execution_count":4}],"source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(400, 300))\n","display.start()"]},{"cell_type":"markdown","metadata":{"id":"pAm6NrxwL8MS"},"source":["### download util files from github"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WznjjptIMBdC","outputId":"cb5eebd1-3512-4da6-c4c8-6611acb94759","executionInfo":{"status":"ok","timestamp":1660211784161,"user_tz":-480,"elapsed":2897,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-08-11 09:56:20--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//agent_memory.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/agent_memory.py [following]\n","--2022-08-11 09:56:20--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/agent_memory.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 581 [text/plain]\n","Failed to rename agent_memory.py to agent_memory.py.1: (2) No such file or directory\n","Saving to: ‚Äòagent_memory.py‚Äô\n","\n","agent_memory.py     100%[===================>]     581  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:21 (39.2 MB/s) - ‚Äòagent_memory.py‚Äô saved [581/581]\n","\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//config.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/config.py [following]\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/config.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 595 [text/plain]\n","Failed to rename config.py to config.py.1: (2) No such file or directory\n","Saving to: ‚Äòconfig.py‚Äô\n","\n","config.py           100%[===================>]     595  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:21 (7.59 MB/s) - ‚Äòconfig.py‚Äô saved [595/595]\n","\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//loops.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/loops.py [following]\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/loops.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3675 (3.6K) [text/plain]\n","Failed to rename loops.py to loops.py.1: (2) No such file or directory\n","Saving to: ‚Äòloops.py‚Äô\n","\n","loops.py            100%[===================>]   3.59K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:21 (31.1 MB/s) - ‚Äòloops.py‚Äô saved [3675/3675]\n","\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//model_factory.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/model_factory.py [following]\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/model_factory.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1226 (1.2K) [text/plain]\n","Failed to rename model_factory.py to model_factory.py.1: (2) No such file or directory\n","Saving to: ‚Äòmodel_factory.py‚Äô\n","\n","model_factory.py    100%[===================>]   1.20K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:21 (51.6 MB/s) - ‚Äòmodel_factory.py‚Äô saved [1226/1226]\n","\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//optimize_hyperparameters.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/optimize_hyperparameters.py [following]\n","--2022-08-11 09:56:21--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/optimize_hyperparameters.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6727 (6.6K) [text/plain]\n","Failed to rename optimize_hyperparameters.py to optimize_hyperparameters.py.1: (2) No such file or directory\n","Saving to: ‚Äòoptimize_hyperparameters.py‚Äô\n","\n","optimize_hyperparam 100%[===================>]   6.57K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:22 (27.5 MB/s) - ‚Äòoptimize_hyperparameters.py‚Äô saved [6727/6727]\n","\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//q_agent.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/q_agent.py [following]\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/q_agent.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17291 (17K) [text/plain]\n","Failed to rename q_agent.py to q_agent.py.1: (2) No such file or directory\n","Saving to: ‚Äòq_agent.py‚Äô\n","\n","q_agent.py          100%[===================>]  16.89K  --.-KB/s    in 0.001s  \n","\n","2022-08-11 09:56:22 (27.6 MB/s) - ‚Äòq_agent.py‚Äô saved [17291/17291]\n","\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//random_agent.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/random_agent.py [following]\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/random_agent.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 479 [text/plain]\n","Failed to rename random_agent.py to random_agent.py.1: (2) No such file or directory\n","Saving to: ‚Äòrandom_agent.py‚Äô\n","\n","random_agent.py     100%[===================>]     479  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:22 (22.3 MB/s) - ‚Äòrandom_agent.py‚Äô saved [479/479]\n","\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//supervised_ml.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/supervised_ml.py [following]\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/supervised_ml.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8638 (8.4K) [text/plain]\n","Failed to rename supervised_ml.py to supervised_ml.py.1: (2) No such file or directory\n","Saving to: ‚Äòsupervised_ml.py‚Äô\n","\n","supervised_ml.py    100%[===================>]   8.44K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:22 (44.9 MB/s) - ‚Äòsupervised_ml.py‚Äô saved [8638/8638]\n","\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/utils.py [following]\n","--2022-08-11 09:56:22--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/utils.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3858 (3.8K) [text/plain]\n","Failed to rename utils.py to utils.py.1: (2) No such file or directory\n","Saving to: ‚Äòutils.py‚Äô\n","\n","utils.py            100%[===================>]   3.77K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:23 (26.3 MB/s) - ‚Äòutils.py‚Äô saved [3858/3858]\n","\n","--2022-08-11 09:56:23--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src//viz.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /Paulescu/hands-on-rl/main/03_cart_pole/src/viz.py [following]\n","--2022-08-11 09:56:23--  https://raw.githubusercontent.com/Paulescu/hands-on-rl/main/03_cart_pole/src/viz.py\n","Reusing existing connection to raw.githubusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1680 (1.6K) [text/plain]\n","Failed to rename viz.py to viz.py.1: (2) No such file or directory\n","Saving to: ‚Äòviz.py‚Äô\n","\n","viz.py              100%[===================>]   1.64K  --.-KB/s    in 0s      \n","\n","2022-08-11 09:56:23 (20.8 MB/s) - ‚Äòviz.py‚Äô saved [1680/1680]\n","\n"]}],"source":["import os\n","user = \"Paulescu\"\n","repo = \"hands-on-rl\"\n","src_dir = \"03_cart_pole/src/\"\n","pyfiles = [\"agent_memory.py\", \"config.py\", \"loops.py\", \"model_factory.py\", \"optimize_hyperparameters.py\",\\\n","           \"q_agent.py\", \"random_agent.py\", \"supervised_ml.py\", \"utils.py\", \"viz.py\"]\n","### Note - For \"viz.py\" there is an error in get_action(), so I fixed it and put in my respoitory =, needs to download tehe viz.py from my github repository\n","\n","curr_dir=os.getcwd()\n","os.makedirs('src', exist_ok=True)\n","\n","os.chdir('src')\n","\n","for f_rl in pyfiles:\n","  url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{src_dir}/{f_rl}\"\n","  !wget --no-cache --backups=1 {url}\n","\n","##########################   \n","#user = \"lin3372\"\n","#repo = \"252_ML.tutorial\"\n","#src_dir = \"RL/src/02_mountain_car/src\"\n","#pyfiles = [\"viz.py\"]\n","\n","#for f_rl in pyfiles:\n","#  url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{src_dir}/{f_rl}\"\n","#  !wget --no-cache --backups=1 {url}\n","########################## \n","\n","os.chdir(curr_dir)"]},{"cell_type":"markdown","source":["#2.. Intro to Deep Learning: learning the optimal policy from labeled data\n","\n","[05_crash_course_on_neural_nets.ipynb](https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/05_crash_course_on_neural_nets.ipynb)"],"metadata":{"id":"vyVkwgyAT_7V"}},{"cell_type":"markdown","source":["Skip this lecture if you think you are a Deep Learning master\n","\n","üëâ Let's train a few neural network models in a supervised setting.\n","\n","üëâ In Supervised Machine Learning you have input features and target values. And the goal is to find the right mapping between input features and target values.\n","\n","üëâNeural networks are usually highly-parametric models that are able to fit complex patterns between the input features and the target.\n","\n","üëâ The type of neural network we will use is a Multi Layer Perceptron (MLP). MLPs are stacks of linear models, interleaved with activation functions."],"metadata":{"id":"-HhbSQXxUXqY"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","%pylab inline\n","%config InlineBackend.figure_format = 'svg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2OO0NswUnKP","executionInfo":{"status":"ok","timestamp":1660211784162,"user_tz":-480,"elapsed":7,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"62d67069-b225-48b9-9594-f8253d6973c9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n","`%matplotlib` prevents importing * from pylab and numpy\n","  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"]}]},{"cell_type":"markdown","source":["### Environment üåé"],"metadata":{"id":"8IrhbjzeUprX"}},{"cell_type":"code","source":["import gym\n","env = gym.make('CartPole-v1')"],"metadata":{"id":"invCa2slUtKP","executionInfo":{"status":"ok","timestamp":1660211784162,"user_tz":-480,"elapsed":5,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["##1. Data\n","Steps to generate the train data and test data we will need to build the neural network, and to evaluate it."],"metadata":{"id":"FfoNhzoBUwIi"}},{"cell_type":"markdown","source":["### 1.1 Download the agent parameters from Google Drive üì©"],"metadata":{"id":"nrp8S7bsU3aL"}},{"cell_type":"code","source":["from src.supervised_ml import download_agent_parameters\n","\n","path_to_agent_data = download_agent_parameters()\n","print(f'path_to_agent_data={path_to_agent_data}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"mFloHyu9U6v_","executionInfo":{"status":"error","timestamp":1660211789879,"user_tz":-480,"elapsed":5722,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"c9cd1640-096e-47be-8c09-93165b2eeea1"},"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-42148e54429a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupervised_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_agent_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpath_to_agent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_agent_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'path_to_agent_data={path_to_agent_data}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/src/supervised_ml.py\u001b[0m in \u001b[0;36mdownload_agent_parameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://docs.google.com/uc?export=download&id=1ZdyAuzY-0VYfyNrg0a7gHd5TOX-GadJJ'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAVED_AGENTS_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'CartPole-v1'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'gdrive_agent.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# unzip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_is_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mexisting_tmp_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mexisting_tmp_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/saved_agents/CartPole-v1'"]}]},{"cell_type":"markdown","metadata":{"id":"g0hj0GgeMXS7"},"source":["#2.. Environment, actions, states, rewards üëâüèΩ \n","[notebooks/00_environment.ipynb](https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/00_environment.ipynb)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"otM6nCBz5zNy"},"source":["The state is represented by 4 numbers:\n","\n","* The cart position $x$ from $[-2.4, 2.4]$.\n","* The cart velocity **$v$**\n","* The pole angle $Œ∏$ with respect to the vertical from $-12$ to $12$ degrees (from $-0.21$ to $0.21$ in radians)\n","* The pole angular velocity $œâ$. This is the rate of change of $Œ∏$.\n","\n","<figure><center>\n","<img src=\"https://miro.medium.com/max/461/1*VZcW5MKAkp2P2uqZ_-o53w.jpeg\" width=\"60%\">\n","<figcaption>Cart pole state vector (Image by the author)</figcaption>\n","</center></figure>\n","\n","An episode terminates when either:\n","\n","* the cart goes beyond the limits: $x > 2.4$ or $x < -2.4$\n","* the pole is too far from the vertical: $Œ∏ > 12$ degrees or $Œ∏ < -12$ degrees.\n","* or we reached the maximum number of episodes steps, $500$. In this case, the agent perfectly solved the episode.\n","\n","The starting state is sampled randomly from the interval $[-0.05, 0.05]$ for each state. Sometimes, the starting position is so close to balance that the episode is easy. Other times, the starting position is so off-balance that the episode is much harder to solve, and sometimes even impossible.\n","\n","What about the **cart velocity $v$** and the pole **angular velocity $œâ$**. Are these values bounded too?"]},{"cell_type":"markdown","source":["üëâBefore you solve a Reinforcement Learning problem you need to define what are\n","* the actions\n","* the states of the world\n","* the rewards\n","\n","üëâWe are using the ```CartPole-v0``` environment from [OpenAI's gym](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)\n","\n","üëâ```CartPole-v0``` is not an extremely difficult environment. However, it is complex enough to force us level up our game. The tools we will use to solve it are really powerful.\n","\n","üëâLet's explore it!"],"metadata":{"id":"TnLkLb9ogfIw"}},{"cell_type":"markdown","source":["### Load the environment "],"metadata":{"id":"bYs_feIyhIEa"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","%pylab inline\n","%config InlineBackend.figure_format = 'svg'\n","\n","from matplotlib import pyplot as plt\n","%matplotlib inline"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6XfiHi7g0J7","executionInfo":{"status":"ok","timestamp":1660195955752,"user_tz":-480,"elapsed":10,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"5cd0db6e-9a89-4502-869c-f2edc27940da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Populating the interactive namespace from numpy and matplotlib\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n","`%matplotlib` prevents importing * from pylab and numpy\n","  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"]}]},{"cell_type":"code","source":["## Load the environment \n","import gym\n","env = gym.make('CartPole-v1')"],"metadata":{"id":"mDaH2Zu3g4Op"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If you look at the OpenAI gym interval variables ```env.observation_space.low``` and ```env.observation_space.high``` you will see that these 2 numbers seem to be arbitrarily large or small."],"metadata":{"id":"482usGQJhdM5"}},{"cell_type":"code","source":["## The state consists of 4 numbers:\n","x_min, v_min, angle_min, angular_v_min = env.observation_space.low\n","x_max, v_max, angle_max, angular_v_max = env.observation_space.high\n","\n","print(f'Cart position from {x_min:.2f} to {x_max: .2f}')\n","print(f'Cart velocity from {v_min:.2E} to {v_max: .2E}')\n","print(f'Angle from {angle_min:.2f} to {angle_max: .2f}')\n","print(f'Angular from {angular_v_min:.2E} to {angular_v_max: .2E}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCIrhc-Whlmp","executionInfo":{"status":"ok","timestamp":1660195955753,"user_tz":-480,"elapsed":7,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"5925a698-7136-4bce-b3d6-be55245d8c33"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cart position from -4.80 to  4.80\n","Cart velocity from -3.40E+38 to  3.40E+38\n","Angle from -0.42 to  0.42\n","Angular from -3.40E+38 to  3.40E+38\n"]}]},{"cell_type":"code","source":["# env.reset()\n","# frame = env.render(mode='rgb_array')\n","\n","# fig, ax = plt.subplots(figsize=(8, 6))\n","# ax.axes.yaxis.set_visible(False)\n","# min_x = env.observation_space.low[0]\n","# max_x = env.observation_space.high[0]\n","# ax.imshow(frame, extent=[min_x, max_x, 0, 8])"],"metadata":{"id":"BLliAqA6NRUJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **actions**\n","\n","What about the actions our agent can perform?\n","\n","* 0 : Push the cart to the left.\n","* 1 : Push the cart to the right."],"metadata":{"id":"y7HvKSaYE8D7"}},{"cell_type":"markdown","source":["### **rewards**\n","\n","The **reward** is +1 for every step taken. This means that the longer the agent keeps the pole standing, the higher the cumulative reward."],"metadata":{"id":"C5ZusV12FGrZ"}}],"metadata":{"colab":{"collapsed_sections":["pAm6NrxwL8MS"],"name":"05_Hands_on_RL-Deep Q-learning-WIP.ipynb","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}