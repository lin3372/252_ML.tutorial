{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch02-How to develop deep learning models with keras.ipynb","provenance":[],"authorship_tag":"ABX9TyNspm8hr79UIRjOdIlHtsvM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#How to develop deep learning models with keras\n","- [Your First Deep Learning Project in Python with Keras Step-By-Step](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/), by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on July 24, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/), last updated Oct 13, 2021\n","- [TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/) by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on December 19, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/)\n","- Excerpt by Ivan HP Lin (WIP)\n","\n"],"metadata":{"id":"eXOBpP8hetBo"}},{"cell_type":"markdown","source":["## A. Keras Tutorial Overview\n","\n","The steps you are going to cover in this tutorial are as follows:\n","\n","1. Load Data.\n","2. Define Keras Model.\n","3. Compile Keras Model.\n","4. Fit Keras Model.\n","5. Evaluate Keras Model.\n","6. Tie It All Together.\n","7. Make Predictions"],"metadata":{"id":"JMFpHHq2gAdw"}},{"cell_type":"markdown","source":["## **A.1 Load Data**\n","\n","We will use the NumPy library to load our dataset and we will use two classes from the Keras library to define our model."],"metadata":{"id":"7zy2llmvgxl3"}},{"cell_type":"code","source":["# first neural network with keras tutorial\n","from numpy import loadtxt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBT4vaXhhBkH","executionInfo":{"status":"ok","timestamp":1650988993405,"user_tz":-480,"elapsed":456,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"801cfe70-1921-47ab-ef1d-0f0c9acd923e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["In this Keras tutorial, we are going to use the Pima Indians onset of diabetes dataset. This is a standard machine learning dataset from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years.\n","\n","As such, it is a binary classification problem (onset of diabetes as 1 or not as 0). All of the input variables that describe each patient are numerical. This makes it easy to use directly with neural networks that expect numerical input and output values, and ideal for our first neural network in Keras.\n","\n","The dataset is available from here:\n","\n","- [Dataset CSV File (pima-indians-diabetes.csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n","- [Dataset Details](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names)"],"metadata":{"id":"ne6uKW_hk5C4"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnzZJfaGlNS3","executionInfo":{"status":"ok","timestamp":1650988488926,"user_tz":-480,"elapsed":291,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"e52f4653-8231-47f5-85f5-463a7d442506"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-26 15:54:48--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 23278 (23K) [text/plain]\n","Saving to: ‘pima-indians-diabetes.data.csv’\n","\n","\r          pima-indi   0%[                    ]       0  --.-KB/s               \rpima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.001s  \n","\n","2022-04-26 15:54:48 (16.5 MB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n","\n"]}]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZqTBks3lh43","executionInfo":{"status":"ok","timestamp":1650988567598,"user_tz":-480,"elapsed":315,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"991cbf7d-e010-49fb-cb25-7e528d27b369"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-26 15:56:07--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3066 (3.0K) [text/plain]\n","Saving to: ‘pima-indians-diabetes.names’\n","\n","\r          pima-indi   0%[                    ]       0  --.-KB/s               \rpima-indians-diabet 100%[===================>]   2.99K  --.-KB/s    in 0s      \n","\n","2022-04-26 15:56:07 (28.1 MB/s) - ‘pima-indians-diabetes.names’ saved [3066/3066]\n","\n"]}]},{"cell_type":"markdown","source":["We can now load the file as a matrix of numbers using the NumPy function [loadtxt()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html).\n","\n","There are eight input variables and one output variable (the last column). We will be learning a model to map rows of input variables (X) to an output variable (y), which we often summarize as $\\bf y = f(X)$.\n","\n","The variables can be summarized as follows:\n","\n","* Input Variables ($\\bf X$):\n","  1. Number of times pregnant\n","  2.Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","  3. Diastolic blood pressure (mm Hg)\n","  4.Triceps skin fold thickness (mm)\n","  5. 2-Hour serum insulin (mu U/ml)\n","  6. Body mass index (weight in kg/(height in m)^2)\n","  7. Diabetes pedigree function\n","  8. Age (years)\n","\n","* Output Variables ($\\bf y$):\n","  1. Class variable (0 or 1)\n","\n","Once the CSV file is loaded into memory, we can split the columns of data into input and output variables.\n","\n","The data will be stored in a 2D array where the first dimension is rows and the second dimension is columns, e.g. [rows, columns].\n","\n","We can split the array into two arrays by selecting subsets of columns using the standard NumPy [**slice operator**](https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/) or “**:**” We can select the first 8 columns from index 0 to index 7 via the slice 0:8. We can then select the output column (the 9th variable) via index 8.\n","\n","* Reference: [**How to Index, Slice and Reshape NumPy Arrays for Machine Learning in Python**](https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/)"],"metadata":{"id":"SqrbI6_Nl6ub"}},{"cell_type":"code","source":["...\n","# load the dataset\n","dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=',')\n","# split into input (X) and output (y) variables\n","X = dataset[:,0:8]\n","y = dataset[:,8]\n","..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nF2HREbEnFG4","executionInfo":{"status":"ok","timestamp":1650989993891,"user_tz":-480,"elapsed":467,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"68047f40-37ac-4635-a50b-705c792f11f1"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["## **A.2 Define Keras Model**\n","\n","Models in Keras are defined as a sequence of layers.\n","\n","We create a [***Sequential model***](https://keras.io/models/sequential/) and add layers one at a time until we are happy with our network architecture.\n","\n","The first thing to get right is to ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument and setting it to 8 for the 8 input variables.\n","\n","In this example, we will use a fully-connected network structure with three layers.\n","\n","Fully connected layers are defined using the [**Dense class**](https://keras.io/layers/core/). We can specify the number of neurons or nodes in the layer as the first argument, and specify the activation function using the **activation** argument.\n","\n","We will use the [rectified linear unit activation function](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) referred to as ReLU on the first two layers and the Sigmoid function in the output layer.\n","\n","It used to be the case that Sigmoid and Tanh activation functions were preferred for all layers. These days, better performance is achieved using the ReLU activation function. We use a sigmoid on the output layer to ensure our network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard classification of either class with a default threshold of 0.5.\n","\n","We can piece it all together by adding each layer:\n","\n","* The model expects rows of data with 8 variables (the input_dim=8 argument)\n","* The first hidden layer has 12 nodes and uses the relu activation function.\n","* The second hidden layer has 8 nodes and uses the relu activation function.\n","* The output layer has one node and uses the sigmoid activation function."],"metadata":{"id":"B7nv4lD7rX2Y"}},{"cell_type":"code","source":["...\n","# define the keras model\n","model = Sequential()\n","model.add(Dense(12, input_dim=8, activation='relu'))\n","model.add(Dense(8, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUcY8HHQsqrq","executionInfo":{"status":"ok","timestamp":1650990431593,"user_tz":-480,"elapsed":302,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"ae0ec92d-4e21-40df-f6ab-f8ec4c9570b0"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["## **A.3 Compile Keras Model**\n","\n","Compiling the model uses the efficient numerical libraries under the covers (the so-called backend) such as Theano or TensorFlow. The backend automatically chooses the best way to represent the network for training and making predictions to run on your hardware, such as CPU or GPU or even distributed."],"metadata":{"id":"x5pCCepss_FY"}},{"cell_type":"markdown","source":["When compiling, we must specify some additional properties required when training the network. Remember training a network means finding the best set of weights to map inputs to outputs in our dataset.\n","\n","1. We must specify the **loss function** to use to evaluate a set of weights, the optimizer is used to search through different weights for the network and any optional metrics we would like to collect and report during training.\n","\n","2. In this case, we will use **cross entropy** as the **loss** argument. This loss is for a binary classification problems and is defined in Keras as “**binary_crossentropy**“. You can learn more about choosing loss functions based on your problem here:\n","  * [How to Choose Loss Functions When Training Deep Learning Neural Networks](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)\n","\n","4. We will define the **optimizer** as the efficient stochastic gradient descent algorithm “**adam**“. It automatically tunes itself and gives good results in a wide range of problems. To learn more about the Adam version of stochastic gradient descent see the post:\n","  * [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n","\n","5. Finally, because it is a classification problem, we will collect and report the classification accuracy, defined via the **metrics** argument."],"metadata":{"id":"6MG7urz0vOAI"}},{"cell_type":"code","source":["...\n","# compile the keras model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","..."],"metadata":{"id":"cuedukLSwL4x","executionInfo":{"status":"ok","timestamp":1650991354983,"user_tz":-480,"elapsed":401,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"003d7457-758f-49b7-bc4e-3ec981eee650","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":9}]}]}