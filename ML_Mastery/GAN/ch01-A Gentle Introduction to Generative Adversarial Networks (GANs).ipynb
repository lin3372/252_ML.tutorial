{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch01-A Gentle Introduction to Generative Adversarial Networks (GANs).ipynb","provenance":[],"authorship_tag":"ABX9TyNiEclcOX16q4/aeqKwolYP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#[A Gentle Introduction to Generative Adversarial Networks (GANs)](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/)\n","- by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on June 17, 2019 in [Generative Adversarial Networks](https://machinelearningmastery.com/category/generative-adversarial-networks/)\n","- Moderated by ivan H.P. Lin on Apr 26, 2022"],"metadata":{"id":"T5USe3OYQWFs"}},{"cell_type":"markdown","source":["GANs are a clever way of training a generative model by framing the problem as a supervised learning problem with two sub-models: the generator model that we train to generate new examples, and the discriminator model that tries to classify examples as either real (from the domain) or fake (generated). The two models are trained together in a zero-sum game, adversarial, until the discriminator model is fooled about half the time, meaning the generator model is generating plausible examples."],"metadata":{"id":"_5vm25hUQ436"}},{"cell_type":"markdown","source":["## **1.2 What Are Generative Models?**"],"metadata":{"id":"uqlYNI37n1Pj"}},{"cell_type":"markdown","source":["### 1.2.1 Supervised vs. Unsupervised Learning\n","\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-Supervised-Learning.png\" width=\"35%\">\n","<figcaption>Example of Supervised Learning</figcaption></center>\n","</figure>\n","\n","\n","\n"],"metadata":{"id":"kEIjnpZ0RDoS"}},{"cell_type":"markdown","source":["### 1.2.2 **Discriminative vs. Generative Modeling**\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-Discriminative-Modeling.png\" width=\"25%\">\n","<figcaption>Example of Discriminative Modeling</figcaption></center>\n","</figure>\n","\n","**Unsupervised models** that summarize the distribution of input variables may be able to be used to create or generate new examples in the input distribution.\n","\n","As such, these types of models are referred to as **generative models**.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-Generative-Modeling.png\" width=\"25%\">\n","<figcaption>Example of Generative Modeling</figcaption></center>\n","</figure>\n"],"metadata":{"id":"TADM__ypkwr6"}},{"cell_type":"markdown","source":["### 1.2.3 **Examples of Generative Models**\n","\n","[**Naive Bayes**](https://machinelearningmastery.com/naive-bayes-for-machine-learning/) is an example of a generative model that is more often used as a discriminative model.\n","\n","For example, **Naive Bayes** works by summarizing the probability distribution of each input variable and the output class. When a prediction is made, the probability for each possible outcome is calculated for each variable, the independent probabilities are combined, and the most likely outcome is predicted. Used in reverse, the probability distributions for each variable can be sampled to generate new plausible (independent) feature values.\n","\n","Other examples of generative models include **Latent Dirichlet Allocation**, or **LDA**, and the **Gaussian Mixture Model**, or **GMM**.\n","\n","Two modern examples of deep learning generative modeling algorithms include the **Variational Autoencoder**, or **VAE**, and the **Generative Adversarial Network**, or **GAN**."],"metadata":{"id":"lDz4Ad4aoC1r"}},{"cell_type":"markdown","source":["##1.3 **What Are Generative Adversarial Networks?**\n","\n","The GAN model architecture involves two sub-models: a **generator model** for generating new examples and a **discriminator model** for classifying whether generated examples are real, from the domain, or fake, generated by the generator model.\n","\n","* **Generator**. Model that is used to generate new plausible examples from the problem domain.\n","* **Discriminator**. Model that is used to classify examples as real (from the domain) or fake (generated)."],"metadata":{"id":"9WGIa7cGo9xL"}},{"cell_type":"markdown","source":["### 1.3.1 **The Generator Model**\n","\n","The generator model takes a fixed-length random vector as input and generates a sample in the domain.\n","\n","The vector is drawn from randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.\n","\n","This vector space is referred to as a **latent space**, or a vector space comprised of latent variables. Latent variables, or hidden variables, are those variables that are important for a domain but are not directly observable.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-the-GAN-Generator-Model.png\" width=\"25%\">\n","<figcaption>Example of the GAN Generator Model</figcaption></center>\n","</figure>"],"metadata":{"id":"E234roBOpiht"}},{"cell_type":"markdown","source":["### 1.3.2 **The Discriminator Model**\n","\n","The discriminator model takes an example from the domain as input (real or generated) and predicts a binary class label of real or fake (generated).\n","\n","The discriminator is a normal (and well understood) classification model.\n","\n","After the training process, the discriminator model is discarded as we are interested in the generator.\n","\n","Sometimes, the generator can be repurposed as it has learned to effectively extract features from examples in the problem domain. Some or all of the feature extraction layers can be used in **transfer learning** applications using the same or similar input data.\n","\n","- We propose that one way to build good image representations is by training Generative Adversarial Networks (GANs), and later reusing parts of the generator and discriminator networks as feature extractors for supervised tasks\n","  - [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434), 2015.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-the-GAN-Discriminator-Model.png\" width=\"25%\">\n","<figcaption>Example of the GAN Discriminator Model</figcaption></center>\n","</figure>"],"metadata":{"id":"G7qhryBUqgt8"}},{"cell_type":"markdown","source":["### 1.3.3 **GANs as a Two Player Game**\n","\n","Generative modeling is an unsupervised learning problem, although a clever property of the GAN architecture is that the training of the generative model is framed as a supervised learning problem.\n","\n","The two models, the **generator** and **discriminator**, are trained together. The **generator** generates a batch of samples, and these, along with real examples from the domain, are provided to the **discriminator** and classified as real or fake.\n","\n","The discriminator is then updated to get better at discriminating real and fake samples in the next round, and importantly, the generator is updated based on how well, or not, the generated samples fooled the discriminator.\n","\n","In this case, zero-sum means that when the discriminator successfully identifies real and fake samples, it is rewarded or no change is needed to the model parameters, whereas the generator is penalized with large updates to model parameters.\n","\n","Alternately, when the generator fools the discriminator, it is rewarded, or no change is needed to the model parameters, but the discriminator is penalized and its model parameters are updated.\n","\n","At a limit, the generator generates perfect replicas from the input domain every time, and the discriminator cannot tell the difference and predicts “unsure” (e.g. 50% for real and fake) in every case. This is just an example of an idealized case; we do not need to get to this point to arrive at a useful generator model.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-the-Generative-Adversarial-Network-Model-Architecture.png\" width=\"40%\">\n","<figcaption>Example of the Generative Adversarial Network Model Architecture</figcaption></center>\n","</figure>"],"metadata":{"id":"6RMJK9Svraom"}},{"cell_type":"markdown","source":["### 1.3.5 **Conditional GANs**\n","\n","An important extension to the GAN is in their use for conditionally generating an output.\n","\n","The generative model can be trained to generate new examples from the input domain, where the ***input, the random vector from the latent space, is provided with (conditioned by) some additional input.***\n","\n","The additional input could be a class value, such as male or female in the generation of photographs of people, or a digit, in the case of generating images of handwritten digits.\n","\n","- Generative adversarial nets can be extended to a conditional model if both the generator and discriminator are conditioned on some extra information y. y could be any kind of auxiliary information, such as class labels or data from other modalities. We can perform the conditioning by feeding y into the both the discriminator and generator as [an] additional input layer.\n","  - — [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784), 2014\n","\n","\n","The discriminator is also conditioned, meaning that it is provided both with an input image that is either real or fake and the additional input. In the case of a classification label type conditional input, the discriminator would then expect that the input would be of that class, in turn teaching the generator to generate examples of that class in order to fool the discriminator.\n","\n","In this way, a conditional GAN can be used to generate examples from a domain of a given type.\n","\n","Taken one step further, the GAN models can be conditioned on an example from the domain, such as an image. This allows for applications of GANs such as text-to-image translation, or image-to-image translation. This allows for some of the more impressive applications of GANs, such as **style transfer**, **photo colorization**, **transforming photos from summer to winter or day to night**, and so on.\n","\n","In the case of conditional GANs for image-to-image translation, such as transforming day to night, the discriminator is provided examples of real and generated nighttime photos as well as (conditioned on) real daytime photos as input. The generator is provided with a random vector from the latent space as well as (conditioned on) real daytime photos as input.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-a-Conditional-Generative-Adversarial-Network-Model-Architecture.png\" width=\"60%\">\n","<figcaption>Example of a Conditional Generative Adversarial Network Model Architecture</figcaption></center>\n","</figure>"],"metadata":{"id":"6U3atUhkEe2S"}},{"cell_type":"markdown","source":["##1.4 **Why Generative Adversarial Networks?**\n","\n","One of the many major advancements in the use of deep learning methods in domains such as computer vision is a technique called [data augmentation](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/).\n","\n","Data augmentation results in better performing models, both increasing model skill and providing a regularizing effect, reducing generalization error. It works by creating new, artificial but plausible examples from the input problem domain on which the model is trained.\n","\n","The techniques are primitive in the case of image data, involving crops, flips, zooms, and other simple transforms of existing images in the training dataset.\n","\n","Perhaps the most compelling application of GANs is in conditional GANs for tasks that require the generation of new examples. Here, Goodfellow indicates three main examples:\n","\n","* **Image Super-Resolution**. The ability to generate high-resolution versions of input images.\n","* **Creating Art**. The ability to great new and artistic images, sketches, painting, and more.\n","* **Image-to-Image Translation**. The ability to translate photographs across domains, such as day to night, summer to winter, and more.\n","\n","GANs have been able to generate photos so realistic that humans are unable to tell that they are of objects, scenes, and people that do not exist in real life.\n","\n","<figure>\n","<center>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/04/Example-of-the-Progression-in-the-Capabilities-of-GANs-from-2014-to-2017.png\" width=\"60%\">\n","<figcaption>Example of the Progression in the Capabilities of GANs From 2014 to 2017. Taken from [The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation](https://arxiv.org/abs/1802.07228), 2018.</figcaption></center>\n","</figure>"],"metadata":{"id":"yvxuQ6WPGpAV"}},{"cell_type":"markdown","source":["#1.5 Further Reading and Reference"],"metadata":{"id":"1fbCk_EYHyGX"}},{"cell_type":"markdown","source":["###1.5.1 Books\n","\n","* [Chapter 20. Deep Generative Models, Deep Learning](https://amzn.to/2YuwVjL), 2016.\n","* [Chapter 8. Generative Deep Learning, Deep Learning with Python](https://amzn.to/2U2bHuP), 2017.\n","* [Machine Learning: A Probabilistic Perspective](https://amzn.to/2HV6cYx), 2012.\n","* [Pattern Recognition and Machine Learning](https://amzn.to/2K3EcE3), 2006.\n","* [The Elements of Statistical Learning](https://amzn.to/2UcPeva), 2016."],"metadata":{"id":"a9ESy9U3H3e4"}},{"cell_type":"markdown","source":["###1.5.2 papers\n","\n","* [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661), 2014.\n","* [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1701.00160), 2015.\n","* [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160), 2016.\n","* [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784), 2014.\n","* [The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation](https://arxiv.org/abs/1802.07228), 2018."],"metadata":{"id":"a6s_OGsQIZBz"}},{"cell_type":"markdown","source":["### 1.5.3 Blogs/Articles\n","\n","* [Generative model, Wikipedia](https://en.wikipedia.org/wiki/Generative_model).\n","* [Latent Variable, Wikipedia](https://en.wikipedia.org/wiki/Latent_variable).\n","* [Generative Adversarial Network, Wikipedia](https://en.wikipedia.org/wiki/Generative_adversarial_network)."],"metadata":{"id":"JTL96UN0I8Q7"}},{"cell_type":"markdown","source":["# Summary\n","\n","In this post, you discovered a gentle introduction to Generative Adversarial Networks, or GANs.\n","\n","Specifically, you learned:\n","\n","* Context for GANs, including supervised vs. unsupervised learning and discriminative vs. generative modeling.\n","* GANs are an architecture for automatically training a generative model by treating the unsupervised problem as supervised and using both a generative and a discriminative model.\n","* GANs provide a path to sophisticated domain-specific data augmentation and a solution to problems that require a generative solution, such as image-to-image translation."],"metadata":{"id":"lHl9aaEVJXkD"}}]}