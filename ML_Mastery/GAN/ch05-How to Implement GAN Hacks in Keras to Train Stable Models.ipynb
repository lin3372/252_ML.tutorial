{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch05-How to Implement GAN Hacks in Keras to Train Stable Models.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNspL/n250VrLxy5tF9k2Xg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["ch05-How to Implement GAN Hacks in Keras to Train Stable Models\n","\n","- [How to Implement GAN Hacks in Keras to Train Stable Models](https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/), by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on July 12, 2019 in [Generative Adversarial Networks](https://machinelearningmastery.com/category/generative-adversarial-networks/)\n","\n","- Excerpt by Ivan HP Lin (220509)"],"metadata":{"id":"lqAUtXaZ7gQS"}},{"cell_type":"markdown","source":["Generative Adversarial Networks, or GANs, are challenging to train.\n","\n","This is because the architecture involves both a **generator** and a **discriminator** model that compete in a **zero-sum game**. It means that improvements to one model come at the cost of a degrading of performance in the other model. The result is a very unstable training process that can often lead to failure, e.g. a *generator that generates the same image all the time or generates nonsense*.\n","\n","As such, there are a number of heuristics or best practices (called “GAN hacks“) that can be used when configuring and training your GAN models. These heuristics are been hard won by practitioners testing and evaluating hundreds or thousands of combinations of configuration operations on a range of problems over many years.\n","\n","Some of these heuristics can be challenging to implement, especially for beginners.\n","\n","Further, some or all of them may be required for a given project, although it may not be clear which subset of heuristics should be adopted, requiring experimentation. This means a practitioner must be ready to implement a given heuristic with little notice.\n","\n","In this tutorial, you will discover how to implement a suite of best practices or GAN hacks that you can copy-and-paste directly into your GAN project.\n","\n","After reading this tutorial, you will know:\n","\n","* The best sources for practical heuristics or hacks when developing generative adversarial networks.\n","* How to implement seven best practices for the deep convolutional GAN model architecture from scratch.\n","* How to implement four additional best practices from Soumith Chintala’s GAN Hacks presentation and list."],"metadata":{"id":"pKWcVE4l7GuB"}},{"cell_type":"markdown","source":["## 0.. Tutorial Overview\n","This tutorial is divided into three parts; they are:\n","\n","1. Heuristics for Training Stable GANs\n","2. Best Practices for Deep Convolutional GANs\n","  - Downsample Using Strided Convolutions\n","  - Upsample Using Strided Convolutions\n","  - Use LeakyReLU\n","  - Use Batch Normalization\n","  - Use Gaussian Weight Initialization\n","  - Use Adam Stochastic Gradient Descent\n","  - Scale Images to the Range [-1,1]\n","3. Soumith Chintala’s GAN Hacks\n","  - Use a Gaussian Latent Space\n","  - Separate Batches of Real and Fake Images\n","  - Use Label Smoothing\n","  - Use Noisy Labels"],"metadata":{"id":"zSVxnScn7zVh"}},{"cell_type":"markdown","source":["## 1.. Best Practices for Deep Convolutional GANs"],"metadata":{"id":"f9YEVsVj8Hif"}},{"cell_type":"markdown","source":["Perhaps one of the most important steps forward in the design and training of stable GAN models was the 2015 paper by Alec Radford, et al. titled “[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434).”\n","\n","In the paper, they describe the Deep Convolutional GAN, or **DCGAN**, approach to GAN development that has become the de facto standard.\n","\n","We will look at how to implement seven best practices for the DCGAN model architecture in this section."],"metadata":{"id":"vql1fkDQP6Zn"}},{"cell_type":"markdown","source":["### 1.1  Downsample Using **Strided Convolution**s"],"metadata":{"id":"OHOH8GmgQPJR"}},{"cell_type":"markdown","source":["The **discriminator** model is a standard convolutional neural network model that takes an image as input and must output a binary classification as to whether it is real or fake.\n","\n","It is standard practice with deep convolutional networks to use pooling layers to downsample the input and feature maps with the depth of the network.\n","\n","This is not recommended for the DCGAN, and instead, they recommend downsampling using [**strided convolutions**](https://machinelearningmastery.com/padding-and-stride-for-convolutional-neural-networks/).\n","\n","This involves defining a convolutional layer as per normal, but instead of using the default two-dimensional stride of $(1,1)$ to change it to $(2,2)$. This has the effect of downsampling the input, specifically halving the width and height of the input, resulting in output feature maps with one quarter the area.\n","\n","The example below demonstrates this with a single hidden convolutional layer that uses downsampling strided convolutions by setting the ‘strides‘ argument to (2,2). The effect is the model will downsample the input from 64×64 to 32×32."],"metadata":{"id":"RouPRS9GQZWx"}},{"cell_type":"code","source":["# example of downsampling with strided convolutions\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# summarize model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zwLu7nGRdwl","executionInfo":{"status":"ok","timestamp":1651939619318,"user_tz":-480,"elapsed":3952,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"b1e32fc3-ff20-4e5a-83e3-58535e83dda9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n","                                                                 \n","=================================================================\n","Total params: 1,792\n","Trainable params: 1,792\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["1792 == 64 x (3x3x3 + 1)"],"metadata":{"id":"lOmy13XdUCPc"}},{"cell_type":"markdown","source":["### 1.2 Upsample Using **Strided Convolutions**"],"metadata":{"id":"NO6zsVXERrsc"}},{"cell_type":"markdown","source":["The **generator** model must generate an output image given as input at a random point from the latent space.\n","\n","The recommended approach for achieving this is to use a **transpose convolutional layer** with a strided convolution. This is a special type of layer that performs the convolution operation in reverse. Intuitively, this means that setting a stride of 2×2 will have the opposite effect, upsampling the input instead of downsampling it in the case of a normal convolutional layer.\n","\n","By stacking a transpose convolutional layer with strided convolutions, the generator model is able to scale a given input to the desired output dimensions.\n","\n","The example below demonstrates this with a single hidden transpose convolutional layer that uses upsampling strided convolutions by setting the ‘strides‘ argument to (2,2).\n","\n","The effect is the model will upsample the input from 64×64 to 128×128.\n","\n","<figure>\n","<center>\n","<img src=\"https://i.ytimg.com/vi/96_oGE8WyPg/hqdefault.jpg\" width=\"60%\">\n","<figcaption>Transposed Convolution</figcaption>\n","<img src=\"https://www.researchgate.net/profile/Shantanu-Shahane/publication/347534508/figure/fig3/AS:971385199407105@1608607687540/Example-of-Transpose-Convolution-with-Stride-2-2-Kernel-size-2-2.ppm\" width=\"90%\">\n","<figcaption>Transposed Convolution (stride=(2x2))</figcaption></center>\n","</figure>"],"metadata":{"id":"3oA6H7Y4R1Zu"}},{"cell_type":"code","source":["# example of upsampling with strided convolutions\n","from keras.models import Sequential\n","from keras.layers import Conv2DTranspose\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# summarize model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZsF0NEJTUQq","executionInfo":{"status":"ok","timestamp":1651940087903,"user_tz":-480,"elapsed":335,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"6e7ca841-c4a5-4547-a502-1018beeb0f8a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_transpose (Conv2DTra  (None, 128, 128, 64)     3136      \n"," nspose)                                                         \n","                                                                 \n","=================================================================\n","Total params: 3,136\n","Trainable params: 3,136\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["3136 = 64 x (4x4x3 + 1)"],"metadata":{"id":"22_f3z94UVbQ"}},{"cell_type":"markdown","source":["### 1.3 Use LeakyReLU"],"metadata":{"id":"jLfkrClcUjTr"}},{"cell_type":"markdown","source":["The [rectified linear activation unit](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/), or ReLU for short, is a simple calculation that returns the value provided as input directly, or the value 0.0 if the input is 0.0 or less.\n","\n","The best practice for GANs is to use a variation of the ReLU that allows some values less than zero and learns where the cut-off should be in each node. This is called the **leaky rectified linear activation unit**, or **LeakyReLU** for short.\n","\n","A negative slope can be specified for the LeakyReLU and the default value of 0.2 is recommended.\n","\n","Originally, ReLU was recommend for use in the generator model and LeakyReLU was recommended for use in the discriminator model, although more recently, the LeakyReLU is recommended in both models.\n","\n","The example below demonstrates using the LeakyReLU with the default slope of 0.2 after a convolutional layer in a discriminator model.\n","\n","<figure>\n","<center>\n","<img src=\"https://deeplearninguniversity.com/wp-content/uploads/2020/06/Screenshot-2020-06-04-at-9.13.01-PM.png\" width=\"50%\">\n","<figcaption>Leaky ReLU function, with α=0.05</figcaption></center>\n","</figure>\n"],"metadata":{"id":"M_cOjXRXUrBB"}},{"cell_type":"code","source":["# example of using leakyrelu in a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","model.add(LeakyReLU(0.2))\n","# summarize model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CsQpEeu_WaIi","executionInfo":{"status":"ok","timestamp":1651940903122,"user_tz":-480,"elapsed":283,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"0b43a332-6384-4b75-9d0c-05e8e3935a93"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_1 (Conv2D)           (None, 32, 32, 64)        1792      \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n","                                                                 \n","=================================================================\n","Total params: 1,792\n","Trainable params: 1,792\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### 1.4 Batch Normalization\n","\n","<figure>\n","<center>\n","<img src=\"https://i.stack.imgur.com/stBna.png\" width=\"60%\">\n","<figcaption>Batch normalization for image CNN</figcaption></center>\n","<center>\n","<img src=\"https://theaisummer.com/static/ac89fbcf1c115f07ae68af695c28c4a0/ee604/normalization.png\" width=\"60%\">\n","<figcaption>In-layer normalization techniques for training very deep neural networks</figcaption></center></center>\n","</figure>\n","\n","\n","<div>\n","   <figure><center>\n","      <img src=\"https://lh6.googleusercontent.com/QT5hSlqurfmHL5ZGnAkWB-fRej7uy3Pryu1n-Rv3WH4ZNYLbKOkpexJf8zpililWAYc3-otGiH9pR-p8sScHAiednLfl4rC9oQUY-0uKdEcmctX6wLLJ2fkA-A6t2w4pukpNrJ8\" width=\"60%\">\n","   </figure>\n","   <figure><center>\n","      <img src=\"https://lh4.googleusercontent.com/b1yEZVxwXMo8Ukf9XvLG37RDjCuTQ0OV6VBuc-Armt8WJzdlrj02Ss5LqYM1Oi5IStk2O9PudtzE41LjGTqmul8KdMQJjo34TMDdU9ncE0chqrMO5PjEL631KDTJRZ6JFVgVxuM\" width=\"60%\">\n","      <figcaption>Batch Normalization by NTU Prof 李宏毅</figcaption></center>\n","   </figure>\n","</div>"],"metadata":{"id":"Wdr5gP4mjtsy"}},{"cell_type":"markdown","source":["[Batch normalization](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/) standardizes the activations from a prior layer to have a **zero mean** and **unit variance**. This has the effect of stabilizing the training process.\n","\n","Batch normalization is used after the activation of convolution and transpose convolutional layers in the discriminator and generator models respectively.\n","\n","It is added to the model after the hidden layer, but before the activation, such as LeakyReLU.\n","\n","The example below demonstrates adding a Batch Normalization layer after a Conv2D layer in a discriminator model but before the activation."],"metadata":{"id":"GtqA_2g6pr50"}},{"cell_type":"code","source":["# example of using batch norm in a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import BatchNormalization\n","from keras.layers import LeakyReLU\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU(0.2))\n","# summarize model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZsH9cxap6N5","executionInfo":{"status":"ok","timestamp":1652029905353,"user_tz":-480,"elapsed":3468,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"5ae64fe1-0615-4a08-bf3d-e0955cce2f93"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n","                                                                 \n"," batch_normalization (BatchN  (None, 32, 32, 64)       256       \n"," ormalization)                                                   \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n","                                                                 \n","=================================================================\n","Total params: 2,048\n","Trainable params: 1,920\n","Non-trainable params: 128\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### 1.5 Use Gaussain Weight Initialization"],"metadata":{"id":"DFihVS1SqArC"}},{"cell_type":"markdown","source":["Before a neural network can be trained, the model weights (parameters) must be initialized to small random variables.\n","\n","The best practice for DCAGAN models reported in the paper is to initialize all weights using a zero-centered Gaussian distribution (the normal or bell-shaped distribution) with a standard deviation of 0.02.\n","\n","The example below demonstrates defining a random Gaussian weight initializer with a mean of 0 and a standard deviation of 0.02 for use in a transpose convolutional layer in a generator model.\n","\n","The same weight initializer instance could be used for each layer in a given model."],"metadata":{"id":"S_akyndcqH8p"}},{"cell_type":"code","source":["# example of gaussian weight initialization in a generator model\n","from keras.models import Sequential\n","from keras.layers import Conv2DTranspose\n","from keras.initializers import RandomNormal\n","# define model\n","model = Sequential()\n","init = RandomNormal(mean=0.0, stddev=0.02)\n","model.add(Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), \\\n","                          padding='same', kernel_initializer=init, \\\n","                          input_shape=(64,64,3)))\n","# summarize model\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUC-__KfqO3y","executionInfo":{"status":"ok","timestamp":1652030039943,"user_tz":-480,"elapsed":361,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"807e56b8-140c-4b7f-c7b8-7f96e2949ae7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_transpose_1 (Conv2DT  (None, 128, 128, 64)     3136      \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 3,136\n","Trainable params: 3,136\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### 1.6 Adam Stochastic Gradient Descent"],"metadata":{"id":"kr16zhVtqyM2"}},{"cell_type":"markdown","source":["Stochastic gradient descent, or SGD for short, is the standard algorithm used to optimize the weights of convolutional neural network models.\n","\n","There are many variants of the training algorithm. The best practice for training DCGAN models is to use the [**Adam version of stochastic gradient descent**](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) with the learning rate of 0.0002 and the beta1 momentum value of 0.5 instead of the default of 0.9.\n","\n","The Adam optimization algorithm with this configuration is recommended when both optimizing the discriminator and generator models.\n","\n","The example below demonstrates configuring the Adam stochastic gradient descent optimization algorithm for training a discriminator model."],"metadata":{"id":"_srsVZ2lq4hq"}},{"cell_type":"code","source":["# example of using adam when training a discriminator model\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from tensorflow.keras.optimizers import Adam\n","# define model\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', input_shape=(64,64,3)))\n","# compile model\n","opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"],"metadata":{"id":"eZXtwqCDrNlo","executionInfo":{"status":"ok","timestamp":1652030332367,"user_tz":-480,"elapsed":364,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### 1.7 Scale Images to the Range $[-1,1]$"],"metadata":{"id":"noa0VrCyrpTB"}},{"cell_type":"markdown","source":["It is recommended to use the hyperbolic tangent activation function ($tanh(⊙)$)as the output from the generator model.\n","\n","As such, it is also recommended that real images used to train the discriminator are [scaled so that their pixel values](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/) are in the range $[-1,1]$. This is so that the discriminator will always receive images as input, real and fake, that have pixel values in the same range.\n","\n","Typically, image data is loaded as a NumPy array such that pixel values are 8-bit unsigned integer (uint8) values in the range $[0, 255]$.\n","\n","First, the array must be converted to floating point values, then rescaled to the required range.\n","\n","The example below provides a function that will appropriately scale a NumPy array of loaded image data to the required range of $[-1,1]$."],"metadata":{"id":"PHCt2updrubB"}},{"cell_type":"code","source":["# example of a function for scaling images\n","\n","# scale image data from [0,255] to [-1,1]\n","def scale_images(images):\n","\t# convert from unit8 to float32\n","\timages = images.astype('float32')\n","\t# scale from [0,255] to [-1,1]\n","\timages = (images - 127.5) / 127.5\n","\treturn images"],"metadata":{"id":"cbvU8Uz6sY5O","executionInfo":{"status":"ok","timestamp":1652030561708,"user_tz":-480,"elapsed":352,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 2.. Soumith Chintala’s GAN Hacks  \n","* [**How to Train a GAN (Youtube)**](https://www.youtube.com/watch?v=X1mUN6dD8uE) - Highly recommended"],"metadata":{"id":"XcBA0JMBZZug"}},{"cell_type":"markdown","source":["The video is available on [YouTube](https://www.youtube.com/watch?v=X1mUN6dD8uE) and is highly recommended. A summary of the tips is also available as a GitHub repository titled “[How to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks)”\n","\n","\n","In this section, we will review how to implement four additional GAN best practices not covered in the previous section."],"metadata":{"id":"ST1pea_kbZZk"}},{"cell_type":"code","source":[""],"metadata":{"id":"KcQJPeWMlic6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.1 Use a Gaussian Latent Space"],"metadata":{"id":"GtCgBSTYbq2O"}},{"cell_type":"markdown","source":["The latent space defines the shape and distribution of the input to the generator model used to generate new images.\n","\n","The **DCGAN** recommends sampling from a uniform distribution, meaning that the shape of the latent space is a hypercube.\n","\n","The more recent best practice is to sample from a standard [Gaussian distribution](https://machinelearningmastery.com/statistical-data-distributions/), meaning that the shape of the latent space is a hypersphere, with a mean of zero and a standard deviation of one.\n","\n","The example below demonstrates how to generate 500 [random Gaussian points](https://machinelearningmastery.com/how-to-generate-random-numbers-in-python/) from a 100-dimensional latent space that can be used as input to a generator model; each point could be used to generate an image."],"metadata":{"id":"zHwowNOZbvle"}},{"cell_type":"code","source":["import numpy as np\n","# example of sampling from a gaussian latent space\n","from numpy.random import randn\n","\n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape((n_samples, latent_dim))\n","\treturn x_input\n","\n","# size of latent space\n","n_dim = 100\n","# number of samples to generate\n","n_samples = 500\n","# generate samples\n","samples = generate_latent_points(n_dim, n_samples)\n","# summarize\n","print(f'sample shape={samples.shape}, \\nmean={np.round(samples.mean(),3)}, \\nvar={np.round(samples.std(),3)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnOoipD5lvxy","executionInfo":{"status":"ok","timestamp":1652112885473,"user_tz":-480,"elapsed":242,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"ca48a421-ca31-40e7-934b-01b67ff32216"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["sample shape=(500, 100), \n","mean=-0.005, \n","var=0.998\n"]}]},{"cell_type":"markdown","source":["### 2.2 Separate Batches of Real and Fake Images"],"metadata":{"id":"Muu0U1fSmmUz"}},{"cell_type":"markdown","source":["The discriminator model is trained using stochastic gradient descent with mini-batches.\n","\n","* The best practice is to update the discriminator with separate batches of real and fake images rather than combining real and fake images into a single batch.\n","\n","* This can be achieved by updating the model weights for the discriminator model with two separate calls to the **train_on_batch()** function.\n","\n","The code snippet below demonstrates how you can do this within the inner loop of code when training your discriminator model.\n","```\n","...\n","# get randomly selected 'real' samples\n","X_real, y_real = ...\n","# update discriminator model weights\n","discriminator.train_on_batch(X_real, y_real)\n","\n","# generate 'fake' examples\n","X_fake, y_fake = ...\n","# update discriminator model weights\n","discriminator.train_on_batch(X_fake, y_fake)\n","```"],"metadata":{"id":"o_0QKbl-mqyD"}},{"cell_type":"markdown","source":["### 2.3 Use Label Smoothing"],"metadata":{"id":"dqevhqJmnn-j"}},{"cell_type":"markdown","source":["It is common to use the class label 1 to represent real images and class label 0 to represent fake images when training the discriminator model.\n","\n","These are called hard labels, as the label values are precise or crisp.\n","\n","It is a good practice to use soft labels, such as values slightly more or less than 1.0 or slightly more than 0.0 for real and fake images respectively, where the variation for each image is random.\n","\n","This is often referred to as **label smoothing** and can have a [**regularizing effect**](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/) when training the model.\n","\n","The example below demonstrates defining 1,000 labels for the positive class (class=1) and smoothing the label values uniformly into the range [0.7,1.2] as recommended."],"metadata":{"id":"zqg08H4FntUa"}},{"cell_type":"code","source":["# example of positive label smoothing\n","import numpy as np\n","from numpy import ones\n","from numpy.random import random\n","\n","# example of smoothing class=1 to [0.7, 1.2]\n","def smooth_positive_labels(y):\n","\treturn y - 0.3 + (random(y.shape) * 0.5)\n","\n","\n","# generate 'real' class labels (1)\n","n_samples = 1000\n","y = ones((n_samples, 1))\n","# smooth labels\n","y = smooth_positive_labels(y)\n","# summarize smooth labels\n","print(f'y.shape={y.shape}, \\n(y.min, y.max)=({np.round(y.min(),3)}, {np.round(y.max(),3)})')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imyoZZogoCsl","executionInfo":{"status":"ok","timestamp":1652113495447,"user_tz":-480,"elapsed":249,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"dc219855-a1de-4a88-c5b3-f7501568dce3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["y.shape=(1000, 1), \n","(y.min, y.max)=(0.701, 1.199)\n"]}]},{"cell_type":"markdown","source":["There have been some suggestions that only positive-class label smoothing is required and to values less than 1.0. Nevertheless, you can also smooth negative class labels.\n","\n","The example below demonstrates generating 1,000 labels for the negative class (class=0) and smoothing the label values uniformly into the range $[0.0, 0.3]$ as recommended."],"metadata":{"id":"tOKoo3LmpA8T"}},{"cell_type":"code","source":["# example of negative label smoothing\n","import numpy as np\n","from numpy import zeros\n","from numpy.random import random\n","\n","# example of smoothing class=0 to [0.0, 0.3]\n","def smooth_negative_labels(y):\n","\treturn y + random(y.shape) * 0.3\n","\n","# generate 'fake' class labels (0)\n","n_samples = 1000\n","y = zeros((n_samples, 1))\n","# smooth labels\n","y = smooth_negative_labels(y)\n","# summarize smooth labels\n","#print(y.shape, y.min(), y.max())\n","print(f'y.shape={y.shape}, \\n(y.min, y.max)=({np.round(y.min(),3)}, {np.round(y.max(),3)})')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WicVrrpspIgF","executionInfo":{"status":"ok","timestamp":1652113648140,"user_tz":-480,"elapsed":285,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"d98f51a5-4408-425a-ba0b-c87be0997be3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["y.shape=(1000, 1), \n","(y.min, y.max)=(0.0, 0.299)\n"]}]},{"cell_type":"markdown","source":["### 2.4 Use Noisy Labels"],"metadata":{"id":"ifEbhzDBpdqj"}},{"cell_type":"markdown","source":["The labels used when training the discriminator model are always correct.\n","\n","This means that fake images are always labeled with class 0 and real images are always labeled with class 1.\n","\n","It is recommended to introduce some errors to these labels where some fake images are marked as real, and some real images are marked as fake.\n","\n","If you are using separate batches to update the discriminator for real and fake images, this may mean randomly adding some fake images to the batch of real images, or randomly adding some real images to the batch of fake images.\n","\n","If you are updating the discriminator with a combined batch of real and fake images, then this may involve randomly flipping the labels on some images.\n","\n","The example below demonstrates this by creating 1,000 samples of real (class=1) labels and flipping them with a 5% probability, then doing the same with 1,000 samples of fake (class=0) labels."],"metadata":{"id":"C6HUjGiPpkNd"}},{"cell_type":"code","source":["# example of noisy labels\n","import numpy as np\n","from numpy import ones\n","from numpy import zeros\n","from numpy.random import choice\n","\n","# randomly flip some labels\n","def noisy_labels(y, prob_flip):\n","\t# determine the number of labels to flip\n","\tn_select = int(prob_flip * y.shape[0])\n","\t# choose labels to flip\n","\tflip_ix = choice([i for i in range(y.shape[0])], size=n_select)\n","\t# invert the labels in place\n","\ty[flip_ix] = 1 - y[flip_ix]\n","\treturn y\n","\n","# generate 'real' class labels (1)\n","n_samples = 1000\n","y = ones((n_samples, 1))\n","# flip labels with 5% probability\n","y = noisy_labels(y, 0.05)\n","# summarize labels\n","print(f'real image y.sum()={y.sum()}')\n","\n","# generate 'fake' class labels (0)\n","y = zeros((n_samples, 1))\n","# flip labels with 5% probability\n","y = noisy_labels(y, 0.05)\n","# summarize labels\n","print(f'fake image y.sum()={y.sum()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYGKzgQmpza0","executionInfo":{"status":"ok","timestamp":1652114006019,"user_tz":-480,"elapsed":409,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"c9bf87be-459a-46d0-cddb-d831ac321219"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["real image y.sum()=950.0\n","fake image y.sum()=50.0\n"]}]},{"cell_type":"markdown","source":["## 3.. Further Readings"],"metadata":{"id":"8Jw6Dtpaq9PU"}},{"cell_type":"markdown","source":["Papers\n","* [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, 2015](https://arxiv.org/abs/1511.06434)\n","* [Tutorial: Generative Adversarial Networks, NIPS, 2016](https://arxiv.org/abs/1701.00160)\n","* [Improved Techniques for Training GANs, 2016](https://arxiv.org/abs/1606.03498)\n","\n","Articles\n","* [ganhacks: How to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks)\n","* [Ian Goodfellow, Introduction to GANs, NIPS 2016](https://www.youtube.com/watch?v=9JpdAg6uMXs)\n","* [Soumith Chintala, How to train a GAN, NIPS 2016 Workshop on Adversarial Training](https://www.youtube.com/watch?v=X1mUN6dD8uE)"],"metadata":{"id":"aDV6O9KsrDBp"}}]}