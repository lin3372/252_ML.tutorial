{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch02.2-TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPuR1OphvN9hiCRTOjb8mrZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#How to develop deep learning models with keras\n","- [Your First Deep Learning Project in Python with Keras Step-By-Step](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/), by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on July 24, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/), last updated Oct 13, 2021\n","- [TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/) by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on December 19, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/)\n","- Excerpt by Ivan HP Lin (WIP)\n","\n"],"metadata":{"id":"eXOBpP8hetBo"}},{"cell_type":"markdown","source":["# 0. **TensorFlow Tutorial Overview**"],"metadata":{"id":"BLNB5Pa5UWy6"}},{"cell_type":"markdown","source":["It is a large tutorial and as such, it is divided into five parts; they are:\n","\n","1. **Install TensorFlow and tf.keras**\n","  - What Are Keras and tf.keras?\n","  - How to Install TensorFlow\n","  - How to Confirm TensorFlow Is Installed\n","2. **Deep Learning Model Life-Cycle**\n","  - The 5-Step Model Life-Cycle\n","  - Sequential Model API (Simple)\n","  - Functional Model API (Advanced)\n","3. **How to Develop Deep Learning Models**\n","  - Develop Multilayer Perceptron Models\n","  - Develop Convolutional Neural Network Models\n","  - Develop Recurrent Neural Network Models\n","4. **How to Use Advanced Model Features**\n","  - How to Visualize a Deep Learning Model\n","  - How to Plot Model Learning Curves\n","  - How to Save and Load Your Model\n","5. **How to Get Better Model Performance**\n","  - How to Reduce Overfitting With Dropout\n","  - How to Accelerate Training With Batch Normalization\n","  - How to Halt Training at the Right Time With Early Stopping\n","\n","You Can Do Deep Learning in Python!"],"metadata":{"id":"VNK3MJOqUj_i"}},{"cell_type":"markdown","source":["#1. Install Tensorflow and tf.keras"],"metadata":{"id":"bRfDX0FF1mvf"}},{"cell_type":"markdown","source":["In 2019, Google released a new version of their TensorFlow deep learning library (TensorFlow 2) that integrated the Keras API directly and promoted this interface as the default or standard interface for deep learning development on the platform.\n","\n","This integration is commonly referred to as the ***tf.keras*** interface or API (“tf” is short for “TensorFlow“). This is to distinguish it from the so-called standalone Keras open source project.\n","\n","* **Standalone Keras**. The standalone open source project that supports TensorFlow, Theano and CNTK backends.\n","* **tf.keras**. The Keras API integrated into TensorFlow 2."],"metadata":{"id":"2zw5ZooX1_92"}},{"cell_type":"code","source":["# example of tf.keras python idiom\n","import tensorflow as tf\n","# use keras API\n","model = tf.keras.Sequential()\n","..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzktPmMf14QI","executionInfo":{"status":"ok","timestamp":1651122873006,"user_tz":-480,"elapsed":3190,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"96c3c87f-beba-4d78-b7b6-cf972603b9aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# check version\n","import tensorflow\n","print(tensorflow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1sv-OoC1tpv","executionInfo":{"status":"ok","timestamp":1651122873006,"user_tz":-480,"elapsed":6,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"90f53ed1-6001-47c8-cce6-4901c417329c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"markdown","source":["# 2. Deep Learning Model Life-Cycle"],"metadata":{"id":"HuQZbnMf2Z3f"}},{"cell_type":"markdown","source":["## 2.1 The 5-Step Model Life-\n","The five steps in the life-cycle are as follows:\n","\n","1. Define the model.\n","2. Compile the model.\n","3. Fit the model.\n","4. Evaluate the model.\n","5. Make predictions.\n","\n","Example from Ivan's revised code - [How to develop deep learning models with keras](https://colab.research.google.com/drive/1mjhUSBDEjyr_IA5oxH4XaTiPY_l_-jEd#scrollTo=eXOBpP8hetBo)"],"metadata":{"id":"GyCYAhD32f5F"}},{"cell_type":"markdown","source":["### 2.1.1 Define the Model\n","\n","From an API perspective, this involves defining the layers of the model, configuring each layer with a number of nodes and activation function, and connecting the layers together into a cohesive model.\n","\n","Models can be defined either with the **Sequential API** or the **Functional API**"],"metadata":{"id":"0rJmIxRl5YAc"}},{"cell_type":"markdown","source":["### 2.1.2 Compile the Model\n","\n","Compiling the model requires that you first select a **loss function** that you want to optimize, such as **mean squared error** or **cross-entropy**.\n","\n","It also requires that you select an algorithm to perform the optimization procedure, typically **stochastic gradient descent**, or a modern variation, such as **Adam**. It may also require that you select any **performance metrics** to keep track of during the model training process.\n","\n","From an API perspective, this involves calling a function to compile the model with the chosen configuration, which will prepare the appropriate data structures required for the efficient use of the model you have defined.\n","\n","The optimizer can be specified as a string for a known optimizer class, e.g. ‘sgd‘ for stochastic gradient descent, or you can configure an instance of an optimizer class and use that.\n","```\n","# compile the model\n","opt = SGD(learning_rate=0.01, momentum=0.9)\n","model.compile(optimizer=opt, loss='binary_crossentropy')\n","```\n","\n"],"metadata":{"id":"ltJUhP69531l"}},{"cell_type":"markdown","source":["The three most common loss functions are:\n","\n","* ‘***binary_crossentropy***‘ for binary classification.\n","* ‘***sparse_categorical_crossentropy***‘ for multi-class classification.\n","* ***‘mse‘*** (mean squared error) for regression.\n","\n","For a list of supported loss functions, see:\n","[tf.keras Loss Functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses)"],"metadata":{"id":"mP19LyGW_PZe"}},{"cell_type":"markdown","source":["Metrics are defined as a list of strings for known metric functions or a list of functions to call to evaluate predictions.\n","\n","For a list of supported metrics, see:\n","\n","[tf.keras Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n","\n","```\n","# compile the model\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","```"],"metadata":{"id":"02ChXaVo_wjd"}},{"cell_type":"markdown","source":["### 2.1.3 **Fit the Model**\n","\n","Fitting the model requires that you first select the training configuration, such as the number of epochs (loops through the training dataset) and the batch size (number of samples in an epoch used to estimate model error).\n","\n","Training applies the chosen optimization algorithm to minimize the chosen loss function and updates the model using the backpropagation of error algorithm.\n","\n","Fitting the model is the slow part of the whole process and can take seconds to hours to days, depending on the complexity of the model, the hardware you’re using, and the size of the training dataset.\n","\n","From an API perspective, this involves calling a function to perform the training process. This function will block (not return) until the training process has finished.\n","\n","```\n","...\n","# fit the model\n","model.fit(X, y, epochs=100, batch_size=32)\n","```"],"metadata":{"id":"a9pZMVNXlkJt"}},{"cell_type":"markdown","source":["While fitting the model, a progress bar will summarize the status of each epoch and the overall training process. This can be simplified to a simple report of model performance each epoch by setting the “verbose” argument to 2. All output can be turned off during training by setting “verbose” to 0.\n","```\n","...\n","# fit the model\n","model.fit(X, y, epochs=100, batch_size=32, verbose=0)\n","```"],"metadata":{"id":"FoLIN4hymPeV"}},{"cell_type":"markdown","source":["### 2.1.4 **Evaluate the Model**"],"metadata":{"id":"BMs1LQqa3dSI"}},{"cell_type":"markdown","source":["The speed of model evaluation is proportional to the amount of data you want to use for the evaluation, although it is much faster than training as the model is not changed.\n","\n","From an API perspective, this involves calling a function with the holdout dataset and getting a loss and perhaps other metrics that can be reported.\n","\n","```\n","...\n","# evaluate the model\n","loss = model.evaluate(X, y, verbose=0)\n","```"],"metadata":{"id":"w7DU4UJV3pMY"}},{"cell_type":"markdown","source":["### 2.1.5 **Make a Prediction**"],"metadata":{"id":"0ECQZWOF4BWA"}},{"cell_type":"markdown","source":["It requires you have new data for which a prediction is required, e.g. where you do not have the target values.\n","\n","From an API perspective, you simply call a function to make a prediction of a class label, probability, or numerical value: whatever you designed your model to predict.\n","\n","You may want to save the model and later load it to make predictions. You may also choose to fit a model on all of the available data before you start using it.\n","```\n","...\n","# make a prediction\n","yhat = model.predict(X)\n","```"],"metadata":{"id":"UWm8M2fk4LfP"}},{"cell_type":"markdown","source":["## **2.2 Sequential Model API (Simple)**"],"metadata":{"id":"XmafvkUm4UUo"}},{"cell_type":"markdown","source":["It is referred to as “**sequential**” because it involves defining a [Sequential class](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) and adding layers to the model one by one in a linear manner, from input to output.\n","\n","The example below defines a Sequential MLP model that accepts eight inputs, has one hidden layer with 10 nodes and then an output layer with one node to predict a numerical value."],"metadata":{"id":"_bNb5Gif4pOH"}},{"cell_type":"code","source":["# example of a model defined with the sequential api\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","# define the model\n","model = Sequential()\n","model.add(Dense(10, input_shape=(8,)))\n","model.add(Dense(1))"],"metadata":{"id":"JHDPScGD45H6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the visible layer of the network is defined by the “**input_shape**” argument on the first hidden layer. That means in the above example, the model expects the input for one sample to be a vector of eight numbers.\n","\n","The sequential API is easy to use because you keep calling **model.add()** until you have added all of your layers.\n","\n","For example, here is a deep MLP with five hidden layers."],"metadata":{"id":"_SpGvJTr5E3P"}},{"cell_type":"code","source":["# example of a model defined with the sequential api\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","# define the model\n","model = Sequential()\n","model.add(Dense(100, input_shape=(8,)))\n","model.add(Dense(80))\n","model.add(Dense(30))\n","model.add(Dense(10))\n","model.add(Dense(5))\n","model.add(Dense(1))"],"metadata":{"id":"UwrEG43k5O9Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **2.3 Functional Model API (Advanced)**\n","\n","The functional API is more complex but is also more flexible.\n","It involves explicitly connecting the output of one layer to the input of another layer. Each connection is specified."],"metadata":{"id":"DDPAzO0u5ZmF"}},{"cell_type":"markdown","source":["1. First, an input layer must be defined via the Input class, and the shape of an input sample is specified\n","```\n","# define the layers\n","x_in = Input(shape=(8,))\n","```\n","2. Next, a fully connected layer can be connected to the input by calling the layer and passing the input layer. This will return a reference to the output connection in this new layer.\n","```\n","...\n","x = Dense(10)(x_in)\n","```\n","3. We can then connect this to an output layer in the same manner.\n","```\n","...\n","x_out = Dense(1)(x)\n","```\n","4. Once connected, we define a Model object and specify the input and output layers. The complete example is listed below."],"metadata":{"id":"NcuqQfkX51dn"}},{"cell_type":"code","source":["# example of a model defined with the functional api\n","from tensorflow.keras import Model\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import Dense\n","# define the layers\n","x_in = Input(shape=(8,))\n","x = Dense(10)(x_in)\n","x_out = Dense(1)(x)\n","# define the model\n","model = Model(inputs=x_in, outputs=x_out)"],"metadata":{"id":"nVKcksd35uFF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. How to Develop Deep Learning Models\n"],"metadata":{"id":"EUqd7wPL8o8G"}},{"cell_type":"markdown","source":["## 3.1 **Multilayer Perceptron Models - MLP**\n","There are three predictive modeling problems you may want to explore with an MLP; they are binary classification, multiclass classification, and regression."],"metadata":{"id":"CuT1SCwQ9ggF"}},{"cell_type":"markdown","source":["### 3.1.1 **MLP for Binary Classification**\n","\n","We will use the Ionosphere binary (two-class) classification dataset to demonstrate an MLP for binary classification.  This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n","\n","- [Ionosphere Dataset (csv).](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n","- [Ionosphere Dataset Description (csv).](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n","\n","We will use a [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to encode the string labels to integer values 0 and 1. The model will be fit on 67 percent of the data, and the remaining 33 percent will be used for evaluation, split using the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.\n","\n","It is a good practice to use ‘***relu***‘ activation with a ‘***he_normal***‘ weight initialization. This combination goes a long way to overcome the problem of vanishing gradients when training deep neural network models. For more on ReLU, see the tutorial:"],"metadata":{"id":"i3MDO1CQ8_-G"}},{"cell_type":"markdown","source":["The model predicts the probability of class 1 and uses the sigmoid activation function. The model is optimized using the [adam version of stochastic gradient descent](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) and seeks to minimize the [cross-entropy loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)."],"metadata":{"id":"hbqnLJKf-_Pc"}},{"cell_type":"code","source":["# mlp for binary classification\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n","\n","# make a prediction\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etCpM9rM_NCr","executionInfo":{"status":"ok","timestamp":1651163215517,"user_tz":-480,"elapsed":2892,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"c9245e49-2551-4e34-e6b1-b8eae451c16f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(235, 34) (116, 34) (235,) (116,)\n","Test Accuracy: 0.974\n","Predicted: 0.996\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"TVpiF087G2ja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.2 **MLP for Multiclass Classification**"],"metadata":{"id":"R1aiCt8dGUfE"}},{"cell_type":"markdown","source":["We will use the Iris flowers multiclass classification dataset to demonstrate an MLP for multiclass classification.  This problem involves predicting the species of iris flower given measures of the flower.\n","\n","- [Iris Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv).\n","- [Iris Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.names)."],"metadata":{"id":"E_A10wGEGiIk"}},{"cell_type":"markdown","source":["Given that it is a multiclass classification, the model must have one node for each class in the output layer and use the softmax activation function. The loss function is the ‘***sparse_categorical_crossentropy***‘, which is appropriate for integer encoded class labels (e.g. 0 for one class, 1 for the next class, etc.)"],"metadata":{"id":"k7fuD5yPG3cC"}},{"cell_type":"code","source":["# mlp for multiclass classification\n","from numpy import argmax\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(3, activation='softmax'))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n","\n","# make a prediction\n","row = [5.1,3.5,1.4,0.2]\n","yhat = model.predict([row])\n","print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2FZ0ianG89p","executionInfo":{"status":"ok","timestamp":1651165123522,"user_tz":-480,"elapsed":2238,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"5688e5ec-9f47-4164-ad39-953f98a905c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 4) (50, 4) (100,) (50,)\n","Test Accuracy: 0.960\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13d4912c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predicted: [[0.95480573 0.0392486  0.00594568]] (class=0)\n"]}]},{"cell_type":"markdown","source":["### 3.1.3 **MLP for Regression**\n","\n","The regression problem involves predicting a single numerical value. As such, the output layer has a single node and uses the default or linear activation function (no activation function). The mean squared error (mse) loss is minimized when fitting the model."],"metadata":{"id":"sQgaS-uFHzmK"}},{"cell_type":"markdown","source":["We will use the Boston housing regression dataset to demonstrate an MLP for regression predictive modeling.\n","\n","This problem involves predicting house value based on properties of the house and neighborhood.\n","\n","- [Boston Housing Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv).\n","- [Boston Housing Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names).\n","\n","\n","[**Difference Between Classification and Regression in Machine Learning**](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)"],"metadata":{"id":"i1u9faXoICRQ"}},{"cell_type":"code","source":["# mlp for regression\n","from numpy import sqrt\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='mse')\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","error = model.evaluate(X_test, y_test, verbose=0)\n","print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n","\n","# make a prediction\n","row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yo2NI9p8IfdK","executionInfo":{"status":"ok","timestamp":1651165540739,"user_tz":-480,"elapsed":3623,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"4407a516-d45f-47ae-8b59-b57280dc851a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(339, 13) (167, 13) (339,) (167,)\n","MSE: 49.623, RMSE: 7.044\n","Predicted: 24.917\n"]}]},{"cell_type":"markdown","source":["## 3.2 **Convolutional Neural Network Models**"],"metadata":{"id":"DMlyP39dngto"}},{"cell_type":"markdown","source":["They are comprised of models with [convolutional layers](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/) that extract features (called feature maps) and [pooling layers](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/) that distill features down to the most salient elements.\n","\n","CNNs are most well-suited to image classification tasks, although they can be used on a wide array of tasks that take images as input.\n","\n","A popular image classification task is the [MNIST handwritten digit classification](https://en.wikipedia.org/wiki/MNIST_database). It involves tens of thousands of handwritten digits that must be classified as a number between 0 and 9.\n","\n","The **tf.keras** API provides a convenience function to download and load this dataset directly.\n","\n","The example below loads the dataset and plots the first few images."],"metadata":{"id":"56b8Z-u4n6JL"}},{"cell_type":"code","source":["# example of loading and plotting the mnist dataset\n","from tensorflow.keras.datasets.mnist import load_data\n","from matplotlib import pyplot\n","\n","# load dataset\n","(trainX, trainy), (testX, testy) = load_data()\n","\n","# summarize loaded dataset\n","print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n","print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n","\n","# plot first few images\n","for i in range(25):\n","\t# define subplot\n","\tpyplot.subplot(5, 5, i+1)\n","\t# plot raw pixel data\n","\tpyplot.imshow(trainX[i], cmap=pyplot.get_cmap('gray'))\n","\n","# show the figure\n","pyplot.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"5VpB4kPzoTwp","executionInfo":{"status":"ok","timestamp":1651240980119,"user_tz":-480,"elapsed":5732,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"35c4962b-73a3-42bd-cd69-fc1d6770ef3e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Train: X=(60000, 28, 28), y=(60000,)\n","Test: X=(10000, 28, 28), y=(10000,)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 25 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV8AAAD8CAYAAADQSqd1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeVSb15n/P68WtCEQ+25kVhvjBe/gldhpbMfZ00kySdNO0jTttDmd/noy09Nm2s7S0+lMJjOTdqbTpFmadmaapZPFtePYjpd4iwHbYGwwBrODWCQWCZAQku7vDxuNCXZsQEgC9DnnPcdIr+77vF8/93nve+9z75WEEIQIESJECP8iC7QBIUKECDEXCQXfECFChAgAoeAbIkSIEAEgFHxDhAgRIgCEgm+IECFCBIBQ8A0RIkSIADCl4CtJ0jZJkmokSaqTJOl7vjJqphPSZTwhTcYT0mQ8c0kTabJ5vpIkyYFLwO1AK1AKPCKEqPKdeTOPkC7jCWkynpAm45lrmkyl5bsaqBNC1AshnMDvgXt8Y9aMJqTLeEKajCekyXjmlCaKKfw2BWi55u9WYM3n/UCSpKCcTieEkHxY3IR0CVZNALMQIs5HZYU0GU+o/oxn1mjCLfjKVILvLSFJ0teAr033dWYSM0STJn9eLKTJ9ZkhuviVGaLJTX1lKsG3DUi75u/Uq5+NQQjxEvASBPVTypfcVJeQJiFNCNWf6zGnNJlKn28pkC1J0nxJksKAh4EPfGPWjCaky3hCmownpMl45pQmk275CiFckiR9C/gIkAOvCiEu+MyyGUpIl/GENBlPSJPxzDVNJp1qNqmLBekrgo8H3CaErzWJjY0lOTmZZcuWsXz5clpbW6mrq+P06dO0t7fjdrtvtajTQoiVvrTtVglWPyGAmkDw6jKb6o8PuamvTPuAm6+RJAmZ7P96S8LCwoiMjEQmk6FUKnG73XR2dpKYmIhOp0Or1eLxeLBYLPT392O1WgNo/fSi0WjIy8ujoKCArVu3snXrVi5dusTZs2dRqVT88Y9/ZHBwMNBmBhU6nY7o6Gh0Oh0NDQ04nU7m6hrXERERREZGEhd3ZZDeYrHQ3d3N0NBQgC2bpQgh/HYAYiqHTCYTarVaREdHe4+lS5eKH/7wh+If/uEfxGuvvSZefPFFkZycLH7+85+LyspK4fF4hN1uF//+7/8utm/fft1y/amBrzW5VpslS5aId999V1itVuFyubzH8PCwsFgsYt68eRMps2yma3IrR1FRkfjlL38pzpw5I3Jzc4VKpQpKTfyhy/bt28V//Md/CLfbLYQQ4tVXXxWrV6++6e9msyZTOG7qK0HZ8pXL5SQkJKBQKIiPjycjI4OlS5cSHh5OWloaBQUF3nMVCgVarRZJkhgcHKS7u5sf/ehH3H333YSHh9Pf309tbS2lpaU0NDQE8K6mD4PBQFZWFi+++CI5OTlotVoAhoaGcLlcSJKEXq9n8eLF3jcDl8sVYKsnRnp6OklJSURERHD06FHsdrtPys3NzUUIQU1NjU/Km4lIksTOnTt57LHH2Lx5M0IIPB7PaHALMU0EXfANDw8nJSWFr3zlK2g0GiIiIoiJiSElJYWwsDAMBgMpKSnX/W11dTWVlZWYTCb27duHy+XCZrPR2trK2bNn6erq8vPdTC9KpZLo6GgWL17Mzp07ycnJQa/XI0kSQggsFgs1NTU4HA527tzJ448/TmZmJiUlJXz66aeBNn9CJCYmkp+fT1xcHKdOnfJJ8JUkifj4eAwGA2q12gdWzlySk5O9WgghvD7k8XgCbdq0EhsbS2JiIkajkbS0NAwGAyqVCiEEhw4dwmq1IpPJSEpKorq6mu7ubmw2m0+uHXTBV6vVkp6ezlNPPUVERARyufy65w0PD+N2u5HL5ahUKtxuNxUVFezduxeHw8HJkycZHBzEZrNhtVppb2/H6XT6+W6mj1GHyMvLY9OmTXzxi1/EYDAgSf839jE0NERFRQVms5ktW7bwwAMPEBcXhyRJMy74Jicnk5+fT0xMDGFhYVMuT5IkFAoFKSkpxMbGMjIywsjIyJxr7clkMjQaDampqURGRiJJEiMjI5jNZiwWCyMjI4E2cVqQJAmtVkteXh5LliyhsLCQgoIC4uLivG/SERERdHV1IUkSeXl5vPvuu1RUVMze4Guz2Whvb6e3txedTnfd4OvxeKisrMRmsxEeHs7SpUsZGRnhzJkzfPDBrE0LHINOp+Pv/u7v2Lp1KwkJCdc9Jzc3l7KyMjo6OigpKWHt2rXExsaSkZHhZ2unzrJlyyguLubcuXM+KW+0S+uee+6ht7eXAwcOUF9f75OyZxIGg4GVK1fy2GOPER8fz/DwMI2NjTz55JNcvnyZgYGBQJs4LYSFhXHnnXfyzDPPkJ+f731jrKqqoq+vD4PBwLe+9S1v/JEkiaioKF5//XWf+UnQBV+Hw0FbWxsvvPAChYWFuFwurFYr3/rWt5AkCZvNRkNDA9/85jexWq2o1Wqys7O59957aW5uDrT5fiEqKorc3Fw2bNhAVFQUkiTh8XioqKjgwoULaDQaHnjgASwWC42NjZSXl2Oz2ViyZMmYlvFMQpIkn9qelJTEc889h8FgoKGhgba2cROpZj1Go5G1a9fy7W9/m/j4eJRKJSaTid/85jfU19fT19c367odZDIZMTEx5Obm8td//dekpaUxPDxMSUkJb7zxBpWVlfT29qLRaPjJT37C4sWLSUxMBKC2tpbu7m6f2RJ0wVcIweDgIEePHvW+9jgcDoqLi8nIyMBsNnPy5EkuXrzI0NAQCoXCK8hcaLkYDAaWL1/O9u3biYuLQ6lUMjg4iMlk4q233qK/v5+4uDiSkpI4ffo0n376KZcvX6a7uxuHw4HBYCA9PZ24uDh6e3tnxMBbdHQ0ERERaDQan5UZFhZGVlYWSqWSnp6eOfPgvpbMzEwKCgpYsGABYWFh9Pf3U19fz+HDh7HZbBPJCZ8xzJ8/n4KCAm886evr48KFC+zZs4fDhw/T3t4OQEZGBpGRkd4uTbvdTmVlpfd7XxB0wRfA6XRy/vx56uvrcbvdhIWFceLECaKjozGbzXz66ac4HA48Hg9OpxOTycQf/vCHQJs97cjlctLT09myZQtPPfUUarUaj8eD2WympKSEl19+mfT0dIxGI/39/fzhD3+gp6cHh8MBXNE1NTWV/Px8cnNzOXv27IwIvvPmzSM+Ph6dTueT8kb7e3U6HTKZjO7ubmpra31S9kxBkiQWLVrE8uXLiYiIQAhBW1sb5eXllJWVBdo8nzPax7t27VruvvtuHnjgAex2O9XV1Xz00Uf8+te/9naxpKSkUFhYSF5eHjqdjuHhYVpbWyktLfXpG1JQBt9RRpO7FQoFVqsVt9tNeno6Dz30EG+//faMCBy+QqlUkp6ezpe+9CU2bNiATqejp6cHi8XC2bNn+d///V+sVivl5eVUVFQAXHfwSKFQEBsby9NPP80PfvCDoJ90IUkSGzduxGg0+mSgDa5k1CQkJDBv3jzkcjk2m82nr5MzgejoaIqLiykuLsbj8WC1Wtm7d++sbcQYDAa+853v8OSTT5KQkIDdbueNN97glVde8b5Fj5KWlsYzzzzjzYBpb2/nueeeo76+3mcpjhDkwXcUh8PBG2+8QXJyMqtXr2bZsmWsWLGCCxcu0NvbG2jzph2ZTEZ0dDR//ud/zh133EFCQgIWi4V//Md/pK6uzjsyPdo/d7MRe7lcTlJSEkql0h/mTwlJkkhJSUGv1+N0OmlsbJzyQ3f9+vXcfffdREVF0dXVhcVi8WmlCmbUajVxcXH84Ac/YOnSpd7xgt27d3P48GGqq6sDbaLPWbp0KZs2beKxxx4jIiICk8nE+fPn+dWvfkVjY6P3zVCpVHq7YhITE5HL5ZSWlnLw4EGOHj3qPc9XzIjg63a7qaur49ixY4SHh3unzkZFRdHW1obVaqWhoWFW9lHBlfS7pKQkNmzYwLx58+ju7qakpISPP/6YtrY2hoeHkcvlt5wmJZPJUKlUM2bwTavVolAocDqdNDc3Tzj4yuVy1Go1MTExpKamUlxczOrVqwkLC6OyspLm5maGh4enyfrgQqfTkZGRwcaNG4mLi8PpdNLd3c2RI0eora31WRpVsKBQKMjJyaG4uJj09HQ6Ojo4e/YsH374ITU1NTidTuRyOXq9nrVr17JkyRKWL1+ORqOhvb2dkpISPvnkE8xms+9t83mJ08Tw8DDvv/8+QgjWrVvHE088QWFhIfX19Vy6dIlXXnmFwcHBWRmAY2NjWbBgAQUFBXg8HsrKyviXf/kXysvLA22aX3E6ndTX14/LPb02E0Iul3v/LUkScrkcrVZLfHw8K1eu5O6772bp0qXMmzcPgD179lBeXj4nWr4ymYy4uDhWrVqF0WhEqVRiNpspKytj7969s24SElx5cC9cuJANGzYghOD8+fO8++67vP766ygUClQqFXq9nvT0dH74wx+Sm5vrnWhSUlLC3r17OXLkyLTYNmOCL0BnZycfffQRDoeD559/ng0bNrB582ZcLhfh4eEcOnSI6upqLBZLoE31KcXFxXz9619HkiTOnTvHyZMnKS0tnXA5o0FqprR4P4tcLicqKmrMwkpwZdReq9USFhZGUVERcXFxaDQaVCoV9957r7eveHQg1+12e1s81dXVdHZ2BuJ2/M7q1au58847+cY3voFSqaS2tpZPPvmEn/zkJ5hMplmXVgZXuhLCw8MxGAwA/PznP6eiooLU1FQefPBBCgsLycjIYN68ed60Tbgyl+CDDz6gurra590No8yo4CuEoKuri8OHD/OjH/2IO+64g/z8fObPn8+f/MmfkJSUxPHjx/nwww9nTY5ifn4+ixcvxmg0AlBZWUlDQ8Ok7m10QY+RkREaGxtnzIw/p9OJy+UiOTmZp59+mg0bNozpJsjJyUGj0SCXy4mOjkYmk+FwOOjp6eH06dN0dnbS0dFBQ0MDTU1NPPHEEyQkJCCEwGQyzeqV7uDKQzc2NpYvf/nLbNq0Cb1ej0wmo6+vD5PJRFdX16yoK9fD5XJht9sZGBggPDycZ599lv7+fiRJIi0tzTtj0uPx0N/f782AsVqtlJWVTevbwIwKvgB2u52Wlhb27NmDEILe3l7sdju5ubl4PB5UKhXd3d0+XXwlkCQmJhIXF0dkZCROp5Pq6mpaWlpu/sOrSJKESqUiNTUVhULB0NAQnZ2dlJWVzYilAoUQXLx4EaPRiEql8uZfXtu9lJqaitvtxmazYbPZ6O3tpa+vj66uLi5dukR7ezsmk4n6+nq0Wi1DQ0NIkoTdbsdms82Yh9BkUSgU5OXlsWrVKnJzc72ft7S0UF9fP6v7u0dGRmhubqa8vJy1a9eybt063G43DocDi8WCyWSiv78fm81GXl6edxC6qamJ9vb2aa0jMy74wpUK2dTUxBtvvMH+/ftZt24dL774Ivn5+RiNRtLT06msrJwVwVepVKJSqZDJZJjNZk6dOjWhnFSFQkFycjJPPfUUer0ek8nEyZMneeWVV2ZM8H355ZdpaGhg/fr1LFmyZNw5JpOJhoYGysvLuXTpEtXV1ddtzUqSxJ133klubi4qlYqWlpZZOUbwWdRqNQ899BDx8fFjMmKOHj3KoUOHAmzd9DI0NMTevXvp7u7mV7/6FZGRkQwMDNDW1sa+ffvYu3evdxD35ZdfJioqiqGhIQ4fPjzt61rMyOA7ytDQEA0NDXR0dPCzn/2M8PBwdDoda9asoaioiJKSkgm1EoMZIQROpxOz2XzLI9JKpZKtW7eybds2nnjiCWw2G4cOHeKdd95hcHBwRi0ic+TIEU6cOHHDhZY8Hg8ulwu3233DgCpJEmvXriUpKQmr1cru3btnxANoKkRHR7NgwQI2b97s7fd0u918/PHHlJeX+3TGVrBiMpnYu3cvixYtGrNam9PpZGRkhKioKBYvXkxhYSEajYbe3l6am5un/cE8I4OvJEkkJiaSmZlJYmIiSUlJ3pWIRkZGsFgsNDU10dfXF2hTfcbw8DDnzp27paCpUqmIj4+nuLiY2267jUWLFlFbW8urr75KeXk5ly9fnlGBF/CuOjZVlEolMpmMwcFBSkpKZvUrN1zJcX3iiSdITEwkLCyMwcFB2traeO2116ivr5+1fb3XMhpoe3p6rvu9JEmo1WoUCgWSJNHf309JScm0T+KaUcFXqVSi1WoxGAwUFBSwfPlysrKyMBqN3tkoIyMjdHV1YTKZZlXOosfjobe396aVJTIyksTERJYtW8Z9991HTk4OcrmcXbt28d///d83dMC5xvDwMA0NDbN+lmRmZiY7d+4kPDwcgP7+fiorKzlw4MCsqh9TweVyMTQ05G2QDA0NUVdXF2r5XstoULnzzjvZsWMHsbGxqFQq7/ejT7ju7u5ZU6lkMpl3XvrmzZu9lehGbNiwgTvuuIPHHnsMvV5PWVkZ+/bt44c//KGfLJ4ZzNR0u4miUqm8azcIIWhubuYPf/jDrF04ZzJYLBZKSkr8rkfQB9/RmUlf+MIXvIMlaWlpaLXaMfmeVVVVHDx4kGPHjk3bjJRAMLqdy2iC/De/+U1OnDjB6dOn6e/vJzMzk7y8PNasWUN2djapqanodDqsVisnT57k448/5vjx44G+jaBiNANk/vz5VFZWztquh7/4i79g586dyGQyPB4PkiTR19fH2bNn50R3w60SFxdHQUHBDccTpougDL6jLb3RwYLRFJEFCxYQExPj3aOsp6cHk8lEZWUlx44do7q6moaGhlmbNK9UKtmwYQPJycksXbrUG3xTU1O9y0Ta7Xa6urqoq6vjrbfeoqamhtbW1kCbHlSMvl6GhYXNyhawXC4nLi6O5cuXYzQaEULgdru5ePEi58+fp6enZ8b1+U8nGo2G5ORkv/tCUAVfmUyGTqcjIiKChIQEMjIy2LBhA3fddRfp6enAlZagw+Ggv7+fmpoazp07x65duzh69OisbME4nU4cDgdOp5OwsDDy8vKYP38+hYWFDA4OEh8fj0ajwe12Mzg4SG1tLZcuXfJOo5yu2TkzndHtc2Zr8E1OTiYrK4u4uDiEEAwPD3Py5ElKSkpm7e4Uk0UmkwVkD7+gCr56vZ57772X+++/n7y8PFJTU8ctI9jb28v58+f55S9/SWlp6azbm+2zXLhwgYqKCvLz8705rlqtFq1WS2xsLHAlQPf19fHuu+/y8ssvz7k1HyaDRqOhoKCAt99+O9Cm+ByZTEZERATR0dHodDo8Hg9dXV289tprM27vPn/Q29vLmTNnAN/vmPJ53DT4SpKUBrwBJHBlP/qXhBD/JknSj4GngNGFUL8vhNgzUQOSk5PJzs7mrrvuYuHChRiNRpKTk1Gr1WOWPBweHubjjz/m6NGj7Nmzh9bWVoaGhgKywd90a3ItZrOZd955h8rKSu677z4eeOABYmJiRu3gwIEDlJSUcPz4cS5cuBCwvm5/ajJV/FnBZpIu/iLYNLHZbNTW1tLc3ExycrJ3Rmhvb++0DsLdSsvXBXxXCHFGkiQ9cFqSpP1Xv/sXIcTzUzEgOTmZ5cuXs2XLFlJSUggPD0epVNLf3+9dLnF0c8zS0lKqqqq4dOlSoFu706rJmAu5XHR0dGC325HL5ZjNZiIiIrzfl5eXU1tby8WLFwM9yOg3TaZCS0sLNpuNyMhIf13S77qMpiV2dnYSHx+PXq/39SWmSlD5isfjYWhoiBMnTlBcXExUVBSbNm2is7OTnp6eaevOvGnwFUKYANPVf9skSaoGUnxlQFxcHPPnzycpKcm7ov7IyAgNDQ2cPHmSvr4+7HY7r7/+etCkx0y3Jp9leHiYrq4uPvzwQz788MPpusyU8Lcmk0EIwblz51iyZAlqtRqbzTbtA0+B0MXlcmEymTh37hwqlYp58+ZhsViCJv0yGH3F5XKxZ88eMjMzyc3N5b777qOiooKqqqrpW1xnNP/vVg7ACDQDEcCPgUbgHPAqEHULvxefPSRJEjKZTMjl8jGHTCYTMplMSJIkJEka9ztfHhPRwB+aBMlRNhs1udbfZDKZ3zQJhC6jdWiS9zrn6k9ERIT4m7/5G1FaWiqcTqd49913xc6dO4VarZ6W+jMRkcKB08D9V/9OAOSADPgJ8OoNfvc1oOzqMW0OEAjnmc2a3IrzhDQJ6cIsqj9yuVwsWLBAPPLII+Ldd98VLS0t4rvf/a5ISUmZFl+5VZGUwEfA/7vB90bg/C2UE3BH8ZXzzHZNbsV5QpqEdGGW1Z+wsDBhNBrFn/3Zn4nXX39dfPGLXxTx8fHT4iu3IpLElZHJf/3M50nX/Ps7wO/nivPMBU1uxXlCmoR0IVR/Ju0r0tUbuCGSJK0HjgKVwOicxO8DjwDLrl6oEXhaXOlI/7yyuoFBINBzf2OvsSFdCBE3kR/PAU1ggrrMUk0guHzFBtRM5PrTRDBpEiy+MuH6c9Pg62skSSoTQqz060WD0IZrCQZ7gsGGawkWe4LFDggeW4LFjlGCwZ7J2CC7+SkhQoQIEcLXhIJviBAhQgSAKQVfSZK2SZJUI0lSnSRJ37vFn700lWv6iGm1YRK6hDTxsz0TYNrsCGkynrkUUybd5ytJkhy4BNwOtAKlwCNCiKpJFThLCOkynpAm4wlpMp65pslUWr6rgTohRL0Qwgn8HrjHN2bNaEK6jCekyXhCmoxnTmkyleCbAly7NXArnzM/++rrhAjSY8cUdJi0LkGuicuHukzUVwJ978GoSTD7SkiTSfjKtA+4SZL0NUmSyoD3pvtak0X4eSm/maAJUO5PXUY1uapLsOJXTWBm+EpIk+tyU1+ZSvBtA9Ku+Tv16mdjEEK8BDwDHJnCtWYSN9UlpMn1NbmaJ/mMPw0LIKH6M545pclUgm8pkC1J0nxJksKAh4EPbnDuZ18nggpJkqJ8WNyt6hLUmgBGH+oyUV8JVgKpSdD6SkiT63JTX5l08BVCuIBvcWVxjGrgLSHEhcmWF2D+2VcFzSJdRvCRLiFNxjOLNIGQJtfjpr4ypT3crvZp3Ep/z2dfJ4KN1b4s7BZ18YkmmzZtIj8/nwULFngXXK+pqcFms0216G58qMsEfSVYCaQmc6L+zARNIiIi+MpXvoIkSVRUVHD48OHrnXZTX/HXBpqlQLavC5UkCZlMhkwmQ6/Xo1AocLvdk9ka+7yvbbsFpqxJWFgY69evZ9u2baxbt46Ghgba29vp6OjwRfA1ACemWsgkKJ3Kj1UqFZIkoVAo0Gq1JCcnI5Pd+AXParVisVjo6+u7FZ8JpCY+qT8KhQKNRkNCQgIdHR2+2sl4RtafyRAREUF2djZ/+qd/itVqxel03ij43txXJroc3GQPYAc+XrZNo9EIg8EgkpOTxeOPPy6+853viK9+9atCpVJNtKwkf+ngK01kMplIT08Xe/fuFTabTbjdbuF2u8Xf/d3fiZUrV/pC374A6jIpm+VyucjJyRF5eXli8+bN4i/+4i/E8PCw8Hg8Xn0+e3z00UfikUceEUqlMtg1mXL9kcvlIikpSdx+++3i8OHDori42Fd1ccZqMtFj27Zt4pVXXhF2u128/fbb4uGHH560r/ht63ghxB7JBzvGjj61v/zlL5Obm0tqaippaWloNBpkMhlms5nU1FT+9V//lb6+vlu17XOXrZsupqKJEIKenh4qKytJSEjwbivvQ+oCpctEmTdvHnl5eaxdu5Y77rgDuVyOTqcjLi4OhUIxWlGvS1FREUqlEqPRyM9//nOGhobweDw3Oj1gmvii/mi1WjZv3sw///M/43K5SExMJDIykv7+/qnaNmM1mQhPP/00O3bsoKioCJfLxZkzZ2hoaLjR6Tf1Fb8F36kgSRIxMTHk5eWRmZnJkiVLKCwsJD4+Hp1Oh1KpxOl0otFoSE5OZsOGDbz11ls4nU6GhoYCbf60IITA4XBgNpunXHlmOuvWraOoqIhVq1aRk5MzptthlBsFYI1GQ25uLsPDw7z99ts0NzcHemfsaUOSJHQ6HYmJiQwODhIZGYlOp5vz/nOrLFiwgPT0dLRaLc3NzZSXl9PU1DTp8oI6+EqShEajISIigkWLFrF9+3ZWrVrFqlWrCAsLw+Px0N/fT3V1NXa7nezsbBITE1myZAlJSUl0d3fP2uAL4Ha7GR4enrXB4lZZtmwZhYWFLFu2DLiyFfjIyAi9vb1IkjQm8KpUKsLCwpDL5d7PEhISyM/PJyEhAZPJNOv1lCSJ8PBwwsPD0Wg0gTYnoISFhaFWq9FqtXR3d193d3SZTIZWqyU9PZ3IyEgcDod3Z+OOjo5JXzuog69Op2P9+vU89NBD3HPPPeh0ujGVprOzk2PHjvG9730PpVLJj370Ix555BGioqKIjo5GrVYH0PrpRZIk9Ho9GRkZpKQEc2rs9HP27FmMRqM3+FqtVmpqajh48KB3sM3j8SCTyVi5ciULFy4kOTk5kCYHBf58ZQ9WFixYQFFRETt27OBrX/saFouFkZGRMedERkaybds2Fi1ahEKhoKqqip/+9Kd0dnZO6dpBHXxXrVrF9u3b2blzJ+Hh4d6KJISgvb2dX/ziF+zfvx+TyURqamqArfUvkiShVquJjY3FYDB4P09LSyM7O5vW1lY6Ozs/t79ztrB//34qKyt59dVXAXA6nfT29tLR0TGm5TvaffXtb3+be++9l6ioKznwDQ0NfPrpp1RVVeFwOAJ2H/5GoVCgVCoDbUZA+dKXvsSWLVtISUkhMzOT4eFhent7x5wTExPDV7/6VZKTkzl06BBvv/02NTU1DA8PT+naQR188/LyyMnJ8VaSoaEhBgcH6enp4cMPP+To0aPU1dXhdDoxGAyoVKoAW+w/hBDY7XZaWlro6OggMTERgEWLFmGz2Whvb8dsNuNyuQJs6fTT09PD4OAgbW1XUoRHux3sdvu4cyMjIwHGpJ/ZbDZvet71XjtnG6MPI4PBQHR0dICtCSzR0dHExsZ6u2EUirEhMTw8nMTERLKyslCr1QwNDWE2m33ykA7q4JuWlobBYGBwcJCRkRFMJhMmk4mamhp+8Ytf0NnZid1uR5IkEhIS5lT/lRACq9VKWVkZSUlJ3lfugoICdDodVVVVnDp1amGiucwAACAASURBVE4E39HBx8+rEJIkoVKpWLp0KSkpKWN8xWq10tHRMSe0git6SZJEXFwcCQkJgTYnYGi1WiRJwu123/D/Pj4+noyMDKKjo3G73YyMjHxeNsyECOrg+8ILL3Do0CFWrVrF4cOHaW9vp7e3l/7+/nECxMTEjBndniu88847yOVyHn300UCbEtTEx8dTXFzMo48+Sn5+PmFhYd7vjh49yksvBcNmCNOL2+3G4XBgs9mIiIggLi7O+8Y019BqtTz77LNs2LCByMhI6urqqKqqwmq1jjlny5Yt3H///Wg0GioqKvjkk084ePCgT2wI6uDb29tLSUkJFy9epK+vj+Hh4es+eSRJIjc3d06+Qo0mbMtkMjweD5IkhQZSriKTydi4cSObNm1i0aJFZGdnk5KSQnh4uPecpqam6w6yzEYcDgednZ1cuHCBNWvWBNqcgDGaknrXXXcRExPDxYsXefnllzGbzd5MF0mS+LM/+zN27tzJsmXLsFgsPPfcc5SXl/vsDSmog+9outC1HeB6vZ6kpKQxfXZyuZz09HTCw8Nxu9309vZiNpuv2+cXYvahVqsxGAzExsYSFxfn/VyhULBjxw4KCwsxGo1ERUUhl8vxeDxYrVZqa2s5c+YMNTU1c6Kv1+12Y7fbb3Uq9awkPDycrKwsCgsLmT9/PhaLhcrKSk6cOIHD4UAIgVarxWg0snXrVvLy8lCr1Zw6dYozZ85MOcPhWoI6+F6LTCZDoVCQnp7O9u3bvf01o2RnZ6PX6xkaGqKyspKamhosFksALfYvo28D10y9nBPIZDJvbndRURHr1q3zfieXy1m1ahUymWyMJsPDwzQ3N/Of//mfHD16lM7OzjnR8v0sn7fmxWxEoVBgNBrZuXMnX/3qV4mMjOTw4cN8+umn1NfXe30kPj6ee+65h82bN3snVLz55psMDg761h6fljYNjC4Ekp2dzaOPPkphYSHLly8H8L5iezwe5HI5AwMDVFRU8Mwzz9Dd3T2ngtBcRKlUkpOTwz/90z+xePFi4uLixgWU6wWYhoYGjhw5wm9/+1vcbvec9ROdTkdERESgzZh2JEkiIiKCu+66i+eee4758+ejVCoRQpCTk8P27duJjIzk5ZdfRqVSkZOTw913341KpeLMmTMcOHCA3/72tz4fkA3a4CuXy0lJSWHt2rVs27aN1NRUUlJSiIiIwGazUVdX532VHM1VHJ0+WVBQgMlkwmq1ztmKNRcYffiq1Wo0Gs11c1Y/2+qFK1k0y5YtIz8/n6qqqlk/o+1GZGZmkpubG2gzpp158+axfPlyvvWtb5GSkoJCocDj8dDV1UVCQgKRkZFkZWWRkpKCXq8nJSWF7OxsHA4H+/bt480335yWTJigDL4KhYLY2Fg2btzI7bffzrZt2+jv76enp4eWlhYsFgv19fVs3boVlUrlfXrL5XKio6PZvHkzlZWVNDc3Y7PZ5kQAHp1MIEkSSqWS6OjoWT/w5vF4GBgYoLKyEkmSSE5OpqenZ8yA7KguKpWK2NhY7wM8KSmJpKQkampqAngH/mdkZMS74FR0dDQxMTEBtmh6iY2NpaCggNtvv50VK1bgdrtpb2+nra2N1tZWli5dSnx8PElJSWi1WnQ6HeHh4ej1eqxWK0qlEo1Gg0aj8fYJ+4qgC74KhQK9Xk9hYSE//vGPMRqNDAwM8Nvf/pYzZ85QW1tLbW0tMTExGAwG4uPjiYiIQAiBWq1m3rx5PPnkk1RVVXHkyBEuXrzI8PDwrA/Ao4FWCIFer2fJkiXjEsZnGy6Xi8bGRn7605+Sn5/P0qVLOXLkyHUrSXJyMjt27OCrX/0qGo1m1vvDjejt7eXcuXM8+OCDgTbFLxQWFvLoo49yzz334HQ6sVqtHDhwgNdee43+/n6+/vWvU1RUxKJFi8jKyhpTjyIiInj66adZvXo1X/va12hubvZpCzioaqdCoWDDhg3ceeedPPnkk+h0OlpbWykrK+OVV17xZj0kJSXx61//mmXLlhETE4PT6eSVV14hMjISo9FIUVERf/u3f0tdXR1nz57l9ddfZ2BgAJfLhcvl4uLFiwG+U99z7UBbTEwMO3bsIC8vj5qamlteWnOm0tnZicVi4fjx44yMjFw3sNbX11NdXc1jjz02pybjfBa73U5bWxtCCO/Sm6mpqbS3t/ts8kAwcf/992M0GqmqquLVV19l9+7ddHZ2eh/Q//Zv/0ZFRQVPPvkkS5cuHbN2DFzxm9LSUhobG32uT9AEX0mS2LJlC9u2beO2225DpVJx4MABTp8+TWlpKRaLhaioKHJzc9myZQuLFy9GJpNRXV3N/v37ef/999FoNCQmJlJRUcGSJUswGAysWbPGG6BH8xy/973vzSpH6+rq4vjx46xZswaZTOadzVVUVITNZpv1wVcIwcjIyOdmLISFhWE0GufcCP9n8Xg8uFwub264TCYbM+FktlFfX09DQwNtbW0cP36c1tbWMWsyXNslJUkShw4dorq6mp6eHgAaGxupra2dlngRFMFXoVAQExPDF77wBTZu3EhWVhaXL1/mo48+ory8nMuXL5OUlER+fj5r1qzh3nvvBaC2tpazZ8/y+9//noqKCmQyGREREVy+fJn29nZWrFjBokWL2LRpE3AlSFVWVgbyVqeF3t5ezp49602rgv+beFJSUhJg66YHtVqNUqlkYGDgpl0I4eHhpKWlsW7dujm/kMzookMOhwONRoNarSYpKYnm5uZZ1SAZpby8nO7uburq6jCbzWO+k8lkxMbGkpiYSExMDCMjIxw9epQDBw541wkZGBjweYrZKEERfA0GA/fffz+PPfYYERERmEwmfvKTn3Dy5Ek0Gg2rVq3i4YcfZu3atcTHxwPw/PPP89FHH1FTU0N3d7e3LLPZjNls5sSJE+Tn51NYWMjdd98NwPHjx/n9738/65xsYGCApqamcUFots52G83XTEpK4tNPP73pQMiqVau44447+OY3vzmnuxwAuru7+eSTT6ivrycrK4u0tDQefvhhn87cCiZ27dp13c9Hl2RdvXo1BQUFaLVaGhoaOHXqFMePH/ePcX7ec+m6+x3l5eWJ6upq4XA4xPDwsOjp6REHDx4Uhw4dEmfPnhXt7e3CarWK4eFhceHCBfHTn/5UJCQkCLVaLWQy2Q33W1IqlUKv14uEhASRkJAgIiMjhUKhGHdeIPafupkmEzkUCoVISEgQVVVVY/Zzs1qt4i//8i9FYmLiZMotCzZNtFqtWLlypXjxxRfF0aNHRUlJiUhOTr7u/6lSqRTR0dHirrvuEv/7v/8r2traxMjIiHC5XMLhcIiKigpRXFws1Gr1jNDEV74CiLCwMPHzn/9cXLhwQezbt08kJyd/bj262TETNdFoNOIb3/iGOH36tLBYLKK5uVmsX79eREVF+UTjW/GVoGj5jm77AldeBdRqNbm5uSiVShwOBxaLhXPnztHU1MSlS5c4deoUZrP5plNCR/sBfbCTb1Djcrno7+/HZDIRGxvrXWAoPDwctVo9a7IeDAYDDz74IBs3biQ1NZWRkRE2bdpEb2/vuFZbZGQk8+bNo6ioyDswK0kSzc3N1NXVefffmo2tvVvBbrfjcrlwOBx0dXXNurfBzyMsLIyYmBiKi4tJTk5maGjIu4aMP2NFUNRKh8PBpUuXUCqVaLVa5HI5SqWSwcFBmpubuXDhAmfPnqW0tJS2tjZ6enrmxFz8ieDxeKivr2f+/PneHN9rWgezgoiICLZt2+Z9MA8MDLB9+/brbnoZFxfHggULWLhwIUIIXC4XVquV0tJSjh075h3BnsuMNnrUajWDg4Ozylc+j6ioKBYtWsSqVatQKBTU1dXx8ccf09fX59eHcVAE34aGBh5++GG+8IUvkJmZSXx8PBaLhXfffZeOjg7ver4hbozb7ebtt98mJyeHefPmBdocvxAeHs6f/umffu45kiRhtVppbW3l+PHjPPfcc/T19YUe3lwZtExJSWHr1q3s2bNnzsz027p1K3/7t39LWloaBw4c4P333+eXv/yl3+24afCVJCkNeANI4EpfxktCiH+TJOnHwFPA6GjX94UQeyZjhMfjYXBwkAMHDnD06FEUCoX3VfpGeZuBxB+aTJTRlm99fT0ZGRl+36PMH5qYTCZ+9KMf8eCDD7JixQpycnKue97oxqnDw8OcO3eOY8eOceHCBWpra/0eeIPRV+RyOVu3biUmJoaqqioaGhrmlCaNjY189NFHPPXUU96NMAPBrbR8XcB3hRBnJEnSA6clSdp/9bt/EUI87wtDRnciniH4RZOJIITAYrGwd+9eGhsbvWsbl5aWMjAw4A8Tpl2ToaEhTp8+jVKppKurC4vFwvLlywkLC8Nms9HV1UVbWxsXL17EbDYzMDBAY2Mj1dXVmEymQK1yF5S+Mjg4SH9/P319fbeUrudjAqpJc3Ozt6V/6NChgHU/3TT4CiFMgOnqv22SJFUDc3q73GDVpLe3lzfffDMg1/aHJiMjI7S2tvL+++/T0NBAU1OTd/+ttrY2ysvLOXnyJKdOnaK9vX3MrgSBIhh9xePxUF5eTl9fH42NjVPeCHKiBFqTlpYWWlpa+OMf/+ivS16fCaZ1GIFmIAL4MdAInANeBaJu8JuvAWVXD1+lcfj0mGKqy6zUhCmkVflLE0mShFwuF3K5XMhkMiGTyYQkSUGpSbD5yqheU0kxGz1miyb+9pWJiBQOnAbuv/p3AiAHZMBPgFdvoYxAC+JT55nNmtyK84Q0CelCqP5M2lduVSQl8BHw/27wvRE4P1OFmqTjzGpNbsV5QpqEdCFUfybtKzddZUS6Mj/1FaBaCPHCNZ8nXXPafcD5m5U1WwhpMp6QJtcnpMt4QppcQbr69LjxCZK0HjgKVAKjmezfBx4BlnElyjcCT4srHemfV1Y3MAiYP+88PxB7jQ3pQoi4zzv5s8wBTWCCusxSTSC4fMUGBMPq78GkSbD4yoTrz02Dr6+RJKlMCLHSrxcNQhuuJRjsCQYbriVY7AkWOyB4bAkWO0YJBnsmY8PcXtw0RIgQIQJEKPiGCBEiRACYUvCVJGmbJEk1kiTVSZL0vVv82UtTuaaPmFYbJqFLSBM/2zMBps2OkCbjmUsxZdJ9vpIkyYFLwO1AK1AKPCKECMxE6SAhpMt4QpqMJ6TJeOaaJlNp+a4G6oQQ9UIIJ/B74B7fmDWjCekynpAm4wlpMp45pclUgm8K0HLN3618zvzsq68TIkiPHVPQYdK6BLkmLh/qMlFfCfS9B6MmwewrIU0m4SvTPuAmSdLXJEkqA96b7mtNFuGnpfxGmQmaAOX+1GVUk6u6BCt+1QRmhq+ENLkuN/WVqQTfNiDtmr9Tr342BiHES8AzwJEpXGsmcVNdQppcX5OreZLP+NOwABIU9Ucmk6HT6Vi7di3r169n2bJl03GZWyUoNPEbk5mXfXWQTgHUA/OBMKACWHSDcx8Efk3g51vf6Lju6knTqcsM0MTsK10m4SuBvvdg1MTnviJJkggPDxf5+fmioqJCNDY2il27dgWs/gSDJv70lUm3fIUQLuBbXFkcoxp4SwhxYbLlBZh/9lVBs0iXEXykS0iT8QSDJg8//DAvvvgi7733Hrm5ufT393P58uXJFDVrNPEhN/WVKe3hJq70adxKf89nXycmhEwmIz4+noyMDNLT08nJyaG1tRWz2czQ0BBCCI4dO8bw8PDoU3GirJ6sbdfjFnWZkiZ+oBsf6jJBXwlWAqmJT3xFoVCg1+t5/PHH2bJlCwsXLiQpKYnu7m4OHjw42QXGZ7Qm08RNfcVfG2iWAtmT+aFarSYqKoq1a9eybNkyFi9ezIoVK6ipqaG1tRWbzYbH46G6uhqz2TzZVfkDsXrSpDXxEwbgRACuW/rZD2QyGVqtFpVKhRACtVqNXC5HLpdjMBgYGhrC6XRed/tzl8vF4OAgDofDFzs2BFKTKfuKUqkkOjqa7OxsHn30UbKyslCr1XR3d1NdXc2xY8c4derUZIqesfUnMTGRiIgI1Go1NTU1OJ3OyTbgPstNfcVvC+tcTbvYPdHfLVq0iG3btvHDH/4QnU6HXC4fd47b7eaLX/wiJSUltLVNquGULG6yetJ0MFlN/EQ/sDBAuoxxSp1Ox8qVK8nIyMDpdLJ48WL0ej0xMTHcfffdlJWV0dnZSV9f35hyhBB0dnZSWlrKxYsXuXTp0lRNC6QmU/aV1NRUioqK+MpXvsKWLVu826a//PLLVFRUcOHCBdrb2ydT9IysP5Ik8dxzz3H77beTm5vLunXraGtrw263+8K8m/qK37aOF0LskSRpwr9rampi//79PPvss2g0musGX7lczj/90z/xxhtv8MEHH1BeXj5R2/zuOFevOylN/ERdoHS5FplMxlNPPcXOnTtZsmQJQgjCwsKQyWTIZDJUKhWrVq3C5XKNa7EIIfB4PNjtdvr7+2loaGDfvn2UlZVRW1tLZ2fnRM0JmCa+8JXw8HDmz5/Phg0bvPXI6XRiMpkoKSmZ9EarM1UTlUrFwoULycnJQa/Xs2HDBj7++GOam5t9Yd5NfcVvwXey2O12Ojo6OHjwIJs2bSIhIQG5XI7VakWj0aBUKoErT/Xc3Fyys7MnHHznCnq9HqVSiVqtJjc3l0WLFqHVanG73dTX13P06FHM5kAvizqe1atXk5mZSWxsrPczl8uFw+G47s6zVqsVSZKIiIhApVIRFRVFdHQ0UVFRaLVaPB4Pvb29kwm+MxJJkoiOjub2229n/fr1aLVaAI4fP87Ro0cpLy9nYGDAr9vHBwMul4uhoSGGh4eRyWTExsYSFhbmt+sHffB1u9309/eza9cuMjMziYqKQq1W09fXh0Kh8AZflUpFREQEUVFRAbY4uFAqlYSFhaHRaMjIyECr1WIwGLjtttvYsWMHUVFROJ1Ojhw5wqVLl4Iu+EqShF6vx+FwYDKZGBkZAa48lK1W63W7EkwmE3K5nPj4eCIjIykoKCAxMZH4+Hji4+Opq6ujurqaCxdm6kD6xJDL5aSnp7Nt2zZWrFjB4OAgFouF3bt3s3///jmjw2dxuVy0t7fT1dVFYmIiBoMhFHw/y/DwMP/zP/9DcXExCQkJzJs3j4GBAQwGw5jzSktL2b07WLtQA0NGRgaLFy/mtttu46677iI2NtY7cDWK2+1m2bJlhIeHB9DS6+N2u3nmmWdITk5GpVJ5XwlHRkZwOBx0dXV97u/Dw8N54YUXuPvuu4mPjwcgNzeX1atXs3///mm3PxhQqVTcc889LFiwgJGREfbv3893v/tdOjs7fdW/OWPZt28f4eHhLFu2jPnz53vfCvzBjAi+o+zevRu73c727duZP38+KpVqzPdyudzbEp7LGI1GvvzlL5ORkUFGRgapqamEh4cTGRmJx+PBbDZz+PBhLl++TE1NDefPn2dgYMBXfV0+Z7R1IpPJcDqdANcm298QuVzO+vXryc7OJjo6GrgStM+cOcPHH3887XYHA1u2bOHJJ5+kqKgImUzGyZMnefHFFzGZTF4t5zJNTU20tLQgl8vZsmULu3btora2lv7+/mm/9owKvufPn8ftdjMwMMCTTz5JVFTUmNeEjIwMlixZct1+wLmASqUiNzeXNWvWcMcddxAVFYVOp8PtdlNSUkJfXx8Oh4P+/n4+/fRTOjo6aG1tpbm5GZfLFWjzb4jT6ZxQoJAkiYSEBBYvXsx9991Heno6CoUCIQTvv/8+x44dmxM+kpKSwpIlSygqKiIpKYny8nJqampoaWnxZUrVjMbhcOBwOLz94kajkdTU1FDw/SzNzc1YLBbq6urYsWMHWq12TPBduHAha9eu5YMPPgiglYFBkiTi4uLYtm0bt912G0uXLsVkMtHW1kZdXR1vvvkmdXV12O12HA7HrB1sUiqVaLVaFi1axOOPP869996LRqPB7XZjs9l48cUXqaqqoqenJ9CmTiuSJLFw4ULy8vJIS7syF+HSpUtcvnz5uvnOarUamUzGaPbA6OSluYRCoWD+/PnMnz/fL/3gMyr4bty4kZycHLKyssjLyxvXOd7Y2DhnBw+USiXPPPMM99xzD2q1mpdffpmf/exn9PT0MDIyckuv6TMdpVLJunXr2LJlC0VFRWzevBlJknC73Vy8eJFf/OIXnD9/HpvNFmhTpxWZTIZer2fZsmUYjUbv50NDQ/T09NDR0THmfEmS+NKXvkRSUpK33/+nP/0pvb29/jQ74AghkMvlKBT+CYtBH3zDw8NJTU3lL//yL8nNzSU6OhqdTnfdvt36+vo5lWamUqm47bbbWLJkCYsWLeLQoUN0dHQwNDTE0aNHsVgs3sA72zEYDGRlZfGzn/3Mm+VwbQ7o8PAwnZ2dc0KP0fzm9PR0EhISkMlkeDwe6uvraWpq8p63du1aUlNTkSSJBx98kOTkZPR6vfe7//qv/+Ktt96aE0E4ED4R9MFXq9WSlpbGbbfdRnx8PGq1mhslVms0GiIjI/1sYWBQKBQsXryYrVu3kpeXR0REBC+99BIOhwObzUZ9fb03LWsuEBMTw+LFiykoKBjXcpEkCYPBwJo1a3C73XR1dWGxWOju7vZOT59NyOVy4uLiMBqNxMbGIoRgaGgIs9ns7cuMjIwkNzeXpUuXEhsbS15eHgaDAaVSicPhIC0tzdttdfDgQRwOx6zTKdDMiOAbHx/vzcH7vBktixcvprW1lRMnAjH93r+oVCr+5E/+hAceeAAhBB9//DEVFRUMDg7OyUoSFxdHQUEBcKUVc62fyGQyMjIy+Ku/+isqKyspLy+nsrKSTz75hKqqKux2+6yaYBAWFsaiRYtYuHAh8fHxuFwu7/Rru92OXC4nKyuLhQsXsmbNGu9DyW6309fXh8ViYcGCBRQWFqJWq6msrKS9vX1W+5UkSX5v/QZ98G1qasJsNhMfH89TTz1FVlbWDdPJIiIivClFsx2tVsszzzxDWFgYJ06c4IMPPmBoaGhWV5DPo6mpid27d5OdnU1ubi6xsbHXzVvOz88nLy8Pt9vNyMgIb7zxBnv37uX48eOzYhAuLCyMyMhI5s2bh1KpxG6309XVxdtvv015eTlDQ0NkZ2fz9a9/neLiYpKTk7FYLBw7dox9+/Zx/vx5tFotv/nNb1CpVEGZ+z1d+Huqf9AHXyEEdrudXbt24XA4mDdvHhqNBrjSoklJSWH79u1oNBokSfK7gIHC7XbT1NREWloaRqORL33pS97MBn+kyQQbvb29nD17lr//+78nLS0Ng8FAREQEer2e3NxcMjMzKSgoQJIk74poYWFhbNu2jeTkZBYsWMDzzz8/4/uDY2NjWbp0KU888QTR0dG0tLRw+PBh/uu//gubzUZeXh733XcfxcXFREdHY7FYKC0t5Ze//CW9vb1ER0fzla98BYVCQVtbGxcvXqS7uzuoUxFnKkEffOFKoKmrq0MulxMVFTUm+Obk5JCTk8PChQu9T2q1Wj2VtX2DktFptkNDQ7hcLpxOJwcPHmTlypXEx8dTVFTE7bffzvDwMMPDwzgcjkCb7FdG8zW7urowGAzodDo0Gg0Gg4GFCxeyZMkSlEolqampY1IUR2c1abVa3n77bdrb22f05IOoqCgyMzNZunQpAC0tLRw8eJALFy6wYsUKioqKKC4uZt68edTU1FBdXc2RI0eorq5mwYIF3u2ELBYLFRUVnDp1iqGhoQDf1fQzGiscDoffZv3NiOA7Sk1NzbjPGhsbSU1NJTMzk7i4OObPn09CQgJtbW2z5mktSRIajYb8/HyqqqoYGBhgcHCQH/zgB9x7771s376dBx54gO9///vYbDasVmvQzlbzB319fWOWlywrKyMhIYHy8nKeeOIJFi5cSGJiovf7hIQEVqxYwUMPPcRrr7120ynLwUxUVJQ3r1cIwcWLF3nnnXcA+PKXv8wXvvAFMjMz8Xg8vPnmm7z33ntcuHCB1atX841vfIN7770Xj8fDq6++yjvvvMOBAwcCeTt+p7OzE5PJP4u0zajg+1kUCgUZGRl85zvfQaPRYLVacblcuN3uWdPqjY2N5aGHHuKhhx4iJSWFF198kSNHjlBeXk5fXx9//OMfUavVPPDAA+h0OiIiIvw6P32m0NXVxTvvvMOHH37IN77xDb74xS+yZMkS7/dKpRKj0ejXhVWmA5VKhV6vR5IkTpw4QXV1NXK5nAULFmA0GomJicHlcvEP//APvPfeezQ2NpKdnc3zzz/PggULMJlM/Od//ievvvpq0C2y5A+6u7vH5UFPFzM6+K5cuZL169d7uyHq6+s5c+YMvb29s2bg6Zvf/CYbNmwgOTmZY8eOcfr0ae+C10II8vLyyMnJQQhBbW0tLS0tcyIvc6IIIRgeHsbpdNLa2kpLS8uY4Ot2uzGbzTP+benacQ+n04nL5UKSJBQKxZgZbAaDgUcffdS7G4hOp2PXrl2cPn2aU6dOeXPE5xoej8dvsSOogu+oI+j1evr7+7FarTdMAVIoFKxcuZI1a9Z4P2toaODs2bMMDg76y+RpZ82aNeTm5qJQKOjo6PD2WyYnJzMyMsLmzZtZvHgxdrud0tJSGhsb59SAm0Kh8C4j6nQ6b3rvo0H4s33io8sLzvSA43A4sFqtCCHQ6/Xo9Xp0Op13YtJocM7MzCQzM5Po6GgkSaKsrIwPP/yQgwcPMjQ0NON1mCz+HLQPquCr1+u57777uO2229i9ezd79uy5bitOkiRiY2PZuHEjGzZs8H5eU1NDaem4LcBmNLt27UImk7Fx40aeffZZnn32WeBKS62hoYGUlBQ8Hg+tra38x3/8BxcvXpwzg22jkwnuv/9+ZDIZTU1N7Nq163O7nORyuXdZ0lFGd7uorKyc8do1NjZSUlICwIoVK2hqaqK0tJT8/HxiYmJQqVTI5XK2b9+OJEmMjIzQ29vLb37zG2+Ldy6jUCjm5vTib3/722zdupX8/HwyMjIYAApvjwAAIABJREFUGhqitraWvr4+WltbMRqNJCYmkpSUxBNPPMGKFSvQaDQIIfjd737HqVOnZkWu5rX87ne/o7m5mcrKSnJycli2bBk6nQ64ktd8/vx5Tp06xVtvvTUrgsetotVqmT9/Pi+88AJ5eXm89957vPnmmzcMvEql0vuqff/993uzAQB6enq4dOkSZWVlvthkM6B4PB6cTid2ux21Ws22bdsoLCwkLCzMu5PJKMPDw7S3t3PkyBEOHTo06+rOZFi0aBGXL1/2y6BbUAXfpqYm2tvbMRqNZGVl8fjjj3u3iL98+bJ3lDomJobly5cTFRWFy+Wip6eH3bt3e3cfnU3YbDbOnTtHf38/cXFxpKamegeFJEnCbDbT1NTknak1W/q6b0ZOTg5btmxh6dKlREdHe7cMUigUYwZcFQoFCxYsIDs7m1WrVlFUVERWVpZ3LWin08mFCxfYt2/frHhwWa1W6uvreeutt1i5ciVJSUkkJycDV7pc+vr6aGhooLu7m+7ubpqamjhx4gR9fX2zapbfrTK6I4rZbPZuI/TZdcKni6AKvqWlpSQmJnqT3u+66y7sdjs9PT00NDSQk5NDdHS0VxyPx4PFYuHMmTMcPnwYs9k8Kx2opaWFlpaWQJsRVBiNRgoLC727U0RHR5Ofn49KpRqzDoFGo2Hz5s1s2rSJbdu2ed8aRoNze3s7n376Kfv27QvMjfiYgYEBLl++zG9/+1sGBgZYuHDhmJXNWlpaOHXqlHdw9v+39+5RUd3n/v/rMzcGhuE+yh1UFAXFGwpe4/0SjcYkXW3T/pqVtkmbNpeTnJycJmnPSc/pbXU1te3paps2Tc9qm8TmJGlijPEWiWJAAygGARFBkPtFmOF+m/n8/kDmi6JyG2aGYb/W2ksYZvZ+5u2zn73383k+z6eyspKLFy+6zmAXM7C4akNDA8HBwVM3+Obn5xMZGUlAQABvvPEGL7zwgn0VhsE5ugE6Ojr49NNP2bNnjwusVXAlFRUV5OTkcN999wGwY8cOtm7dal+VY2CU32g0MnPmzCFLTtlsNjo6OnjhhRfIzMz0qObqXV1dfPLJJ3zyySeuNsXtsVqt9olJUkrmzp1LWVkZ//jHPyb82MMGXyFEFPBXYDoggT9KKX8thHgJeARouP7WF6SUB8drUEZGBnl5eUgpCQgIYNq0aWg0GmbNmkVKSoq9d0NbWxu/+93vXLJmm7M1mQw4W5PKykoyMzM5fPgwK1euxGg0otFoiI+Px2az2ZvrqFSqG2p3rVYrWVlZZGdnk5mZyccff3zDhAxHo/jKUNxNk9bWVi5dusSCBQvw8vJyqzvfPuBfpZRnhRBGIEcIMbDy4F4p5S8caVBrayutra1oNBqOHz+Or68vKpWKsLAwzp07Z+832tXVxaFDhygsLHTk4UeKUzWZJDhVk5aWFkpKSnjrrbcwm81ERkbi7++PxWIhLCwMb29vbDabPbB2d3fT0NBAc3MzWVlZ5OfnU1RURFNT00TX9iq+MhS30qShoYFTp06xcuVKysvL3WeGm5SyBqi5/nOrEKIQiJhow/r6+jhz5sxEH2ZMuEoTd8bZmnR2dlJRUcHrr79OWVkZc+fOZcaMGZSXl5OcnExwcDA2m40rV67Yg3BeXh5XrlyhoqLCaSP7iq8Mxd00qamp4dChQ2zatIns7GznrYYzsLzMSDYgFrgK+AEvAWXA58BrQOBtPvMokH19k+64jUaDqaIJkD2ZNBFCSJVKZf/35k0IIYUQLtPEk33FUzRxoJ+MyFdGI5IvkAPcd/336YAaUAE/Bl4bwT5c7iiOdB5P1mQkzqNoouiCcv6M2VdGKpIWOAw8c5u/xwIXJqtQY3Qcj9ZkJM6jaKLognL+jNlXVAyD6J/o/GegUEr5y0Gvhw162x7gwnD78hQUTYaiaHJrFF2GomjSj7h+9bj9G4RYDaQDecDA9KkXgC8Di+iP8mXAt2R/Iv1O+2oA2gFX96oLGWRDjJTSNJoPTwFNYJS6eKgm4F6+0goMbWrtfNxJE3fxlVGfP8MGX0cjhMiWUiY79aBuaMNg3MEed7BhMO5ij7vYAe5ji7vYMYA72DMWG4ZNOygoKCgoOB4l+CooKCi4gHEFXyHENiFEkRDishDieyP82B/Hc0wHMaE2jEEXRRMn2zMKJswORZOhTKWYMuacrxBCDVwCNgOVQBbwZSllwZh26CEougxF0WQoiiZDmWqajOfOdzlwWUpZKqXsAfYBux1j1qRG0WUoiiZDUTQZypTSZDzBNwIY3GS2kjvMz77+OCHddLt7HDqMWRc316TPgbqM1ldc/d3dURN39hVFkzH4yoQPuAkhHhVCZAPvTfSxxop0ciu/yaAJkOtMXQY0ua6Lu+JUTWBy+IqiyS0Z1lfGE3yrgKhBv0def+0GpJR/BJ4ATozjWJOJYXVRNLm1JtfrJJ9wpmEuRDl/hjKlNBlP8M0CZgshZgghdMCXgP23ee/NjxNuhRAi0IG7G6kubq0JEOtAXUbrK+6KKzWZUF9RqVSo1WrUavWoP+upmoyTYX1lzMFXStkHPE5/c4xC4C0ppZMaYTqclx21Iw/SpRcH6aJoMhR30USv1xMbG8uvfvUrPv30U44fP05cXNxol0/3KE0cxLC+Mq413K7nNEaS77n5ccLdWO7InY1QF3fXpAEH6jJKX3FXXKmJw31l2rRpJCYm8tWvfpU5c+bQ3d1NcXExHR0dAx3DRorHaOJAhvUVZy2gmQXMdtKxxoIruieNSxMhBIGBgfj4+NjXnRpYq2xgccjy8nL6+vpGeyINEABkjNW+cZDlrAOpVCpmzJiBl5cXNpuN0tJSent776SXKzVx6Pnj5+dHUlISa9asYf369RQVFVFYWMj58+dpbW21r/48Qibd+eMEhveVsfTiHGP/zrtxfY/N221hztLBUZro9Xr51a9+Vf7mN7+RH3zwgczPz5fd3d2yp6dHNjY2yrS0NBkVFSV1Ot1YNTG7UJcJ/z9XqVTSYDDI/fv3y6KiIpmVlSVjY2OH08uVmjjs/FGr1XLbtm3y+PHj8vLly/Lll1+WISEhUqPRTJnzxwnbsL7i1K5mQgjnHWwUSCmFq449Wk38/PxYtWoVX/ziF9m2bRtWqxWz2UxFRQVarZbZs2cTHByMEIKsrCxefvll9u+/3ZjFHcmRLuoU5Wg/8ff3x9fX94bFVzUaDYsWLWLv3r1otVoKCgrYs2fPcHd9LtMEHKOLwWAgKiqK9957j9bWVk6fPs0Pf/hDmpqaRnu3a2cynT9OZFhfcVbaYUKIj48nJCQEIQQhISFERUURHBwMQFNTExkZGWRnu3PZ6OjZtWsXq1evJikpiUuXLnH27FnKy8upra0FYObMmSQlJbF7924SEhJITU2lqqqKnJwcF1s+8QghMJlMzJs3j5CQEAwGAwAmk4mAgABCQkIAuHjxIk1NTSQmJmI0Gu0rZgshEMJlcWTCUavVxMTEsGvXLlQqFZ988gkff/wxjY2uboXrWtRqNXq9nrlz55KYmEhoaCg+Pj4A9nRMbm6uw487qYKvTqdDo9Gg1WrR6/WsXLmSOXPmoNVqiY2NZfHixcTGxgJw9epVjEYjVVVVTlsKeiIRQqDX69mzZw8LFiwAYN++fezfv5+rV6/S0dEBwPTp01m7di0rV64kNDSU5ORk6uvrp0TwVavVREdHs2PHDuLj4wkKCgL6g6+fnx8GgwG9Xk9GRgalpaVERUWh0+loa2ujrq7OxdZPPAEBASQmJrJ7924KCws5ePAgmZmZrjbLpWi1Wvz8/IiIiGDLli3cfffdJCQkEBAQAMDx48c5cuQIVVVVXLt2bcxPB7dkMuXykpKS5K5du+QTTzwh33zzTVlWVib7+vpuufX29sra2lp5+PDhYffrinzVaDXx9vaWmzdvlsXFxbKoqEi+8sorUqVS3fK9M2fOlP/93/8t29vbZWNjo/zggw/Gove4Vup1hZ94e3vLxx9/XF68eFFarVb71t3dLcvKyuRf//pXeeXKFdna2mr/m81mk2+//ba899573VoTR5w/3/rWt+R7770nm5qaZFxcnPT29nZIfnMya5KQkCAfe+wxeebMGdnb2yutVuuQWFJfXy//8pe/yJCQEIeeP25556tSqQgKCuKpp55i9uzZ9qtQUFAQvr6++Pr6YjAYaG5u5urVq0RHRw/ZhxACnU6HXq93tvkThkajoba2lpqaGo4fPz7gfENoamri+PHjPPHEE2g0GvR6PQaDYSwlRJOGxMREtmzZwmOPPUZERATV1dVkZ2djsVhIS0ujsLCQuro6Fi5cyEMPPcTGjRsxGo1YLBby8/M5deqUq7/ChKLValmxYgWxsbHk5ORQW1tLV1eXq81yGUII/P39efjhh1m3bh3x8fG0tLRw4cIFioqK+Pzzz9m8eTMLFy4kODiYBQsW4OPjg0qlctjdr9sFXz8/P8LCwtiyZQsbN24kMjISX19foN+BtFotQgjeeecdrl69is1mIyIiAoPBQHx8PLGxsXh7ewP9AystLS2u/DoOw2q1UlFRwbvvvktjYyPnz5+/bSDt7e21PyJ5e3sTGBjIvHnz+Pzzz+np6XGy5c7BaDQSHR1NdHQ0vb29lJaW8uGHH9LQ0EBeXh719fVoNBr8/f3x8fFBrVbT19dHTk4OFy9epLm52dVfYcLQaDQsXbqU6OhoOjs7OX78ON3d3R57IR4JXl5e7Nq1i5SUFEJDQ6mrq+Pdd9+lpKSEqqoqysrKsFqtGI1GgoKCmD59OiEhIVy7do329naH2OB2wTcsLIyVK1fyb//2b5hMJrRarf1vnZ2ddHZ20tbWxo9//GMaGxuRUuLn58eMGTP42te+hslkwtvbG5vNRkNDA2VlZa77Mg6kp6eH4uJiLl++jNVqpbe397bvtdlsdHd309fXh06nw2QykZKSQlFRkccG34FHOSEE7e3tlJWVkZaWxpUrV5BSYjQamTlzJnfffTfx8fHodDrMZjMfffQRhYWFWK1WV3+FCcPLy4vt27djMpkoKipi//799PX1udosl6LX6/nmN7/J/PnzaWtrIycnh//4j/+gu7vb/p7Ozk4WLVrEwoUL8ff3x2QyUVlZ6bnBd/ny5Tz88MOEh4ff8HpPTw+vvfYan332mX0EcuD2v7GxkUceeYSkpCT7iHZNTQ1vvvkmf/rTn5z+HSaKwY5xJ7q6uigvL6e4uBi1Wo2XlxczZsy44ULmaZSVlfHRRx+xefNmYmNjWb16Nc899xz//u//jkajYcGCBTz99NNs2rQJq9XK5cuXefXVV/nLX/6C2Wx2tfkTilar5a677qK2tpacnBzy8yfrjF3HIaWkq6sLm81GbW0tR48eve0F2Gq10tXVxbVr1+js7HSYDW4VfOfPn8+iRYuYPfv/TVzp7Oykrq6OX//616Snp1NTU0NHR8eQvIvJZLKXhwBkZ2dTVFSExWJxmv3ugpSSvr4+ent77Tp5cgkVgMViobi4mPz8fEwmE0FBQSQnJ5OcnMymTZtYtmwZCxYsQKfT8cknn3Ds2DHefvttWltbXW36hBIcHMy8efNISEjg5Zdf5tixYzf83dfXl1mzZmGxWLh27ZrH63EzQgh6e3tpa2tDq9USHBxMREQEy5cvJzExkdmzZ1NYWMif/vQnSktL7VVFjsCtgu/SpUtvGGAzm81cvXqV3Nxcjh49ekNJFfSXFnl7exMSEmLPDVutVpqbmykoKKCmpmbKPl4JIVCpVAghkFION2120tPd3Y3ZbKahoYHe3l4CAgKIjIxkx44drF69mri4OPz8/CgvL+fcuXOcOXOGigp3borlGIKDg5k/fz5CCC5fvkxZWRlCCKKjo5k5cyZRUVHMmjULs9lMXl4eRUVFU0IXlUqFv78/arUaX19f4uLi2LhxI2FhYURHR7Nw4ULq6+vJy8ujsrKSEydOYLFYHJqecqvgu3btWubMmYNarcZms3Hp0iVOnDjBBx98wMWLF4e832AwEB4ezurVq5k/fz4BAQG0t7fz+eefk5OT4xH1vWNBpVKh0+nw8vJCrVbT3d1NW1vbkOCrUqnsAXocPSDcgoELTGdnJ1arFa1WS0hICE8++eQNF6C0tDTS09OnzKN3REQEK1asoLy8nJqaGiwWC2q1mg0bNvCVr3yFpKQkvL29sVqtHDx4kA8//JB9+/Z5dA4c+n0/PDwcLy8vwsPDuffee9mzZw+xsbEEBARgtVp59NFHSU9Pp7S0dEJscKvg+89//pOOjg5WrlxJW1sbL774IoWFhbcdiV63bh3bt2/noYceQqfTUVNTQ3Z2Nk899RS1tbV3HJTyZPR6vf2Oxt/fn7q6OtLS0uz5KpVKRWBgILNnzyYmJoawsDAOHjxIRUWFQ3NazsZms1FZWXnL3HhTUxOnT5/m97//PaWlpTQ1NbnAQuczZ84ctm3bxjPPPENJSQk2mw1fX1+efvppPvjgA37xi1+Qm5vLunXr+MpXvsKzzz5LfX096enpHl2KJqXEbDZjMBjw9fVl4cKF9hmONpuNzs5OLl++PKHjAW4VfLOzs6msrOS9996jr6+PgoICWlpahuR3VSoVSUlJ7Ny5k3Xr1qHT6bDZbBQWFnLy5Enq6uo8/jH7Vmg0GoxGo32K7cAAW3BwMN/4xjdYtmyZPU0TEBBAVFQUBoPBXpL2xhtvUF5e7uJvMXa0Wi3x8fH4+PjckOO+cuUKZ86c4be//S2XL1922Gi1uzNQHqXT6eyDSwaDgejoaC5evEhmZiY5OTk0NzeTnp5OVFQUK1eu5IEHHuDs2bMeHXxbW1t55plniIuLw2QyERwczLe//W00Gg0Wi4WzZ89SVlY2oTlwtwq+tbW19h4Fd0KtVrN161aWL19un05cVFTEmTNnyMnJGXFVwGRDpVKh1Wrx8vLC29sbo9GIn58fGo0GIQReXl6YTCamTZvG7Nmz7cHXaDSydu1apk+fjtFotKdnhBD09PTYc1mT+WIVEhLC3LlzSUhIsPd0GKC5uZmSkhIyMlzRDdJ1BAYG2psJtbe3Y7Va7StWZGRkcOnSJRoaGgCoqqoiNzeXkJAQtm3b5lGTk25Fb28vR48epaioiGnTphEVFcUjjzyCRqPBbDZz6tQpmpqaJvTp2a2C70jR6/V8//vft1c3WK1WXnvtNQ4fPkxBQYGLrXM8A4Nn3t7eBAUFER4ezowZM1i8eDGLFy8mMLB/tRIvLy+io6PtJ9wAGo2GyMhI1Go1VquV1tZWDh48yKlTp6ivr6elpWVSD7IIIVi2bBnf+c53WLNmjf3RceBvk/miMh78/Pzw8fGxT9Dp6uqip6eH0tJSKioqaGtru+H9eXl5+Pn58eyzz3p0WeJgrl69isViQaVS2f2ktraWN998c8Jv4iZd8E1ISOCLX/wiXl5eN5xYWVlZI7prnmx4eXmxZs0aNm3axNq1a+0z+FQqFRqNBo1Gg9VqpbOzk46ODvv0R5Wqf4Wozz77jMzMTPbv309BQQE9PT1IKe2TMGw226QNTmq1GpPJxPbt29m+fTubN29GCEFpaSlVVVXU1tZy33334efnh7+/v6vNdRk2m42amhq6u7uxWq32oHvz/7vFYpmSHc78/PyIj49HrVY7tSRzUgVflUpFQEAAc+bMsQfegcGk8vJyj8zlPfjgg6xdu5alS5cSGhrKtWvXqKysxGKxUFBQgNVqpb29HbPZTGNjIw8++CDJyckEBgbS1NREeno677//vr2NokO7MrkYrVbLvHnzuOeee1i8eDEABw4c4JNPPqGtrY3Q0FDuvfdezGazR08fvh0DgWTwkwAMDboDhISEEB4eTldX16S9II8FKaX9JqSmpoaqqiqnnCeTJvgOLJsTHh5uz/O2tbVRUlLC/v37aWho8Mhc786dO1m6dCnBwcGUlJSQnZ1NXV0dDQ0NZGRk0NPTQ2dnJ2azGbVazdq1a5k/fz69vb1cuHCB06dPk5WV5XHa6HQ6goODSU1NJSUlBR8fH4qKivjggw84efIkRqOR7du3A/13dFMx+MLoJtdEREQQGxtLbW2tx5eaDaDT6TAYDPj5+dHX10dpaSnFxcVOqfqZNMHX29ubVatWsWXLFpYv71+XbmDyxaFDhzwuuAywePFi/P39uXDhAo899hhFRUVDHEMIgbe3N88//zzJycn4+vrS2NjISy+9xIULFzxSm/DwcFJSUnjuuefw9fXl0KFD/M///A8nT54kKCiIlStX8vDDD6PRaGhqauLatWuuNtnp3NR68Y5oNBqSk5NZtmwZH3744aQuORwNoaGhLFmyhHvuuYfW1lZOnjzJ4cOHnTJHwO2Dr0ajISgoiO9///usX7+eqKgoenp62Lt3LwcOHKCwsJDW1laPfkzq6uqiubmZS5cuDSn/0Wq1LFu2jEcffZSdO3fi5eVFUVERP/vZz8jOznbodEh3IiYmhuXLl2M0Gu0tIdPT07FarSxcuJBFixbh6+trb7Qz1abNQv9gUnl5Oa2trezevZvDhw8PGRcRQqDVavne977HsmXL6Ovr4ze/+Y3HT8sXQmAwGHjxxRe56667mDZtGq+88grvvPOO0wbt3T74enl5ERISwtq1a4mJiUGj0dDY2MjBgwc9vhUg9JdJDay7tXXrVry8vOjs7MRisWA2m1m4cCHJycmsWLGCjo4OTpw4QWZmJllZWbfsgeEpDPQpVqlU9PT00NXVhdVqJT4+nu3bt7N8+XKEEOTm5nLmzBmPrIIZjpaWFi5dukRWVhZ79uyho6ODc+fOUVFRQWBgIAEBAYSFhbFo0SKSk5MpLS0lNzeXqqoqj0876HQ6tm3bRlJSEgaDgeLiYg4dOkRZWZnT6pvdOvhqNBoCAgKIiYkhISEBKSX19fVcuHDBI/OYtyI/Px+dTkdQUBAPPvggRqORlpYWqqurqaqqYuPGjURHR6PX68nOzmbfvn189tlnk3qyxEgYKL+TUmK1WvHx8SE6Opq77rqLLVu2EBoaSkVFBUePHrXXtE41Ojo6KCoqIi0tjRdeeIGamhp8fX05d+4ckZGRhIeHM3v2bDZs2EB9fT2nT5/m8OHDHp9yUKvV+Pv7s3v3bqKjo2lra+PMmTNkZmY6teWqWwffyMhIUlNT2bFjB0IIqqur+eijj/jpT3/qsX1pb+ZrX/sa69ev57777uOb3/ymvYRsgIyMDD744AOOHTvG8ePHPf6OZQBvb297+ZjFYmHlypXs3LmTlJQUhBCcOnWKn/3sZxw5cmTKaHIrLl26REVFBSqViscee4yvf/3raDT9p31XVxelpaW888477N27d7iVmz2GsLAwUlJSuPfeewEoKChwiZ8MG3yFEFHAX4Hp9K9N9Ecp5a+FEC8BjwAN19/6gpTyoCONu//++9mwYYP9hEpLS+P48ePU1NS4NMfrbE2ysrK4dOnSLXsTd3R02HOargwyztakubmZyspKAFJTU5FSolaraWtrIy0tjWPHjpGVleXywOvK82eArq4u3nrrLY4fP26vjwfs9d4Wi8WpgdeVmgzUhT/++OOoVCpee+01jh07xsmTJ90v+AJ9wL9KKc8KIYxAjhDi6PW/7ZVS/sLRRg3U80ZERBAaGmofVMnNzaW0tNQdGuY4VZO2tjba2tqoqqpy5G4djVM1qa2t5ezZs2RkZNhbJl67do2LFy/y0UcfkZ2d7S5N0p1+/tyMlJJr1665U8WHSzRRq9UkJSXZVzkvKysjIyOD3Nxclyw3NmzwlVLWADXXf24VQhQCERNqlEbDjBkzCAoKQq/X09XVxccff0xubq79bseVuEITd8fZmgxMlx1oHKNSqSgtLSUtLY0DBw5QXV09UYceFYqvDMUVmqhUKvz8/Fi3bh0LFixASsnp06c5d+6c68ZHRrlMcyxwFfADXgLKgM+B14DA23zmUSD7+jaiZZeDgoLkz372M1ldXS2bm5vl2bNnZWJiovTx8XHIUtc3b+NcutopmrhgG/My6c7URAghVSqVVKvVUqVSSSGEW2riyb4yGTTx8/OT3/72t2VZWZmsqqqSH374oTQYDFKlUrnMV0Yjki+QA9x3/ffpgBpQAT8GXhvBPkZkuMFgkF/4whdkSUmJTE9Pl9/97ncnVKhxOI7TNHHBNqZAo2gy9XRxd01CQkLk6tWrZXp6uty3b5988cUX5fr16ycy8I7IV0ZU7SCE0ALvAK9LKd+lX/G6QX//E3BgJPsaCT09PRQWFrJ//35qamo4deqU2/VtcLYmkwFFk1uj6DIUZ2pis9no6OggLy+PrKwsCgsLuXjxousrO0ZwZRH0j0z+6qbXwwb9/DSwb6pcuaeCJozyLk/RZOrqomgyNl8R17/AbRFCrAbSgTxg4FLxAvBlYNH1A5UB35L9ifQ77asBaAdc3bcuZJANMVJK02g+PAU0gVHq4qGagHv5SitQNJrjTxDupIm7+Mqoz59hg6+jEUJkSymTnXpQN7RhMO5gjzvYMBh3scdd7AD3scVd7BjAHewZiw2q4d+ioKCgoOBolOCroKCg4ALGFXyFENuEEEVCiMtCiO+N8GN/HM8xHcSE2jAGXRRNnGzPKJgwOxRNhjKVYsqYc75CCDVwCdgMVAJZwJellFOvd98gFF2GomgyFEWToUw1TcZz57scuCylLJVS9gD7gN2OMWtSo+gyFEWToSiaDGVKaTKe4BsBDF5vvJI7zM++/jgh3XS7exw6jFkXN9ekz4G6jNZXXP3d3VETd/YVRZMx+MqED7gJIR4VQmQD7030scaKnKBWfrdjMmgC5DpTlwFNruvirjhVE5gcvqJockuG9ZXxBN8qIGrQ75HXX7sBKeUfgSeAE+M41mRiWF0UTW6tyfU6ySecaZgLUc6foUwpTcYTfLOA2UKIGUIIHfAlYP9t3nvz44RbIYQIdODuRqqLW2sCxDpQl9H6irviSk3c1lc8SROXrpBFAAAYvklEQVQhBGq1GrVabW86P0aG9ZUxB18pZR/wOHAYKATeklLmj3V/LuZlR+3Ig3TpxUG6KJoMxYM0AQ/S5NFHH+X111/n9OnTrF27FpNpVDOnBzOsr4xrDbfrOY2R5HtufpxwOCEhISxbtozg4GD2798/2uXklzvSlhHqMuGazJw5k02bNrFgwQL7kilXrlyhqalpJB9vwIG6jNJX3BVXajKhvjJOPEYTk8lEbGwsc+bM4aGHHuKvf/0rJ0+eHEsHtGF9xVkLaGYBs29+UaVSIYRACIHVah1NsBxCZGQkGzduJCYmhtzcXC5dujSaRTYvjPnAY+eWmjgCrVaLv78/ycnJPPDAA2zcuBGVSkVxcTFarZbi4uKRLCkTAGRMhH3DkOWCY44UV2oyIb4yGD8/P/z9/TGZTDQ0NGA2m2ltbR3JRz3i/NFqtQQGBmIymfDz82Pr1q2kp6dz6tSpsQTfYX3FKdOLBz1O3ICPjw+BgYEEBQXh7e095hyLEIKUlBSWL19Oamoqe/bswWg0Dlnp9w48PaYDj4PbaeIIQkJCuOeee3jqqadISkpCSonNZuMb3/gGjz76KLt27bKvYHsH/HCdLu6KKzWZEF8ZzIoVK3juuefIzs7mxRdfZPnyEd/QTnpNhBBMnz6duLg4YmJiAAgPD8fPzw+1Wj2WXQ7rK05bOl5KeXBwcBVC8NBDD7Ft2zZCQkJ49dVX+cc//kFbW9uY9l9YWEhTUxMpKSk8+eSTfPzxx+Tn52OxWEZi2x3b1k0UN2viCFJTU0lOTmbLli0kJibi7e1t/1tcXByRkZEsWrSII0eOUF9ff6fFSC+7ShdHExQUxMyZM9mxYwcPPPAA3t7etLS0cPLkSf7rv/5rpGkYcKEmE+Erg/Hx8WH16tXcc889ADzwwAN4eXmh0+n46KOPhrPNIzTx9fVFr9ejVquRUnLixAmuXLky1gV7h/UVpwXfmxFC4OfnR2hoKLNmzWLXrl3k5+eP9JF4CFqtFpVKhVqtJjAw0L6ooqej0+nw8fEhODiYHTt2kJCQQGxsLLNnz8bb25vOzk66uroQQhAQEICvry8BAQEjufOd9KhUKhYsWMCaNWuIj48nMjKSS5cu4ePjg8FgYMOGDbz66qt0dXXR0dHhanNdhlqtZsmSJcyZM4fg4GCklKjVarq7u0eadpj0aLVa1qxZYx9gk1KSnZ1NbW3thK144RZnoK+vL+vXrycjI4O+vj5aW1tHk69FpVIRFhaGwWCwv+bt7Y1Op5sIc90GHx8fTCYTYWFhzJ07l3/5l38hMDAQvV5vD6719fXU1dWhUqlISkpCr9e72GrnoNPp8Pf3Z8OGDezatYvp06dTXFzM22+/jcFgYN68eTz55JOYTCaqq6unbPBVq9X4+PiwceNG4uLi8PHxAaCyspIrV65QUeG2FW4OQ6/XM23aNLZs2UJoaKj99YKCgjHdCI4Utwi+KpUKHx8fnn/+ecLCwnj11Ve5cGFkOXy1Wo2vry9f/epXmTdvnv31DRs20NraSl1d3R0+PXnR6XRs3ryZnTt3smTJEpKSklCpVIOXVwHg008/JS0tDZVKxU9/+tMpEXw1Gg1z5szhvvvu49lnn+Xw4cO8+eabvPXWW1gsFiIjI+13dJ2dnWN9rPQIjEYjixYt4qmnnsLf39/++i9/+UvS09Ndt6y6E0lISOCRRx7h3nvvdeoTocuCr5SS2traG3K8Pj4+rFq1ip6eHn70ox/R1tY27C2/Xq8nKiqKxMREgoKCJtpstyAmJobU1FR+9KMfERAQgF6vR6VS3TL4DlSTAPb3TGTu0B1YtWoVW7du5Stf+QqvvPIK77//PoWFhbS0tCClZMaMGSQkJNDU1ER9fb3bLc7qLAIDA1m0aBHPPPOM/Y538EKT1dXVLrZw4lm9ejVbt25l165dYx1YGzMuS4pKKcnLyyMnJ4f8/P46apVKRVRUFMnJycyZMwcvL68R7cdms9Hb23tDoC4rKxvNQMqkITY2ltTUVHbs2EFsbCz+/v6o1WpaW1vp7Oykr+//FQv09fXZN2BcpXyTBS8vL1asWMGCBQtoaWnh6NGjFBUVce3aNWw2G76+vsTHx7NgwQK7Ni5fxdZFpKSksGPHDhYtWoRarcZqtdLc3MzJkyepr6+nq6vL1SZOGGq1mrlz57J9+3buuusuTCYT165do7u722k2uDTtcPbsWQIDA1GpVMydOxe1Wk1ISAiJiYmsWLGC8vJyOjs777gPq9VKe3s7ZrOZoKAge543Pz+fmhqPGKy3o9PpSElJ4e6777aPSnd1dWE2m6mrqyMoKAiTyWSvcLBYLJjNZtra2ggMDLRfqDw1CKvVaiIiIlizZg1hYWGkp6eTnp5+QxAZqPZYuHAhXV1dHqvFSNi2bRt79uwhPDwcgNbWVioqKvjoo49oaWnxmIuSWq22D8ar1Wo0Gg2+vr5s3ryZPXv2MHPmTDo7OykoKGDevHnjmdU2KlwafG02G6dOnaK1tZUdO3YQExODRqPBaDTy8MMPk5mZSXt7+x0HQ7RaLSaTiejoaHx9fZ1ovXPx8fFh8+bN/OhHPyI2Ntb+enFxMe+99x4///nP+eIXv8h3v/tdlixZgs1mY+/evXz44YdUVVXZg7WnIoQgKCiI9957D7Vazccff8wPf/jDGy7earWan//85yxduhS1Ws3f//73KZtygP461qioKPsF6PTp0xw4cIATJyZ1v5ob8PHxISwsjMjISGbOnEliYiJJSUksXbqUgIAAVCoV586d47XXXuPYsWPs3buXbdu2OcU2lw+4dXd309jYyIULFwgLC0Oj0aDVapk1axbh4eFUVFTcEHyFEOh0OrZs2YJGoyEkJIQVK1bcUM/qacTFxZGcnMxTTz1FaGgoUkq6urooLi7mb3/7G6dOncJqtWKz2aitrSUrK4vPPvuMf/7zn1RWVtLT08PJkyfJz89n/vz5rv46E0J4eDjLly8nJiaGV155hSNHjtxQ4x0YGEhycjJJSUkYjUZKS0vZt2/fmOvKJzMajYaHH36YWbNmIYSwpwAPHDjAgQMHXG2eQwkODmbLli3s3LmTmTNnYjAY8PLywmazcejQIdLS0rhw4QKFhYV2LZyFy4OvzWajs7OTkpIS1q9fD/QHWIPBQGhoKAEBAdTX1xMUFIS/vz96vR4fHx/uueceNBoN/v7+JCQkoNVq7ftra2ujq6sLq9Xqyq/mMGbOnMn69euZP38+3t7eNDY2UlxczJEjRzh16hSlpaVIKWlsbCQzMxO1Wk1WVhZlZWX2HFZ1dTXNzc0em8ebPn06S5YswWq1cuHCBS5evGjPdWu1WsLCwti2bRvBwcFcu3aNwsJCiouLp1ylQ2BgIPHx8WzYsIFp06bR19eHxWLhyJEjZGdnU1lZ6WoTHUpPTw9NTU2Ul5fb6/57enqwWCycOnWKjIwMKisraW1tJTIy8obgq9VqJ3Rw2uXBF7DnWzo7O2+YFhwXF8eVK1eoq6sjKSnJXtFgNBr52te+Zg+4g+nt7aW2tpbOzk6PCL5CCBITE9m+fbt90kR+fj5vv/02f/jDH+zOIoTg4sWLfP7553R0dGA2m2/YT1dXF729vVitVo+sdoiMjGTFihVUVlZy+fLlG/L9AQEBJCYm2n3m888/Jy0tbUSzHz0JIQSzZ8/mm9/8JqtXryYkJISOjg4uX77MH/7wB6qrq28YsPUE6urqePvttzlw4IB92nBPTw8dHR03VHMM3PUOznP7+PhMaOmZWwTfpqYm/v73v7NkyRLWr19PQkICAE899RSPP/44VqvV3l9zoFTqdmUher2e2bNns3nzZgDOnz/vtO8xEQzMzPLx8UEIwaZNmzh//jx9fX03XKWllPaazDs9OnlqqVlERATLli3jV7/6FdXV1fYLr6+vL08++SQ7d+4kICCAN954g3379pGR4Yr+OK5l9uzZrFixgq1btxIaGoparaa8vJy//e1v1NTUeOxT0cCgfGFh4W3fI6Wkra2N5uZmmpubCQgIYMOGDRQWFnLx4sUJscstgi/0l0UdOXKEsLAwe/DVaDS3vPIMl5tRqVTExcVx7ty5CbN3otFqtYSGhvKd73yHVatWYTAY7Lne250kt9NECIGXl5f9McrTRvgHelbYbDZOnz5NS0sLAQEBxMXF8fWvf51Vq1YRFhZGbW0tb775Jnl5eVMy17tkyRKSk5MJCQlBrVbT1NRESUkJp0+fnhLpl+H8vq2tjcbGRpqbm/H396e4uJjm5uYJs8dtgi9AaWkp165du6NIVqvVPvW4paWFrq4ubDYbMTExN/RyCAgImNSDcAaDgZSUFNavX090dDQajWbMQVOr1RIREUFQUBB6vd7jptIONESB/o5uS5cuxdfXl4SEBHbs2IHJZKKzs5PCwkJyc3NpbGz0iJTUSFGpVERERJCcnExCQoK9fj4/P5/Tp09z5cqVKaXH7ejp6aG9vd1+c1NdXT2h1TBuFXyHY2Awra6uDiklZ8+epbKykq6uLp599tlJHWxvJiQkhO985zvExsbaA8tYa3SNRiPr1q0jMTGR4OBgjyuvamtro7W1FZVKxfPPP4+3tzc+Pj74+vrS19eHRqOhoaGB999/H7PZ7HF5zeHQ6/Xcf//97Ny5k7i4OPssyL/97W+8++67HjkZyRE0NTVNaCrG7YNvd3c3bW1t1NTU8P7775OZmcnp06eB/lSFj48PcXFxPPnkkx4VfG+mubmZ3/zmN6PuVWEymUhOTuYHP/gBAQEBWCwWqqurPWqCQWlpKe+++y4Wi4U9e/ZgNpspLS3l/Pnz/OAHP6C5uZmMjAz+/ve/O3UGkztgMBiIioriwQcfJCwsDOi/w3vrrbfIzc2d0MfqyYzNZptawbepqYmioiKys7MJDAzk2rVrlJSUkJ+fT0lJCcXFxdTW1t4wki+EuGUHtLi4OMLDw9Hr9R4xkGC1Wqmvrx/VXZvJZGL79u1s3ryZadOm0dXVRUZGBgcPHqSlpcVjHjVtNhtXr17l8OHDlJaW0t3djZ+fH7NmzcJoNHL06FGOHz9OW1ubx1xwRkJgYCDLli1j586dzJgxA71eT319PTk5Ofzv//4vZWVlU0qPAby9vTEajfabNSklfX19tLe3c+nSJT777DNCQkLw9vbGYDBgNBrRarVs3LgRi8VCeXk5RUVF47bDrYKvxWIhPz+fI0eOEBoaSlVVFQUFBfaa1dEQHR2NyWTCy8tr0gbfgaoEIQQajYbQ0NBhS1+EEHh7exMWFkZiYiJbt25l3bp19lK0tLQ0Dh06NOy07cmG2WzGbDZTUFCAt7c3qamp3H///bS3t3P27FnOnj3rMRebkRIUFMTixYvZvXu3velUfX09J06cID09fUqlX1QqFTqdjoCAAEJDQ4mJicHPz8++hFl3dzdmsxm9Xk9bWxs9PT3Ex8djs9mIiIjAy8uL++67j7KyMjIzMz0v+HZ2dnLkyBGOHDky4s/c7so9UA98q1rgycRAaVhQUBD/+Z//yf79+++YevDy8mLBggU8//zzbN26FZ1OR3d3NxUVFTz33HPk5+dPaI9Sd2DOnDmsW7eO3bt3s3fvXk6dOjUlWiPeTFhYGDExMURGRtpfa2hoGOuaZJMWtVpt7354//33s3btWtasWWO/87XZbPY7X4PBYO8P89JLL9knbGm1WoxGIxkZGVgsFvbvv92K9iPHrYLvWLBarbS0tNDQ0IBOp7sh77tq1SosFgs///nPJ91dT2NjI7/97W/56U9/ar/yAvzkJz/BbDbT09PDiRMnqK6uJjw83F7XrNVq7SP+fX19pKWl8emnn5Kens7Zs2c9rtLhVjz++OOsWbOG6upqXn311SnRGvFWDH60hv7m4GfPnqWkpGTKBN/AwEA2btzI3XffzebNmzEYDOj1evsg9sC5ZLVauXz5MlVVVTes3jEwyD3QmvXcuXP2MafxMumDb29vL42Njfzf//0fmzZtsk/Bhf5puStXrkSj0Uy6bl4dHR3k5OTw9ttvc9ddd7Fo0SJ0Oh0LFiygt7eXvr4+pk+fjsViwd/fnzlz5tjvkqWU1NXVcf78eY4dO2ZP23R0dHj0SadSqQgNDSU6OhopJZ988gl1dXWTNu00XlJTU5k7d67997y8PPLy8qbM0kCAvUPi6tWr7U8AZrOZkpISsrOzKSsro62tDavVSmNjI2az+Y7+Ultb67CL+aQPvn19fTQ1NbFv3z68vb3x9/cnLi4OlUrF9OnTSUhIwGAw0NfXN6nufnt6eigrK+Mf//gHVqvVvt7d9OnTUavV2Gw2ZsyYccNnpJR0d3dTV1dn71B15syZUefLJytarZakpCQCAwOpr6/n8OHDdHZ2TqqLrqPQarWkpqYSHx+PlBKz2UxOTg55eXlT6mIUFRVlX5G4s7OTjo4OSkpK+Oyzz3j99dcpKirCYrG45qZkoObPGRsgJ3KLiYmRX/rSl2Rtba3s6emRfX19sqKiQt51113SYDDc9nPO1GAsmhiNRjl37lz5wx/+UFZXV0ur1Sp7e3uHbNXV1fLjjz+WL730kvT395dCiPHome3Omty8qdVqGRoaKrOysmRxcbH83e9+J318fBztYy7TZDS6aLVamZiYKDMzM2Vra6tsbW2VL730koyNjZ2Q886dNYmMjJTPP/+8PHfunDx06JB8+umnZWpq6oTGoZH6yrB3vkKIKOCvwPTrO/2jlPLXQoiXgEeAhutvfUFKeXC4/U0k1dXVZGZm8vLLL/OFL3yBpqYmcnNzKSgocOjV3tmatLe3c+XKFX7/+99TW1vL6tWrWbFiBVFRUdTW1lJYWEhaWhoVFRUUFhba81bXndMpuNpPZsyYwbp165g7dy4/+clPOHr0qFtUdLhCl4H01MAq3t3d3XR3dzvVH+6EMzWpq6vjz3/+M++88459cV53mWQ0krRDH/CvUsqzQggjkCOEOHr9b3ullL+YOPNGR29vLw0NDRw/fpyuri5aW1spLy+fiMcKp2pis9no7u6mtraW9PR06uvrKSgowGQy0dzczNWrV8nLy6OpqYm6ujpXOZdL/SQiIoJVq1bR0dHBxYsX7W023QCn69LX12fPZXZ3d9PZ2cnVq1fdKd3gNE16e3upr6+nvr7eUbt0GMMGXyllDVBz/edWIUQhEDHRho2VgYGqnJycCTuGKzW5cOHCiFd2diau9pPIyEhSUlIoLS2lqqpqSEtNV+EKXbq7uzl9+jSXL19Gp9PR2dnJhQsX3KaZkKt9xV0Y1QKaQohYYDFw5vpLjwshPhdCvCaECLzNZx4VQmQLIbLHZambomgyFFdootPp0Ov1vPHGG1RVVbllVYezdXnwwQdZvHgxK1as4Pz5827zuD2YKX3+jCKx7QvkAPdd/306oKY/gP8YeG0iBlKcsY0j2e+xmjDGwSVXaRIWFiZTU1NlRESE9PLycitNPN1XFE3G5isjFUkLHAaeuc3fY4ELk1WoMTqOR2syEudRNFF0QTl/xuwrw6YdRH+DgT8DhVLKXw56PWzQ2/YA7peInCAUTYaiaHJrFF2GomjSj7h+9bj9G4RYDaQDecBAIu0F4MvAIvqjfBnwLdmfSL/TvhqAdqBxXFaPn5BBNsRIKU2j+fAU0ARGqYuHagLu5SutwPg7uowfd9LEXXxl1OfPsMHX0QghsqWUyU49qBvaMBh3sMcdbBiMu9jjLnaA+9jiLnYM4A72jMWGUVU7KCgoKCg4BiX4KigoKLgAVwTfP7rgmDfjDjYMxh3scQcbBuMu9riLHeA+triLHQO4gz2jtsHpOV8FBQUFBSXtoKCgoOASnBZ8hRDbhBBFQojLQojvOemYUUKINCFEgRAiXwjx1PXXXxJCVAkhcq9vdzvDnlvY53RNrh9X0WXoMRVNhh5T0eTWx3WMLmOZnTKG2SxqoASYCeiA80CCE44bBiy5/rMRuAQkAC8Bzzrju7ubJoouiiaKJu6hi7PufJcDl6WUpVLKHmAfsHuiDyqlrJFSnr3+cyvgTt2TXKIJKLrcCkWToSia3BpH6eKs4BsBVAz6vRIn/yeOpXvSBONyTUDR5VYomgxF0eTWjEeXKTHgJoTwBd4B/kVK2QL8HphF/1TGGuBlF5rnMhRdhqJoMhRFk1szXl2cFXyrgKhBv0def23CEUJo6RfodSnluwBSyjoppVVKaQP+RP8jjLNxmSag6HIrFE2Gomhyaxyhi7OCbxYwWwgxQwihA74E7J/og7p59ySXaAKKLrdC0WQoiia3xlG6OGXpeCllnxDicfr7d6rpb5Kc74RDrwL+PyBPCJF7/bUXgC8LIW7onuQEW27AhZqAosutUDQZiqLJrXGILsoMNwUFBQUXMCUG3BQUFBTcDSX4KigoKLgAJfgqKCgouAAl+CooKCi4ACX4KigoKLgAJfgqKCgouAAl+CooKCi4ACX4KigoKLiA/x+cYIZk+T332QAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["We can train a CNN model to classify the images in the MNIST dataset.\n","\n","Note that the images are arrays of grayscale pixel data; therefore, we must add a channel dimension to the data before we can use the images as input to the model. The reason is that CNN models expect images in a [channels-last format](https://machinelearningmastery.com/a-gentle-introduction-to-channels-first-and-channels-last-image-formats-for-deep-learning/), that is each example to the network has the dimensions [rows, columns, channels], where channels represent the color channels of the image data.\n","\n","It is also a good idea to scale the pixel values from the default range of 0-255 to 0-1 when training a CNN. For more on scaling pixel values, see the tutorial:\n","\n","* [How to Manually Scale Image Pixel Data for Deep Learning](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/)"],"metadata":{"id":"55VZszhNojLS"}},{"cell_type":"code","source":["# example of a cnn for image classification\n","from numpy import asarray\n","from numpy import unique\n","from numpy import argmax\n","from tensorflow.keras.datasets.mnist import load_data\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPool2D\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dropout\n","\n","# load dataset\n","(x_train, y_train), (x_test, y_test) = load_data()\n","\n","# reshape data to have a single channel\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n","x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n","\n","# determine the shape of the input images\n","in_shape = x_train.shape[1:]\n","\n","# determine the number of classes\n","n_classes = len(unique(y_train))\n","print(f\"data shape={in_shape}, num_class={n_classes}\")\n","\n","# normalize pixel values\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# define model\n","model = Sequential()\n","model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=in_shape))\n","model.add(MaxPool2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n","model.add(Dropout(0.5))\n","model.add(Dense(n_classes, activation='softmax'))\n","\n","# define loss and optimizer\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# fit the model\n","model.fit(x_train, y_train, epochs=10, batch_size=128, verbose=1)\n","\n","# evaluate the model\n","loss, acc = model.evaluate(x_test, y_test, verbose=0)\n","print('Accuracy: %.3f' % acc)\n","\n","# make a prediction\n","image = x_train[0]\n","yhat = model.predict(asarray([image]))\n","print('Predicted: class=%d' % argmax(yhat))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u22fzGO9pCtD","executionInfo":{"status":"ok","timestamp":1651241630889,"user_tz":-480,"elapsed":277335,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"57a34ef3-8a58-448a-abab-c4376f052793"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["data shape=(28, 28, 1), num_class=10\n","Epoch 1/10\n","469/469 [==============================] - 40s 82ms/step - loss: 0.3559 - accuracy: 0.8904\n","Epoch 2/10\n","469/469 [==============================] - 26s 56ms/step - loss: 0.1482 - accuracy: 0.9552\n","Epoch 3/10\n","469/469 [==============================] - 25s 54ms/step - loss: 0.1056 - accuracy: 0.9682\n","Epoch 4/10\n","469/469 [==============================] - 25s 54ms/step - loss: 0.0869 - accuracy: 0.9736\n","Epoch 5/10\n","469/469 [==============================] - 27s 57ms/step - loss: 0.0740 - accuracy: 0.9778\n","Epoch 6/10\n","469/469 [==============================] - 25s 54ms/step - loss: 0.0653 - accuracy: 0.9795\n","Epoch 7/10\n","469/469 [==============================] - 25s 53ms/step - loss: 0.0560 - accuracy: 0.9821\n","Epoch 8/10\n","469/469 [==============================] - 25s 53ms/step - loss: 0.0522 - accuracy: 0.9834\n","Epoch 9/10\n","469/469 [==============================] - 26s 56ms/step - loss: 0.0476 - accuracy: 0.9846\n","Epoch 10/10\n","469/469 [==============================] - 24s 52ms/step - loss: 0.0448 - accuracy: 0.9852\n","Accuracy: 0.987\n","Predicted: class=5\n"]}]},{"cell_type":"markdown","source":["## 3.3 **Recurrent Neural Network Models**\n","\n","The most popular type of RNN is the Long Short-Term Memory network, or LSTM for short. LSTMs can be used in a model to accept a sequence of input data and make a prediction, such as assign a class label or predict a numerical value like the next value or values in the sequence."],"metadata":{"id":"tznwZdShBmoR"}},{"cell_type":"markdown","source":["We will use the car sales dataset to demonstrate an LSTM RNN for univariate time series forecasting.\n","\n","This problem involves predicting the number of car sales per month.\n","\n","The dataset will be downloaded automatically using Pandas, but you can learn more about it here.\n","\n","* [Car Sales Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv).\n","* [Car Sales Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.names)."],"metadata":{"id":"rVjg34EvB24j"}},{"cell_type":"markdown","source":["We will frame the problem to take a window of the last five months of data to predict the current month’s data.\n","\n","To achieve this, we will define a new function named ***split_sequence()*** that will [split the input sequence into windows](https://machinelearningmastery.com/time-series-forecasting-supervised-learning/) of data appropriate for fitting a supervised learning model, like an LSTM.\n","\n","For example, if the sequence was:\n","```\n","1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n","```\n","Then the samples for training the model will look like:\n","```\n","Input \t\t\t\tOutput\n","1, 2, 3, 4, 5 \t\t6\n","2, 3, 4, 5, 6 \t\t7\n","3, 4, 5, 6, 7 \t\t8\n","...\n","```\n","We will use the last 12 months of data as the test dataset."],"metadata":{"id":"_b28W5sDCKoR"}},{"cell_type":"markdown","source":["LSTMs expect each sample in the dataset to have two dimensions; \n","1. the first is the number of time steps (in this case it is 5), \n","2. and the second is the number of observations per time step (in this case it is 1).\n","\n","Because it is a regression type problem, we will use a linear activation function (no activation\n","function) in the output layer and optimize the mean squared error loss function. We will also evaluate the model using the **mean absolute error (MAE)** metric."],"metadata":{"id":"iEPhu_DqCsxj"}},{"cell_type":"code","source":["# lstm for time series forecasting\n","from numpy import sqrt\n","from numpy import asarray\n","from pandas import read_csv\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","\n","# split a univariate sequence into samples\n","def split_sequence(sequence, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequence)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps\n","\t\t# check if we are beyond the sequence\n","\t\tif end_ix > len(sequence)-1:\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn asarray(X), asarray(y)\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n","df = read_csv(path, header=0, index_col=0, squeeze=True)\n","\n","# retrieve the values\n","values = df.values.astype('float32')\n","\n","# specify the window size\n","n_steps = 5\n","\n","# split into samples\n","X, y = split_sequence(values, n_steps)\n","\n","# reshape into [samples, timesteps, features]\n","X = X.reshape((X.shape[0], X.shape[1], 1))\n","\n","# split into train/test\n","n_test = 12\n","X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# define model\n","model = Sequential()\n","model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n","model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n","\n","# evaluate the model\n","mse, mae = model.evaluate(X_test, y_test, verbose=0)\n","print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))\n","\n","# make a prediction\n","row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n","yhat = model.predict(row)\n","print('Predicted: %.3f' % (yhat))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ej9zI_bQC5eX","executionInfo":{"status":"ok","timestamp":1651248029377,"user_tz":-480,"elapsed":25235,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"1168789d-52f2-4de7-9165-eb1406f29564"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["(91, 5, 1) (12, 5, 1) (91,) (12,)\n","Epoch 1/350\n","3/3 [==============================] - 2s 140ms/step - loss: 431690688.0000 - mae: 18162.9004 - val_loss: 165204688.0000 - val_mae: 10445.7764\n","Epoch 2/350\n","3/3 [==============================] - 0s 19ms/step - loss: 170816608.0000 - mae: 9596.3350 - val_loss: 258818432.0000 - val_mae: 14528.0518\n","Epoch 3/350\n","3/3 [==============================] - 0s 19ms/step - loss: 200586656.0000 - mae: 11100.0312 - val_loss: 86115320.0000 - val_mae: 8230.8799\n","Epoch 4/350\n","3/3 [==============================] - 0s 20ms/step - loss: 75040984.0000 - mae: 6458.2090 - val_loss: 59294540.0000 - val_mae: 5645.7163\n","Epoch 5/350\n","3/3 [==============================] - 0s 33ms/step - loss: 52255768.0000 - mae: 5531.4585 - val_loss: 117746136.0000 - val_mae: 9581.8115\n","Epoch 6/350\n","3/3 [==============================] - 0s 29ms/step - loss: 107876656.0000 - mae: 8430.1953 - val_loss: 186418944.0000 - val_mae: 11647.5361\n","Epoch 7/350\n","3/3 [==============================] - 0s 19ms/step - loss: 129565328.0000 - mae: 9394.7139 - val_loss: 122545768.0000 - val_mae: 10148.2607\n","Epoch 8/350\n","3/3 [==============================] - 0s 21ms/step - loss: 51442632.0000 - mae: 5914.2319 - val_loss: 25230394.0000 - val_mae: 4122.6841\n","Epoch 9/350\n","3/3 [==============================] - 0s 18ms/step - loss: 34307808.0000 - mae: 4586.6919 - val_loss: 59504284.0000 - val_mae: 6930.3228\n","Epoch 10/350\n","3/3 [==============================] - 0s 17ms/step - loss: 58253336.0000 - mae: 5820.5742 - val_loss: 59296588.0000 - val_mae: 6649.2852\n","Epoch 11/350\n","3/3 [==============================] - 0s 18ms/step - loss: 47992268.0000 - mae: 5281.3862 - val_loss: 28668546.0000 - val_mae: 4940.2446\n","Epoch 12/350\n","3/3 [==============================] - 0s 18ms/step - loss: 23458666.0000 - mae: 3869.6729 - val_loss: 14178060.0000 - val_mae: 2875.6982\n","Epoch 13/350\n","3/3 [==============================] - 0s 19ms/step - loss: 18724992.0000 - mae: 3485.7678 - val_loss: 29636402.0000 - val_mae: 4452.5098\n","Epoch 14/350\n","3/3 [==============================] - 0s 23ms/step - loss: 26305746.0000 - mae: 4241.7334 - val_loss: 30258662.0000 - val_mae: 4470.3350\n","Epoch 15/350\n","3/3 [==============================] - 0s 24ms/step - loss: 21365448.0000 - mae: 3737.4470 - val_loss: 26490710.0000 - val_mae: 3646.1746\n","Epoch 16/350\n","3/3 [==============================] - 0s 23ms/step - loss: 16254591.0000 - mae: 3101.2000 - val_loss: 14211759.0000 - val_mae: 2979.8516\n","Epoch 17/350\n","3/3 [==============================] - 0s 23ms/step - loss: 18029836.0000 - mae: 3173.8875 - val_loss: 14439072.0000 - val_mae: 3434.8691\n","Epoch 18/350\n","3/3 [==============================] - 0s 26ms/step - loss: 19777496.0000 - mae: 3330.5886 - val_loss: 13392943.0000 - val_mae: 3044.0793\n","Epoch 19/350\n","3/3 [==============================] - 0s 24ms/step - loss: 16587548.0000 - mae: 3039.6426 - val_loss: 18675376.0000 - val_mae: 3614.4368\n","Epoch 20/350\n","3/3 [==============================] - 0s 23ms/step - loss: 16220523.0000 - mae: 3203.2712 - val_loss: 21535262.0000 - val_mae: 3516.7891\n","Epoch 21/350\n","3/3 [==============================] - 0s 24ms/step - loss: 16541069.0000 - mae: 3350.9814 - val_loss: 21157600.0000 - val_mae: 3450.9563\n","Epoch 22/350\n","3/3 [==============================] - 0s 29ms/step - loss: 16212277.0000 - mae: 3312.7271 - val_loss: 17836350.0000 - val_mae: 3054.5012\n","Epoch 23/350\n","3/3 [==============================] - 0s 24ms/step - loss: 15031681.0000 - mae: 3154.0496 - val_loss: 15641721.0000 - val_mae: 3140.2463\n","Epoch 24/350\n","3/3 [==============================] - 0s 24ms/step - loss: 15043549.0000 - mae: 3052.5811 - val_loss: 15042549.0000 - val_mae: 3414.8333\n","Epoch 25/350\n","3/3 [==============================] - 0s 21ms/step - loss: 14984683.0000 - mae: 2981.7329 - val_loss: 14961217.0000 - val_mae: 3397.1340\n","Epoch 26/350\n","3/3 [==============================] - 0s 21ms/step - loss: 14605591.0000 - mae: 3008.1416 - val_loss: 14140508.0000 - val_mae: 2963.6140\n","Epoch 27/350\n","3/3 [==============================] - 0s 22ms/step - loss: 13685133.0000 - mae: 2994.3076 - val_loss: 23196782.0000 - val_mae: 3455.8860\n","Epoch 28/350\n","3/3 [==============================] - 0s 21ms/step - loss: 13826805.0000 - mae: 3014.0820 - val_loss: 23791102.0000 - val_mae: 3517.2363\n","Epoch 29/350\n","3/3 [==============================] - 0s 24ms/step - loss: 13783870.0000 - mae: 3029.0286 - val_loss: 9923808.0000 - val_mae: 2445.5210\n","Epoch 30/350\n","3/3 [==============================] - 0s 21ms/step - loss: 11915883.0000 - mae: 2815.5127 - val_loss: 12267064.0000 - val_mae: 2791.0449\n","Epoch 31/350\n","3/3 [==============================] - 0s 21ms/step - loss: 12240110.0000 - mae: 2857.7732 - val_loss: 12364576.0000 - val_mae: 2798.2883\n","Epoch 32/350\n","3/3 [==============================] - 0s 25ms/step - loss: 11812839.0000 - mae: 2779.5278 - val_loss: 14090800.0000 - val_mae: 3003.4131\n","Epoch 33/350\n","3/3 [==============================] - 0s 26ms/step - loss: 11862417.0000 - mae: 2751.0017 - val_loss: 15024592.0000 - val_mae: 3155.8555\n","Epoch 34/350\n","3/3 [==============================] - 0s 21ms/step - loss: 11475137.0000 - mae: 2697.7434 - val_loss: 14981629.0000 - val_mae: 3168.4915\n","Epoch 35/350\n","3/3 [==============================] - 0s 24ms/step - loss: 11099632.0000 - mae: 2665.6445 - val_loss: 13352099.0000 - val_mae: 2956.3430\n","Epoch 36/350\n","3/3 [==============================] - 0s 24ms/step - loss: 11106739.0000 - mae: 2691.5535 - val_loss: 16158936.0000 - val_mae: 3455.4299\n","Epoch 37/350\n","3/3 [==============================] - 0s 25ms/step - loss: 10950521.0000 - mae: 2680.8057 - val_loss: 15861616.0000 - val_mae: 3407.2061\n","Epoch 38/350\n","3/3 [==============================] - 0s 24ms/step - loss: 10469206.0000 - mae: 2583.9365 - val_loss: 15941184.0000 - val_mae: 3414.2185\n","Epoch 39/350\n","3/3 [==============================] - 0s 23ms/step - loss: 10212827.0000 - mae: 2539.9751 - val_loss: 15763083.0000 - val_mae: 3389.6699\n","Epoch 40/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9961183.0000 - mae: 2523.7922 - val_loss: 15388548.0000 - val_mae: 3346.8499\n","Epoch 41/350\n","3/3 [==============================] - 0s 21ms/step - loss: 10104650.0000 - mae: 2558.6787 - val_loss: 15286381.0000 - val_mae: 3332.7180\n","Epoch 42/350\n","3/3 [==============================] - 0s 24ms/step - loss: 9914153.0000 - mae: 2523.0339 - val_loss: 15209296.0000 - val_mae: 3319.9651\n","Epoch 43/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9949614.0000 - mae: 2527.7190 - val_loss: 14529659.0000 - val_mae: 3203.7800\n","Epoch 44/350\n","3/3 [==============================] - 0s 21ms/step - loss: 10424323.0000 - mae: 2606.5454 - val_loss: 14816811.0000 - val_mae: 3201.0945\n","Epoch 45/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9985044.0000 - mae: 2521.5281 - val_loss: 14709549.0000 - val_mae: 3241.1741\n","Epoch 46/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9464130.0000 - mae: 2444.3799 - val_loss: 13184887.0000 - val_mae: 3057.0476\n","Epoch 47/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9323863.0000 - mae: 2449.0674 - val_loss: 13307141.0000 - val_mae: 3018.1550\n","Epoch 48/350\n","3/3 [==============================] - 0s 22ms/step - loss: 9124126.0000 - mae: 2409.9795 - val_loss: 16216411.0000 - val_mae: 3508.0762\n","Epoch 49/350\n","3/3 [==============================] - 0s 22ms/step - loss: 9070762.0000 - mae: 2408.0349 - val_loss: 12442056.0000 - val_mae: 3120.7229\n","Epoch 50/350\n","3/3 [==============================] - 0s 29ms/step - loss: 8981570.0000 - mae: 2403.1189 - val_loss: 12222357.0000 - val_mae: 3112.3010\n","Epoch 51/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8936942.0000 - mae: 2392.9980 - val_loss: 12127352.0000 - val_mae: 3082.7029\n","Epoch 52/350\n","3/3 [==============================] - 0s 30ms/step - loss: 8873576.0000 - mae: 2358.8806 - val_loss: 12107857.0000 - val_mae: 3034.3538\n","Epoch 53/350\n","3/3 [==============================] - 0s 28ms/step - loss: 8807333.0000 - mae: 2344.5347 - val_loss: 11809827.0000 - val_mae: 2994.7354\n","Epoch 54/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8791633.0000 - mae: 2368.0991 - val_loss: 11488403.0000 - val_mae: 2969.4709\n","Epoch 55/350\n","3/3 [==============================] - 0s 27ms/step - loss: 8796447.0000 - mae: 2369.0496 - val_loss: 11333339.0000 - val_mae: 2963.9895\n","Epoch 56/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8691273.0000 - mae: 2358.7913 - val_loss: 11997749.0000 - val_mae: 3148.2236\n","Epoch 57/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8440409.0000 - mae: 2340.4834 - val_loss: 12854667.0000 - val_mae: 3210.3564\n","Epoch 58/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8098639.5000 - mae: 2267.0229 - val_loss: 13787531.0000 - val_mae: 3283.5244\n","Epoch 59/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7976096.5000 - mae: 2237.6003 - val_loss: 13799696.0000 - val_mae: 3232.6960\n","Epoch 60/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7756826.0000 - mae: 2186.8311 - val_loss: 13348677.0000 - val_mae: 3220.7278\n","Epoch 61/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7666838.5000 - mae: 2182.6877 - val_loss: 12992720.0000 - val_mae: 3180.4402\n","Epoch 62/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7538983.5000 - mae: 2163.6338 - val_loss: 12925384.0000 - val_mae: 3136.1941\n","Epoch 63/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7780667.0000 - mae: 2216.2087 - val_loss: 12513539.0000 - val_mae: 3116.4697\n","Epoch 64/350\n","3/3 [==============================] - 0s 26ms/step - loss: 7714561.5000 - mae: 2208.2568 - val_loss: 12380908.0000 - val_mae: 3079.6829\n","Epoch 65/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7684964.5000 - mae: 2215.2244 - val_loss: 12208673.0000 - val_mae: 3069.4922\n","Epoch 66/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7471866.5000 - mae: 2147.3455 - val_loss: 9137620.0000 - val_mae: 2588.8875\n","Epoch 67/350\n","3/3 [==============================] - 0s 26ms/step - loss: 8312381.0000 - mae: 2271.1899 - val_loss: 9144496.0000 - val_mae: 2569.2512\n","Epoch 68/350\n","3/3 [==============================] - 0s 26ms/step - loss: 8278821.5000 - mae: 2280.3083 - val_loss: 8835040.0000 - val_mae: 2566.6536\n","Epoch 69/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8790316.0000 - mae: 2370.4319 - val_loss: 9707928.0000 - val_mae: 2754.2451\n","Epoch 70/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9456458.0000 - mae: 2467.4316 - val_loss: 13750151.0000 - val_mae: 3134.0374\n","Epoch 71/350\n","3/3 [==============================] - 0s 22ms/step - loss: 10480667.0000 - mae: 2563.7913 - val_loss: 18411482.0000 - val_mae: 3630.0977\n","Epoch 72/350\n","3/3 [==============================] - 0s 21ms/step - loss: 11047026.0000 - mae: 2626.8364 - val_loss: 11691205.0000 - val_mae: 2811.4001\n","Epoch 73/350\n","3/3 [==============================] - 0s 22ms/step - loss: 9885381.0000 - mae: 2454.6675 - val_loss: 11358127.0000 - val_mae: 2825.0410\n","Epoch 74/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9246169.0000 - mae: 2335.5317 - val_loss: 9956821.0000 - val_mae: 2614.8718\n","Epoch 75/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8430811.0000 - mae: 2229.3381 - val_loss: 9921935.0000 - val_mae: 2708.5125\n","Epoch 76/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7662089.0000 - mae: 2138.8301 - val_loss: 9346491.0000 - val_mae: 2753.8262\n","Epoch 77/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8845750.0000 - mae: 2286.1753 - val_loss: 13015909.0000 - val_mae: 3231.3838\n","Epoch 78/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7934697.5000 - mae: 2304.6465 - val_loss: 15106661.0000 - val_mae: 3158.8369\n","Epoch 79/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7601294.0000 - mae: 2169.1174 - val_loss: 16254735.0000 - val_mae: 3350.4534\n","Epoch 80/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7866548.5000 - mae: 2206.7253 - val_loss: 14384821.0000 - val_mae: 3069.2913\n","Epoch 81/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7981632.5000 - mae: 2256.6223 - val_loss: 15799765.0000 - val_mae: 3268.5061\n","Epoch 82/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8629248.0000 - mae: 2316.5647 - val_loss: 16707811.0000 - val_mae: 3335.2988\n","Epoch 83/350\n","3/3 [==============================] - 0s 27ms/step - loss: 8620251.0000 - mae: 2325.5762 - val_loss: 17483630.0000 - val_mae: 3349.9912\n","Epoch 84/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8805647.0000 - mae: 2329.4229 - val_loss: 17237246.0000 - val_mae: 3333.6045\n","Epoch 85/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8026425.5000 - mae: 2256.7607 - val_loss: 16678677.0000 - val_mae: 3255.7314\n","Epoch 86/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7700187.5000 - mae: 2257.6265 - val_loss: 13729683.0000 - val_mae: 3015.3713\n","Epoch 87/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7457245.5000 - mae: 2235.3584 - val_loss: 14657408.0000 - val_mae: 3220.7297\n","Epoch 88/350\n","3/3 [==============================] - 0s 24ms/step - loss: 6884341.5000 - mae: 2140.6304 - val_loss: 14318143.0000 - val_mae: 3157.5417\n","Epoch 89/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7009650.5000 - mae: 2143.8000 - val_loss: 13904380.0000 - val_mae: 3061.2097\n","Epoch 90/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7034753.5000 - mae: 2159.8455 - val_loss: 13853735.0000 - val_mae: 3062.9290\n","Epoch 91/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7118481.5000 - mae: 2139.2590 - val_loss: 13451368.0000 - val_mae: 2931.6882\n","Epoch 92/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6829588.5000 - mae: 2109.3425 - val_loss: 13430900.0000 - val_mae: 3001.2754\n","Epoch 93/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6570179.0000 - mae: 2068.5496 - val_loss: 13650116.0000 - val_mae: 3096.2395\n","Epoch 94/350\n","3/3 [==============================] - 0s 31ms/step - loss: 6547425.0000 - mae: 2086.9028 - val_loss: 13541004.0000 - val_mae: 3085.9050\n","Epoch 95/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6585129.0000 - mae: 2110.2305 - val_loss: 11774501.0000 - val_mae: 2802.1436\n","Epoch 96/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7154909.5000 - mae: 2154.2036 - val_loss: 13265696.0000 - val_mae: 2972.1672\n","Epoch 97/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7288588.5000 - mae: 2174.1025 - val_loss: 14893648.0000 - val_mae: 3124.7949\n","Epoch 98/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7307261.0000 - mae: 2171.6396 - val_loss: 15212173.0000 - val_mae: 3279.6028\n","Epoch 99/350\n","3/3 [==============================] - 0s 28ms/step - loss: 7651200.5000 - mae: 2187.0103 - val_loss: 13847069.0000 - val_mae: 3107.8723\n","Epoch 100/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7744785.0000 - mae: 2207.2046 - val_loss: 14674357.0000 - val_mae: 3211.0723\n","Epoch 101/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7708940.5000 - mae: 2188.9858 - val_loss: 14249712.0000 - val_mae: 3197.3499\n","Epoch 102/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7918394.5000 - mae: 2199.1250 - val_loss: 13874735.0000 - val_mae: 3141.4141\n","Epoch 103/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8113157.0000 - mae: 2207.7764 - val_loss: 13317395.0000 - val_mae: 3018.9246\n","Epoch 104/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8000106.0000 - mae: 2206.6306 - val_loss: 13076499.0000 - val_mae: 2977.1765\n","Epoch 105/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8042463.5000 - mae: 2273.7803 - val_loss: 13017045.0000 - val_mae: 2937.7559\n","Epoch 106/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7989361.0000 - mae: 2277.2114 - val_loss: 12816409.0000 - val_mae: 2888.1750\n","Epoch 107/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7900870.5000 - mae: 2222.1853 - val_loss: 12901732.0000 - val_mae: 2899.4551\n","Epoch 108/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7687110.5000 - mae: 2188.2537 - val_loss: 14481465.0000 - val_mae: 2885.4922\n","Epoch 109/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7699540.5000 - mae: 2172.7131 - val_loss: 14507167.0000 - val_mae: 3039.7722\n","Epoch 110/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8621398.0000 - mae: 2282.9482 - val_loss: 13449667.0000 - val_mae: 3024.3875\n","Epoch 111/350\n","3/3 [==============================] - 0s 25ms/step - loss: 9354850.0000 - mae: 2364.4192 - val_loss: 12262669.0000 - val_mae: 2937.1155\n","Epoch 112/350\n","3/3 [==============================] - 0s 24ms/step - loss: 9117984.0000 - mae: 2374.2556 - val_loss: 13009903.0000 - val_mae: 2961.4817\n","Epoch 113/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8486783.0000 - mae: 2231.5615 - val_loss: 11669117.0000 - val_mae: 2811.1350\n","Epoch 114/350\n","3/3 [==============================] - 0s 31ms/step - loss: 8184925.0000 - mae: 2250.4082 - val_loss: 12524073.0000 - val_mae: 2821.9705\n","Epoch 115/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8300178.5000 - mae: 2279.9060 - val_loss: 14309867.0000 - val_mae: 2941.0442\n","Epoch 116/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8434263.0000 - mae: 2362.3496 - val_loss: 14290360.0000 - val_mae: 2961.6201\n","Epoch 117/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8174396.5000 - mae: 2300.3052 - val_loss: 14270427.0000 - val_mae: 2940.1213\n","Epoch 118/350\n","3/3 [==============================] - 0s 26ms/step - loss: 8000932.5000 - mae: 2235.2180 - val_loss: 14045157.0000 - val_mae: 2937.2109\n","Epoch 119/350\n","3/3 [==============================] - 0s 27ms/step - loss: 7623481.0000 - mae: 2238.9143 - val_loss: 13710944.0000 - val_mae: 2969.0691\n","Epoch 120/350\n","3/3 [==============================] - 0s 20ms/step - loss: 8683512.0000 - mae: 2288.6316 - val_loss: 14538725.0000 - val_mae: 3029.2922\n","Epoch 121/350\n","3/3 [==============================] - 0s 23ms/step - loss: 9585063.0000 - mae: 2444.3181 - val_loss: 11838192.0000 - val_mae: 2849.4756\n","Epoch 122/350\n","3/3 [==============================] - 0s 19ms/step - loss: 9165252.0000 - mae: 2419.2268 - val_loss: 14225973.0000 - val_mae: 3155.5149\n","Epoch 123/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8811446.0000 - mae: 2414.7556 - val_loss: 13128480.0000 - val_mae: 2898.5254\n","Epoch 124/350\n","3/3 [==============================] - 0s 19ms/step - loss: 8616279.0000 - mae: 2340.4609 - val_loss: 18413750.0000 - val_mae: 3151.0872\n","Epoch 125/350\n","3/3 [==============================] - 0s 20ms/step - loss: 8339843.5000 - mae: 2312.1797 - val_loss: 19241706.0000 - val_mae: 3547.7712\n","Epoch 126/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8198109.5000 - mae: 2327.5928 - val_loss: 18862310.0000 - val_mae: 3259.1787\n","Epoch 127/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7844435.5000 - mae: 2218.9934 - val_loss: 19018258.0000 - val_mae: 3312.5300\n","Epoch 128/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7565478.5000 - mae: 2183.1543 - val_loss: 18921944.0000 - val_mae: 3311.9773\n","Epoch 129/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7549418.0000 - mae: 2183.8677 - val_loss: 20008880.0000 - val_mae: 3586.9802\n","Epoch 130/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7384791.0000 - mae: 2158.2705 - val_loss: 20702354.0000 - val_mae: 3698.7742\n","Epoch 131/350\n","3/3 [==============================] - 0s 19ms/step - loss: 7304246.0000 - mae: 2117.9871 - val_loss: 20912042.0000 - val_mae: 3732.1062\n","Epoch 132/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7155601.0000 - mae: 2102.9983 - val_loss: 20534510.0000 - val_mae: 3684.4778\n","Epoch 133/350\n","3/3 [==============================] - 0s 26ms/step - loss: 7237860.0000 - mae: 2149.5833 - val_loss: 20841810.0000 - val_mae: 3798.5042\n","Epoch 134/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6877358.5000 - mae: 2075.2773 - val_loss: 22248222.0000 - val_mae: 3994.9382\n","Epoch 135/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7379503.0000 - mae: 2126.6758 - val_loss: 22283458.0000 - val_mae: 4011.7927\n","Epoch 136/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7466145.0000 - mae: 2165.5491 - val_loss: 21332698.0000 - val_mae: 3882.8015\n","Epoch 137/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7124298.5000 - mae: 2100.9092 - val_loss: 22442258.0000 - val_mae: 4039.7578\n","Epoch 138/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7297100.5000 - mae: 2117.2839 - val_loss: 22234858.0000 - val_mae: 4027.9407\n","Epoch 139/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6903568.0000 - mae: 2084.2244 - val_loss: 21497072.0000 - val_mae: 3912.7842\n","Epoch 140/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7036060.0000 - mae: 2136.6367 - val_loss: 21964862.0000 - val_mae: 3996.6907\n","Epoch 141/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6771632.5000 - mae: 2039.9426 - val_loss: 22483336.0000 - val_mae: 4031.0117\n","Epoch 142/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6628630.0000 - mae: 2015.5638 - val_loss: 21486240.0000 - val_mae: 3937.8367\n","Epoch 143/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6631823.5000 - mae: 2044.7960 - val_loss: 21138862.0000 - val_mae: 3820.1477\n","Epoch 144/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6548384.5000 - mae: 2022.6388 - val_loss: 21492042.0000 - val_mae: 3888.2207\n","Epoch 145/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6574657.5000 - mae: 1999.8438 - val_loss: 21749014.0000 - val_mae: 3911.6028\n","Epoch 146/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6582474.0000 - mae: 1999.1858 - val_loss: 21066540.0000 - val_mae: 3822.4792\n","Epoch 147/350\n","3/3 [==============================] - 0s 24ms/step - loss: 6605870.5000 - mae: 2046.0529 - val_loss: 21275216.0000 - val_mae: 3886.2432\n","Epoch 148/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6634816.5000 - mae: 2004.9648 - val_loss: 21877710.0000 - val_mae: 3957.2715\n","Epoch 149/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6409081.5000 - mae: 1984.5580 - val_loss: 21376810.0000 - val_mae: 3945.1270\n","Epoch 150/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6570012.0000 - mae: 2034.2584 - val_loss: 21326534.0000 - val_mae: 3929.9617\n","Epoch 151/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6296062.0000 - mae: 1950.9788 - val_loss: 22314394.0000 - val_mae: 4037.2200\n","Epoch 152/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6576994.5000 - mae: 1983.2452 - val_loss: 21319678.0000 - val_mae: 3921.9055\n","Epoch 153/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6371572.5000 - mae: 1956.3899 - val_loss: 21346368.0000 - val_mae: 3923.7585\n","Epoch 154/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6235426.0000 - mae: 1943.7192 - val_loss: 21361726.0000 - val_mae: 3926.1155\n","Epoch 155/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6526358.0000 - mae: 2002.4680 - val_loss: 21285834.0000 - val_mae: 3911.4607\n","Epoch 156/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6194897.5000 - mae: 1902.6165 - val_loss: 22135634.0000 - val_mae: 3995.8928\n","Epoch 157/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6408403.5000 - mae: 1960.1841 - val_loss: 21128700.0000 - val_mae: 3882.2859\n","Epoch 158/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6249981.0000 - mae: 1960.8973 - val_loss: 21133176.0000 - val_mae: 3887.6218\n","Epoch 159/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6403319.0000 - mae: 1930.4114 - val_loss: 21813070.0000 - val_mae: 3974.3650\n","Epoch 160/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6159870.5000 - mae: 1913.9717 - val_loss: 21024752.0000 - val_mae: 3856.6174\n","Epoch 161/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6259428.0000 - mae: 1962.5056 - val_loss: 21061008.0000 - val_mae: 3844.3281\n","Epoch 162/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6202710.5000 - mae: 1945.6075 - val_loss: 21770160.0000 - val_mae: 3970.5251\n","Epoch 163/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6168951.5000 - mae: 1910.0996 - val_loss: 21339706.0000 - val_mae: 3917.9426\n","Epoch 164/350\n","3/3 [==============================] - 0s 26ms/step - loss: 6326104.0000 - mae: 1976.3535 - val_loss: 21233210.0000 - val_mae: 3870.5129\n","Epoch 165/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6190377.5000 - mae: 1899.9587 - val_loss: 22058438.0000 - val_mae: 3992.1904\n","Epoch 166/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6154056.5000 - mae: 1901.2994 - val_loss: 21340712.0000 - val_mae: 3910.8613\n","Epoch 167/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6050572.0000 - mae: 1904.6339 - val_loss: 21298702.0000 - val_mae: 3881.1211\n","Epoch 168/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6067881.5000 - mae: 1916.9489 - val_loss: 21533966.0000 - val_mae: 3933.0344\n","Epoch 169/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6260814.0000 - mae: 1905.6075 - val_loss: 21518724.0000 - val_mae: 3939.7512\n","Epoch 170/350\n","3/3 [==============================] - 0s 20ms/step - loss: 5958585.5000 - mae: 1872.1880 - val_loss: 21366390.0000 - val_mae: 3894.3542\n","Epoch 171/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6028037.0000 - mae: 1906.3180 - val_loss: 21388872.0000 - val_mae: 3889.6418\n","Epoch 172/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6102269.0000 - mae: 1911.1951 - val_loss: 21770064.0000 - val_mae: 3951.9319\n","Epoch 173/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6081669.5000 - mae: 1888.0763 - val_loss: 21406426.0000 - val_mae: 3906.8047\n","Epoch 174/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6044276.5000 - mae: 1899.4235 - val_loss: 21355568.0000 - val_mae: 3870.6504\n","Epoch 175/350\n","3/3 [==============================] - 0s 24ms/step - loss: 5944294.5000 - mae: 1905.8180 - val_loss: 21852014.0000 - val_mae: 3968.5645\n","Epoch 176/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6019971.5000 - mae: 1857.1492 - val_loss: 21658486.0000 - val_mae: 3948.8809\n","Epoch 177/350\n","3/3 [==============================] - 0s 24ms/step - loss: 5922411.5000 - mae: 1881.9012 - val_loss: 21394402.0000 - val_mae: 3870.4338\n","Epoch 178/350\n","3/3 [==============================] - 0s 25ms/step - loss: 6293397.0000 - mae: 1940.6777 - val_loss: 21838344.0000 - val_mae: 3956.4766\n","Epoch 179/350\n","3/3 [==============================] - 0s 27ms/step - loss: 5868604.5000 - mae: 1839.2397 - val_loss: 21379982.0000 - val_mae: 3871.8984\n","Epoch 180/350\n","3/3 [==============================] - 0s 30ms/step - loss: 6139993.5000 - mae: 1942.1931 - val_loss: 21430618.0000 - val_mae: 3870.5273\n","Epoch 181/350\n","3/3 [==============================] - 0s 24ms/step - loss: 5816366.0000 - mae: 1861.9792 - val_loss: 22543208.0000 - val_mae: 4006.5417\n","Epoch 182/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6272649.0000 - mae: 1886.5814 - val_loss: 21889834.0000 - val_mae: 3962.5684\n","Epoch 183/350\n","3/3 [==============================] - 0s 26ms/step - loss: 5958426.0000 - mae: 1881.9258 - val_loss: 21565482.0000 - val_mae: 3848.1709\n","Epoch 184/350\n","3/3 [==============================] - 0s 25ms/step - loss: 6031680.0000 - mae: 1892.6625 - val_loss: 22003600.0000 - val_mae: 3962.2805\n","Epoch 185/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6026636.0000 - mae: 1848.8557 - val_loss: 21838928.0000 - val_mae: 3935.7087\n","Epoch 186/350\n","3/3 [==============================] - 0s 24ms/step - loss: 5892973.5000 - mae: 1845.9371 - val_loss: 21585198.0000 - val_mae: 3842.8242\n","Epoch 187/350\n","3/3 [==============================] - 0s 27ms/step - loss: 5918880.5000 - mae: 1870.8713 - val_loss: 21862506.0000 - val_mae: 3935.8008\n","Epoch 188/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6312820.5000 - mae: 1888.7102 - val_loss: 22248318.0000 - val_mae: 3986.8203\n","Epoch 189/350\n","3/3 [==============================] - 0s 23ms/step - loss: 5706190.0000 - mae: 1788.6038 - val_loss: 21546848.0000 - val_mae: 3821.9993\n","Epoch 190/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6266367.5000 - mae: 1966.7068 - val_loss: 21613892.0000 - val_mae: 3889.2361\n","Epoch 191/350\n","3/3 [==============================] - 0s 23ms/step - loss: 5909739.0000 - mae: 1826.4915 - val_loss: 23390806.0000 - val_mae: 4052.7473\n","Epoch 192/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6101114.5000 - mae: 1856.3584 - val_loss: 21593798.0000 - val_mae: 3844.2019\n","Epoch 193/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6102678.5000 - mae: 1934.1698 - val_loss: 21709678.0000 - val_mae: 3879.6582\n","Epoch 194/350\n","3/3 [==============================] - 0s 23ms/step - loss: 5886736.0000 - mae: 1856.6777 - val_loss: 22534342.0000 - val_mae: 3986.6797\n","Epoch 195/350\n","3/3 [==============================] - 0s 24ms/step - loss: 6118528.5000 - mae: 1892.4481 - val_loss: 21742094.0000 - val_mae: 3891.4629\n","Epoch 196/350\n","3/3 [==============================] - 0s 21ms/step - loss: 5949722.0000 - mae: 1846.6411 - val_loss: 22019786.0000 - val_mae: 3950.7502\n","Epoch 197/350\n","3/3 [==============================] - 0s 25ms/step - loss: 5761511.5000 - mae: 1804.6010 - val_loss: 21615482.0000 - val_mae: 3885.9648\n","Epoch 198/350\n","3/3 [==============================] - 0s 22ms/step - loss: 5809059.0000 - mae: 1844.9000 - val_loss: 21722118.0000 - val_mae: 3901.6750\n","Epoch 199/350\n","3/3 [==============================] - 0s 24ms/step - loss: 5800146.5000 - mae: 1836.9321 - val_loss: 21863830.0000 - val_mae: 3910.6067\n","Epoch 200/350\n","3/3 [==============================] - 0s 22ms/step - loss: 5847685.5000 - mae: 1830.7661 - val_loss: 22120846.0000 - val_mae: 3946.5964\n","Epoch 201/350\n","3/3 [==============================] - 0s 24ms/step - loss: 6037360.0000 - mae: 1837.9509 - val_loss: 21580622.0000 - val_mae: 3846.4099\n","Epoch 202/350\n","3/3 [==============================] - 0s 23ms/step - loss: 5819725.5000 - mae: 1809.5845 - val_loss: 22319658.0000 - val_mae: 3975.5105\n","Epoch 203/350\n","3/3 [==============================] - 0s 29ms/step - loss: 5729730.0000 - mae: 1786.1284 - val_loss: 19358910.0000 - val_mae: 3368.5066\n","Epoch 204/350\n","3/3 [==============================] - 0s 26ms/step - loss: 7427222.0000 - mae: 1988.2141 - val_loss: 21585670.0000 - val_mae: 3598.1609\n","Epoch 205/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7315132.0000 - mae: 1994.5659 - val_loss: 16224371.0000 - val_mae: 3208.1921\n","Epoch 206/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8020104.5000 - mae: 2115.3318 - val_loss: 15591596.0000 - val_mae: 3141.4817\n","Epoch 207/350\n","3/3 [==============================] - 0s 28ms/step - loss: 9728433.0000 - mae: 2372.7991 - val_loss: 13941005.0000 - val_mae: 3003.7195\n","Epoch 208/350\n","3/3 [==============================] - 0s 25ms/step - loss: 11734795.0000 - mae: 2686.3245 - val_loss: 15576571.0000 - val_mae: 3249.1697\n","Epoch 209/350\n","3/3 [==============================] - 0s 26ms/step - loss: 12208504.0000 - mae: 2654.0222 - val_loss: 15233749.0000 - val_mae: 3214.5198\n","Epoch 210/350\n","3/3 [==============================] - 0s 29ms/step - loss: 12332443.0000 - mae: 2711.6267 - val_loss: 13200875.0000 - val_mae: 3036.6316\n","Epoch 211/350\n","3/3 [==============================] - 0s 26ms/step - loss: 11181188.0000 - mae: 2523.6396 - val_loss: 12773736.0000 - val_mae: 3112.6738\n","Epoch 212/350\n","3/3 [==============================] - 0s 22ms/step - loss: 10715440.0000 - mae: 2445.8787 - val_loss: 14467732.0000 - val_mae: 3282.5115\n","Epoch 213/350\n","3/3 [==============================] - 0s 22ms/step - loss: 10932732.0000 - mae: 2551.5701 - val_loss: 13691613.0000 - val_mae: 3282.7351\n","Epoch 214/350\n","3/3 [==============================] - 0s 23ms/step - loss: 13664798.0000 - mae: 2736.4910 - val_loss: 20256566.0000 - val_mae: 3656.0183\n","Epoch 215/350\n","3/3 [==============================] - 0s 23ms/step - loss: 12095031.0000 - mae: 2620.1465 - val_loss: 16121780.0000 - val_mae: 3309.9871\n","Epoch 216/350\n","3/3 [==============================] - 0s 21ms/step - loss: 13947211.0000 - mae: 2774.0894 - val_loss: 13693689.0000 - val_mae: 3313.0217\n","Epoch 217/350\n","3/3 [==============================] - 0s 25ms/step - loss: 15088722.0000 - mae: 2980.4426 - val_loss: 19040856.0000 - val_mae: 3442.5186\n","Epoch 218/350\n","3/3 [==============================] - 0s 21ms/step - loss: 15672818.0000 - mae: 3057.0601 - val_loss: 12663437.0000 - val_mae: 3044.0125\n","Epoch 219/350\n","3/3 [==============================] - 0s 20ms/step - loss: 19512794.0000 - mae: 3328.3198 - val_loss: 9216921.0000 - val_mae: 2547.5969\n","Epoch 220/350\n","3/3 [==============================] - 0s 21ms/step - loss: 12938355.0000 - mae: 2654.7322 - val_loss: 14015289.0000 - val_mae: 3001.5554\n","Epoch 221/350\n","3/3 [==============================] - 0s 19ms/step - loss: 12811109.0000 - mae: 2730.7561 - val_loss: 9609049.0000 - val_mae: 2667.2773\n","Epoch 222/350\n","3/3 [==============================] - 0s 22ms/step - loss: 9137635.0000 - mae: 2374.5864 - val_loss: 11080079.0000 - val_mae: 2602.1174\n","Epoch 223/350\n","3/3 [==============================] - 0s 20ms/step - loss: 9808869.0000 - mae: 2283.0825 - val_loss: 10045980.0000 - val_mae: 2546.7024\n","Epoch 224/350\n","3/3 [==============================] - 0s 20ms/step - loss: 9601315.0000 - mae: 2388.1067 - val_loss: 10119664.0000 - val_mae: 2590.9421\n","Epoch 225/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8854252.0000 - mae: 2358.8987 - val_loss: 11794331.0000 - val_mae: 2613.3562\n","Epoch 226/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8701472.0000 - mae: 2227.2312 - val_loss: 11183287.0000 - val_mae: 2623.8232\n","Epoch 227/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8774121.0000 - mae: 2368.6831 - val_loss: 12252732.0000 - val_mae: 2810.5869\n","Epoch 228/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8450260.0000 - mae: 2296.3772 - val_loss: 12781856.0000 - val_mae: 2748.1162\n","Epoch 229/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8921632.0000 - mae: 2388.2556 - val_loss: 11866733.0000 - val_mae: 2755.6653\n","Epoch 230/350\n","3/3 [==============================] - 0s 20ms/step - loss: 8758422.0000 - mae: 2337.3347 - val_loss: 12507920.0000 - val_mae: 2791.5012\n","Epoch 231/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8783742.0000 - mae: 2321.1851 - val_loss: 13526856.0000 - val_mae: 3133.8076\n","Epoch 232/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8664274.0000 - mae: 2325.6887 - val_loss: 14340879.0000 - val_mae: 3065.9277\n","Epoch 233/350\n","3/3 [==============================] - 0s 26ms/step - loss: 8208643.0000 - mae: 2251.0886 - val_loss: 11889009.0000 - val_mae: 3053.0652\n","Epoch 234/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7708836.5000 - mae: 2255.8621 - val_loss: 9961511.0000 - val_mae: 2749.1726\n","Epoch 235/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7456235.0000 - mae: 2180.6038 - val_loss: 10484977.0000 - val_mae: 2863.1091\n","Epoch 236/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7451590.5000 - mae: 2227.9285 - val_loss: 9712227.0000 - val_mae: 2663.9299\n","Epoch 237/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7792028.0000 - mae: 2304.6421 - val_loss: 9420947.0000 - val_mae: 2626.3064\n","Epoch 238/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8253788.0000 - mae: 2275.7856 - val_loss: 11227808.0000 - val_mae: 2912.9329\n","Epoch 239/350\n","3/3 [==============================] - 0s 23ms/step - loss: 8946528.0000 - mae: 2426.8662 - val_loss: 13096591.0000 - val_mae: 3157.3730\n","Epoch 240/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9082451.0000 - mae: 2432.5981 - val_loss: 11575832.0000 - val_mae: 2969.2219\n","Epoch 241/350\n","3/3 [==============================] - 0s 24ms/step - loss: 9278682.0000 - mae: 2485.5642 - val_loss: 10805689.0000 - val_mae: 2726.2058\n","Epoch 242/350\n","3/3 [==============================] - 0s 27ms/step - loss: 8311486.0000 - mae: 2348.4885 - val_loss: 12508379.0000 - val_mae: 2838.9094\n","Epoch 243/350\n","3/3 [==============================] - 0s 24ms/step - loss: 9710949.0000 - mae: 2553.7439 - val_loss: 10694003.0000 - val_mae: 2691.9368\n","Epoch 244/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8971825.0000 - mae: 2383.8633 - val_loss: 10773844.0000 - val_mae: 2789.5457\n","Epoch 245/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9139147.0000 - mae: 2423.1438 - val_loss: 10394803.0000 - val_mae: 2533.2092\n","Epoch 246/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9303058.0000 - mae: 2448.9561 - val_loss: 10054628.0000 - val_mae: 2638.1653\n","Epoch 247/350\n","3/3 [==============================] - 0s 21ms/step - loss: 9319320.0000 - mae: 2416.6143 - val_loss: 10689067.0000 - val_mae: 2660.6511\n","Epoch 248/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8625829.0000 - mae: 2331.7810 - val_loss: 10677152.0000 - val_mae: 2771.9094\n","Epoch 249/350\n","3/3 [==============================] - 0s 21ms/step - loss: 8703990.0000 - mae: 2352.1667 - val_loss: 11491036.0000 - val_mae: 2779.0657\n","Epoch 250/350\n","3/3 [==============================] - 0s 26ms/step - loss: 8741297.0000 - mae: 2359.4468 - val_loss: 10881917.0000 - val_mae: 2690.7295\n","Epoch 251/350\n","3/3 [==============================] - 0s 26ms/step - loss: 9358595.0000 - mae: 2391.8970 - val_loss: 10715881.0000 - val_mae: 2684.3643\n","Epoch 252/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8904780.0000 - mae: 2366.6450 - val_loss: 12097133.0000 - val_mae: 2742.8464\n","Epoch 253/350\n","3/3 [==============================] - 0s 22ms/step - loss: 8606417.0000 - mae: 2377.2390 - val_loss: 11411496.0000 - val_mae: 2848.1895\n","Epoch 254/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8571762.0000 - mae: 2278.8411 - val_loss: 10865863.0000 - val_mae: 2591.0471\n","Epoch 255/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8366827.0000 - mae: 2296.2190 - val_loss: 10573760.0000 - val_mae: 2611.5588\n","Epoch 256/350\n","3/3 [==============================] - 0s 24ms/step - loss: 8403963.0000 - mae: 2324.1553 - val_loss: 11361275.0000 - val_mae: 2696.1926\n","Epoch 257/350\n","3/3 [==============================] - 0s 29ms/step - loss: 8102938.0000 - mae: 2227.9392 - val_loss: 11614197.0000 - val_mae: 2844.6963\n","Epoch 258/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7993711.0000 - mae: 2267.7510 - val_loss: 12671123.0000 - val_mae: 2787.3821\n","Epoch 259/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7750275.0000 - mae: 2206.0530 - val_loss: 12201013.0000 - val_mae: 2931.0027\n","Epoch 260/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8320211.0000 - mae: 2259.6450 - val_loss: 12448431.0000 - val_mae: 2771.2024\n","Epoch 261/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8188452.0000 - mae: 2298.5801 - val_loss: 12607435.0000 - val_mae: 2783.2581\n","Epoch 262/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7758825.0000 - mae: 2230.2224 - val_loss: 12941037.0000 - val_mae: 3013.6746\n","Epoch 263/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7704934.5000 - mae: 2198.1260 - val_loss: 13858344.0000 - val_mae: 2916.0925\n","Epoch 264/350\n","3/3 [==============================] - 0s 25ms/step - loss: 8698906.0000 - mae: 2328.1091 - val_loss: 12647229.0000 - val_mae: 2874.6746\n","Epoch 265/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7935137.0000 - mae: 2235.7729 - val_loss: 12868905.0000 - val_mae: 2968.0554\n","Epoch 266/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7423483.0000 - mae: 2171.2080 - val_loss: 13330311.0000 - val_mae: 2880.6003\n","Epoch 267/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7707525.5000 - mae: 2229.9280 - val_loss: 12676847.0000 - val_mae: 2866.7903\n","Epoch 268/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7816418.0000 - mae: 2207.0686 - val_loss: 12703535.0000 - val_mae: 2898.3535\n","Epoch 269/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7116812.5000 - mae: 2137.1477 - val_loss: 13453909.0000 - val_mae: 2930.3164\n","Epoch 270/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7425322.0000 - mae: 2184.2197 - val_loss: 13390016.0000 - val_mae: 2963.1367\n","Epoch 271/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7211527.0000 - mae: 2146.3081 - val_loss: 13448815.0000 - val_mae: 2961.0950\n","Epoch 272/350\n","3/3 [==============================] - 0s 30ms/step - loss: 7496138.5000 - mae: 2207.6746 - val_loss: 13609124.0000 - val_mae: 2932.5928\n","Epoch 273/350\n","3/3 [==============================] - 0s 28ms/step - loss: 7111424.0000 - mae: 2141.1345 - val_loss: 13856385.0000 - val_mae: 3092.4094\n","Epoch 274/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7471839.5000 - mae: 2194.0413 - val_loss: 13402055.0000 - val_mae: 2899.3359\n","Epoch 275/350\n","3/3 [==============================] - 0s 25ms/step - loss: 7163471.5000 - mae: 2141.5957 - val_loss: 13328525.0000 - val_mae: 2931.7590\n","Epoch 276/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7382647.5000 - mae: 2164.8342 - val_loss: 13242363.0000 - val_mae: 2887.5957\n","Epoch 277/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7609091.0000 - mae: 2226.8843 - val_loss: 13538000.0000 - val_mae: 2905.5471\n","Epoch 278/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6932972.5000 - mae: 2090.8081 - val_loss: 14631117.0000 - val_mae: 3178.6523\n","Epoch 279/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7853610.0000 - mae: 2215.9980 - val_loss: 14438628.0000 - val_mae: 3016.8274\n","Epoch 280/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7486473.0000 - mae: 2182.0569 - val_loss: 14099512.0000 - val_mae: 3029.7839\n","Epoch 281/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7230894.5000 - mae: 2144.5183 - val_loss: 14063251.0000 - val_mae: 2979.9241\n","Epoch 282/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7136433.0000 - mae: 2129.7822 - val_loss: 14304859.0000 - val_mae: 2994.0098\n","Epoch 283/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7140722.5000 - mae: 2144.9106 - val_loss: 14292589.0000 - val_mae: 2994.8223\n","Epoch 284/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7144543.5000 - mae: 2124.8220 - val_loss: 14221627.0000 - val_mae: 3040.2605\n","Epoch 285/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7093161.0000 - mae: 2115.9700 - val_loss: 14169197.0000 - val_mae: 2978.4299\n","Epoch 286/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6988734.0000 - mae: 2110.3748 - val_loss: 14186557.0000 - val_mae: 2985.6006\n","Epoch 287/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7017537.5000 - mae: 2119.6345 - val_loss: 13282464.0000 - val_mae: 2942.7629\n","Epoch 288/350\n","3/3 [==============================] - 0s 27ms/step - loss: 7266028.5000 - mae: 2164.4602 - val_loss: 14332965.0000 - val_mae: 2965.5320\n","Epoch 289/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7640925.5000 - mae: 2276.5420 - val_loss: 13650587.0000 - val_mae: 3029.8665\n","Epoch 290/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7491802.0000 - mae: 2234.5986 - val_loss: 12926947.0000 - val_mae: 2892.2156\n","Epoch 291/350\n","3/3 [==============================] - 0s 28ms/step - loss: 7357090.0000 - mae: 2225.1924 - val_loss: 12907141.0000 - val_mae: 2926.1633\n","Epoch 292/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7271055.5000 - mae: 2188.1606 - val_loss: 14226461.0000 - val_mae: 3046.2500\n","Epoch 293/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7408787.5000 - mae: 2227.7390 - val_loss: 12957021.0000 - val_mae: 2867.8125\n","Epoch 294/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7574355.5000 - mae: 2242.7795 - val_loss: 12410293.0000 - val_mae: 2892.6765\n","Epoch 295/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7044033.5000 - mae: 2145.4907 - val_loss: 13581833.0000 - val_mae: 2964.3225\n","Epoch 296/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6983982.5000 - mae: 2148.3406 - val_loss: 11611099.0000 - val_mae: 2728.1492\n","Epoch 297/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6953119.0000 - mae: 2120.3357 - val_loss: 11692593.0000 - val_mae: 2657.9841\n","Epoch 298/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6727355.0000 - mae: 2115.7827 - val_loss: 12577672.0000 - val_mae: 2826.6980\n","Epoch 299/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6836125.5000 - mae: 2125.7520 - val_loss: 11703648.0000 - val_mae: 2682.5906\n","Epoch 300/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6707904.5000 - mae: 2107.3892 - val_loss: 12031133.0000 - val_mae: 2723.1169\n","Epoch 301/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6850614.0000 - mae: 2122.6716 - val_loss: 12323372.0000 - val_mae: 2750.2063\n","Epoch 302/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6717284.0000 - mae: 2121.5513 - val_loss: 11859307.0000 - val_mae: 2800.6980\n","Epoch 303/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7280490.0000 - mae: 2159.6768 - val_loss: 12682315.0000 - val_mae: 2783.5754\n","Epoch 304/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6465560.5000 - mae: 2042.1803 - val_loss: 12050407.0000 - val_mae: 2840.9656\n","Epoch 305/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6688658.5000 - mae: 2104.1860 - val_loss: 12900409.0000 - val_mae: 2817.9436\n","Epoch 306/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6725673.5000 - mae: 2124.0020 - val_loss: 12130029.0000 - val_mae: 2740.0535\n","Epoch 307/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6478060.5000 - mae: 2081.9758 - val_loss: 11748232.0000 - val_mae: 2783.2068\n","Epoch 308/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7044031.5000 - mae: 2174.7158 - val_loss: 12613645.0000 - val_mae: 2770.7354\n","Epoch 309/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6793769.5000 - mae: 2123.1868 - val_loss: 12750833.0000 - val_mae: 2844.5410\n","Epoch 310/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6745823.5000 - mae: 2129.4956 - val_loss: 12771320.0000 - val_mae: 3000.2217\n","Epoch 311/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6910808.5000 - mae: 2162.9695 - val_loss: 13488640.0000 - val_mae: 2920.1758\n","Epoch 312/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7222938.0000 - mae: 2220.0254 - val_loss: 12629479.0000 - val_mae: 2969.0334\n","Epoch 313/350\n","3/3 [==============================] - 0s 21ms/step - loss: 6770767.0000 - mae: 2135.7913 - val_loss: 13389059.0000 - val_mae: 2923.5125\n","Epoch 314/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6667463.0000 - mae: 2116.3892 - val_loss: 11772817.0000 - val_mae: 2902.0051\n","Epoch 315/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7102726.5000 - mae: 2153.0293 - val_loss: 11780640.0000 - val_mae: 2842.4358\n","Epoch 316/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7035530.5000 - mae: 2144.2358 - val_loss: 12081927.0000 - val_mae: 2825.5750\n","Epoch 317/350\n","3/3 [==============================] - 0s 31ms/step - loss: 6648161.0000 - mae: 2109.4771 - val_loss: 12835947.0000 - val_mae: 2839.1516\n","Epoch 318/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7299837.0000 - mae: 2161.9119 - val_loss: 11760495.0000 - val_mae: 2850.5430\n","Epoch 319/350\n","3/3 [==============================] - 0s 22ms/step - loss: 6841996.5000 - mae: 2157.2329 - val_loss: 13491104.0000 - val_mae: 2872.1238\n","Epoch 320/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6711557.5000 - mae: 2100.7087 - val_loss: 11866504.0000 - val_mae: 2943.9446\n","Epoch 321/350\n","3/3 [==============================] - 0s 24ms/step - loss: 7065757.5000 - mae: 2118.4023 - val_loss: 11905688.0000 - val_mae: 2766.3337\n","Epoch 322/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7066766.0000 - mae: 2161.5415 - val_loss: 11663215.0000 - val_mae: 2750.2571\n","Epoch 323/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7353442.5000 - mae: 2202.5171 - val_loss: 11818488.0000 - val_mae: 2878.3879\n","Epoch 324/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6910309.5000 - mae: 2134.9060 - val_loss: 13738552.0000 - val_mae: 2916.8008\n","Epoch 325/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7412933.5000 - mae: 2196.8845 - val_loss: 12289155.0000 - val_mae: 3009.3008\n","Epoch 326/350\n","3/3 [==============================] - 0s 23ms/step - loss: 7018432.5000 - mae: 2189.4595 - val_loss: 14336216.0000 - val_mae: 3007.2234\n","Epoch 327/350\n","3/3 [==============================] - 0s 22ms/step - loss: 7088770.0000 - mae: 2129.9324 - val_loss: 12227296.0000 - val_mae: 2974.9880\n","Epoch 328/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6875226.0000 - mae: 2114.2114 - val_loss: 12836615.0000 - val_mae: 2866.3704\n","Epoch 329/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7305743.5000 - mae: 2210.5603 - val_loss: 12759331.0000 - val_mae: 2846.1238\n","Epoch 330/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6306974.0000 - mae: 1990.0146 - val_loss: 12257387.0000 - val_mae: 3022.2991\n","Epoch 331/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7122947.5000 - mae: 2106.7566 - val_loss: 13387511.0000 - val_mae: 2869.2070\n","Epoch 332/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6922162.0000 - mae: 2125.2053 - val_loss: 11846493.0000 - val_mae: 2836.7910\n","Epoch 333/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6515869.0000 - mae: 2065.7126 - val_loss: 12421203.0000 - val_mae: 2827.3323\n","Epoch 334/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6713898.0000 - mae: 2110.2708 - val_loss: 12031856.0000 - val_mae: 2885.3428\n","Epoch 335/350\n","3/3 [==============================] - 0s 24ms/step - loss: 6705015.0000 - mae: 2092.0635 - val_loss: 12156771.0000 - val_mae: 2906.5146\n","Epoch 336/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7117217.0000 - mae: 2161.3438 - val_loss: 12847553.0000 - val_mae: 2847.2910\n","Epoch 337/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6452851.5000 - mae: 2090.5186 - val_loss: 11951053.0000 - val_mae: 2933.0012\n","Epoch 338/350\n","3/3 [==============================] - 0s 34ms/step - loss: 6714036.5000 - mae: 2122.6106 - val_loss: 13227023.0000 - val_mae: 2881.4949\n","Epoch 339/350\n","3/3 [==============================] - 0s 19ms/step - loss: 6875997.5000 - mae: 2144.8276 - val_loss: 12245823.0000 - val_mae: 2835.0940\n","Epoch 340/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7210590.0000 - mae: 2169.6125 - val_loss: 11969660.0000 - val_mae: 2876.6951\n","Epoch 341/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6627727.0000 - mae: 2077.3967 - val_loss: 14819979.0000 - val_mae: 3047.9739\n","Epoch 342/350\n","3/3 [==============================] - 0s 23ms/step - loss: 6624870.5000 - mae: 2098.8528 - val_loss: 12144671.0000 - val_mae: 2981.0027\n","Epoch 343/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6932137.0000 - mae: 2127.5813 - val_loss: 13441000.0000 - val_mae: 2913.2852\n","Epoch 344/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7255197.5000 - mae: 2175.8716 - val_loss: 12551176.0000 - val_mae: 2871.4082\n","Epoch 345/350\n","3/3 [==============================] - 0s 21ms/step - loss: 7673303.0000 - mae: 2163.9807 - val_loss: 13254640.0000 - val_mae: 3115.5676\n","Epoch 346/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7058330.0000 - mae: 2204.4568 - val_loss: 17888498.0000 - val_mae: 3467.0090\n","Epoch 347/350\n","3/3 [==============================] - 0s 20ms/step - loss: 8402664.0000 - mae: 2307.3823 - val_loss: 13249953.0000 - val_mae: 3070.4727\n","Epoch 348/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6907238.0000 - mae: 2110.5261 - val_loss: 13367288.0000 - val_mae: 2870.5271\n","Epoch 349/350\n","3/3 [==============================] - 0s 20ms/step - loss: 6934092.0000 - mae: 2147.8955 - val_loss: 12503785.0000 - val_mae: 3122.6348\n","Epoch 350/350\n","3/3 [==============================] - 0s 20ms/step - loss: 7531380.5000 - mae: 2238.7456 - val_loss: 10630804.0000 - val_mae: 2692.4602\n","MSE: 10630804.000, RMSE: 3260.491, MAE: 2692.460\n","Predicted: 16885.064\n"]}]},{"cell_type":"markdown","source":["#**Further Reading**"],"metadata":{"id":"06FiR25s_vrs"}},{"cell_type":"markdown","source":["## Related Tutorials\n","\n","* [How to Control the Stability of Training Neural Networks With the Batch Size](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/)\n","* [A Gentle Introduction to the Rectified Linear Unit (ReLU)](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)\n","* [Difference Between Classification and Regression in Machine Learning](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)\n","* [How to Manually Scale Image Pixel Data for Deep Learning](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/)\n","* [4 Common Machine Learning Data Transforms for Time Series Forecasting](https://machinelearningmastery.com/machine-learning-data-transforms-for-time-series-forecasting/)\n","* [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)\n","* [A Gentle Introduction to Dropout for Regularizing Deep Neural Networks](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)\n","* [A Gentle Introduction to Batch Normalization for Deep Neural Networks](https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/)\n","* [A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/)"],"metadata":{"id":"Friol9PKBk68"}},{"cell_type":"markdown","source":["# **Summary**"],"metadata":{"id":"d0mQaLJhT1Pz"}},{"cell_type":"markdown","source":["In this tutorial, you discovered a step-by-step guide to developing deep learning models in TensorFlow using the tf.keras API.\n","\n","Specifically, you learned:\n","\n","* The difference between Keras and tf.keras and how to install and confirm TensorFlow is working.\n","* The 5-step life-cycle of tf.keras models and how to use the sequential and functional APIs.\n","* How to develop MLP, CNN, and RNN models with tf.keras for regression, classification, and time series forecasting.\n","* How to use the advanced features of the tf.keras API to inspect and diagnose your model.\n","* How to improve the performance of your tf.keras model by reducing overfitting and accelerating training."],"metadata":{"id":"tu9E1LAqT4tq"}}]}