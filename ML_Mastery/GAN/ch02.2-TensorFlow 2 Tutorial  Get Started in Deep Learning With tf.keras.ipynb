{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ch02.2-TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNpcjTEfKoz26rOcXHQeLRQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#How to develop deep learning models with keras\n","- [Your First Deep Learning Project in Python with Keras Step-By-Step](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/), by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on July 24, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/), last updated Oct 13, 2021\n","- [TensorFlow 2 Tutorial: Get Started in Deep Learning With tf.keras](https://machinelearningmastery.com/tensorflow-tutorial-deep-learning-with-tf-keras/) by [Jason Brownlee](https://machinelearningmastery.com/author/jasonb/) on December 19, 2019 in [Deep Learning](https://machinelearningmastery.com/category/deep-learning/)\n","- Excerpt by Ivan HP Lin (WIP)\n","\n"],"metadata":{"id":"eXOBpP8hetBo"}},{"cell_type":"markdown","source":["# 0. **TensorFlow Tutorial Overview**"],"metadata":{"id":"BLNB5Pa5UWy6"}},{"cell_type":"markdown","source":["It is a large tutorial and as such, it is divided into five parts; they are:\n","\n","1. **Install TensorFlow and tf.keras**\n","  - What Are Keras and tf.keras?\n","  - How to Install TensorFlow\n","  - How to Confirm TensorFlow Is Installed\n","2. **Deep Learning Model Life-Cycle**\n","  - The 5-Step Model Life-Cycle\n","  - Sequential Model API (Simple)\n","  - Functional Model API (Advanced)\n","3. **How to Develop Deep Learning Models**\n","  - Develop Multilayer Perceptron Models\n","  - Develop Convolutional Neural Network Models\n","  - Develop Recurrent Neural Network Models\n","4. **How to Use Advanced Model Features**\n","  - How to Visualize a Deep Learning Model\n","  - How to Plot Model Learning Curves\n","  - How to Save and Load Your Model\n","5. **How to Get Better Model Performance**\n","  - How to Reduce Overfitting With Dropout\n","  - How to Accelerate Training With Batch Normalization\n","  - How to Halt Training at the Right Time With Early Stopping\n","\n","You Can Do Deep Learning in Python!"],"metadata":{"id":"VNK3MJOqUj_i"}},{"cell_type":"markdown","source":["#1. Install Tensorflow and tf.keras"],"metadata":{"id":"bRfDX0FF1mvf"}},{"cell_type":"markdown","source":["In 2019, Google released a new version of their TensorFlow deep learning library (TensorFlow 2) that integrated the Keras API directly and promoted this interface as the default or standard interface for deep learning development on the platform.\n","\n","This integration is commonly referred to as the ***tf.keras*** interface or API (“tf” is short for “TensorFlow“). This is to distinguish it from the so-called standalone Keras open source project.\n","\n","* **Standalone Keras**. The standalone open source project that supports TensorFlow, Theano and CNTK backends.\n","* **tf.keras**. The Keras API integrated into TensorFlow 2."],"metadata":{"id":"2zw5ZooX1_92"}},{"cell_type":"code","source":["# example of tf.keras python idiom\n","import tensorflow as tf\n","# use keras API\n","model = tf.keras.Sequential()\n","..."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzktPmMf14QI","executionInfo":{"status":"ok","timestamp":1651122873006,"user_tz":-480,"elapsed":3190,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"96c3c87f-beba-4d78-b7b6-cf972603b9aa"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# check version\n","import tensorflow\n","print(tensorflow.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1sv-OoC1tpv","executionInfo":{"status":"ok","timestamp":1651122873006,"user_tz":-480,"elapsed":6,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"90f53ed1-6001-47c8-cce6-4901c417329c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.0\n"]}]},{"cell_type":"markdown","source":["# 2. Deep Learning Model Life-Cycle"],"metadata":{"id":"HuQZbnMf2Z3f"}},{"cell_type":"markdown","source":["## 2.1 The 5-Step Model Life-\n","The five steps in the life-cycle are as follows:\n","\n","1. Define the model.\n","2. Compile the model.\n","3. Fit the model.\n","4. Evaluate the model.\n","5. Make predictions.\n","\n","Example from Ivan's revised code - [How to develop deep learning models with keras](https://colab.research.google.com/drive/1mjhUSBDEjyr_IA5oxH4XaTiPY_l_-jEd#scrollTo=eXOBpP8hetBo)"],"metadata":{"id":"GyCYAhD32f5F"}},{"cell_type":"markdown","source":["### 2.1.1 Define the Model\n","\n","From an API perspective, this involves defining the layers of the model, configuring each layer with a number of nodes and activation function, and connecting the layers together into a cohesive model.\n","\n","Models can be defined either with the **Sequential API** or the **Functional API**"],"metadata":{"id":"0rJmIxRl5YAc"}},{"cell_type":"markdown","source":["### 2.1.2 Compile the Model\n","\n","Compiling the model requires that you first select a **loss function** that you want to optimize, such as **mean squared error** or **cross-entropy**.\n","\n","It also requires that you select an algorithm to perform the optimization procedure, typically **stochastic gradient descent**, or a modern variation, such as **Adam**. It may also require that you select any **performance metrics** to keep track of during the model training process.\n","\n","From an API perspective, this involves calling a function to compile the model with the chosen configuration, which will prepare the appropriate data structures required for the efficient use of the model you have defined.\n","\n","The optimizer can be specified as a string for a known optimizer class, e.g. ‘sgd‘ for stochastic gradient descent, or you can configure an instance of an optimizer class and use that.\n","```\n","# compile the model\n","opt = SGD(learning_rate=0.01, momentum=0.9)\n","model.compile(optimizer=opt, loss='binary_crossentropy')\n","```\n","\n"],"metadata":{"id":"ltJUhP69531l"}},{"cell_type":"markdown","source":["The three most common loss functions are:\n","\n","* ‘***binary_crossentropy***‘ for binary classification.\n","* ‘***sparse_categorical_crossentropy***‘ for multi-class classification.\n","* ***‘mse‘*** (mean squared error) for regression.\n","\n","For a list of supported loss functions, see:\n","[tf.keras Loss Functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses)"],"metadata":{"id":"mP19LyGW_PZe"}},{"cell_type":"markdown","source":["Metrics are defined as a list of strings for known metric functions or a list of functions to call to evaluate predictions.\n","\n","For a list of supported metrics, see:\n","\n","[tf.keras Metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics)\n","\n","```\n","# compile the model\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","```"],"metadata":{"id":"02ChXaVo_wjd"}},{"cell_type":"markdown","source":["### 2.1.3 **Fit the Model**\n","\n","Fitting the model requires that you first select the training configuration, such as the number of epochs (loops through the training dataset) and the batch size (number of samples in an epoch used to estimate model error).\n","\n","Training applies the chosen optimization algorithm to minimize the chosen loss function and updates the model using the backpropagation of error algorithm.\n","\n","Fitting the model is the slow part of the whole process and can take seconds to hours to days, depending on the complexity of the model, the hardware you’re using, and the size of the training dataset.\n","\n","From an API perspective, this involves calling a function to perform the training process. This function will block (not return) until the training process has finished.\n","\n","```\n","...\n","# fit the model\n","model.fit(X, y, epochs=100, batch_size=32)\n","```"],"metadata":{"id":"a9pZMVNXlkJt"}},{"cell_type":"markdown","source":["While fitting the model, a progress bar will summarize the status of each epoch and the overall training process. This can be simplified to a simple report of model performance each epoch by setting the “verbose” argument to 2. All output can be turned off during training by setting “verbose” to 0.\n","```\n","...\n","# fit the model\n","model.fit(X, y, epochs=100, batch_size=32, verbose=0)\n","```"],"metadata":{"id":"FoLIN4hymPeV"}},{"cell_type":"markdown","source":["### 2.1.4 **Evaluate the Model**"],"metadata":{"id":"BMs1LQqa3dSI"}},{"cell_type":"markdown","source":["The speed of model evaluation is proportional to the amount of data you want to use for the evaluation, although it is much faster than training as the model is not changed.\n","\n","From an API perspective, this involves calling a function with the holdout dataset and getting a loss and perhaps other metrics that can be reported.\n","\n","```\n","...\n","# evaluate the model\n","loss = model.evaluate(X, y, verbose=0)\n","```"],"metadata":{"id":"w7DU4UJV3pMY"}},{"cell_type":"markdown","source":["### 2.1.5 **Make a Prediction**"],"metadata":{"id":"0ECQZWOF4BWA"}},{"cell_type":"markdown","source":["It requires you have new data for which a prediction is required, e.g. where you do not have the target values.\n","\n","From an API perspective, you simply call a function to make a prediction of a class label, probability, or numerical value: whatever you designed your model to predict.\n","\n","You may want to save the model and later load it to make predictions. You may also choose to fit a model on all of the available data before you start using it.\n","```\n","...\n","# make a prediction\n","yhat = model.predict(X)\n","```"],"metadata":{"id":"UWm8M2fk4LfP"}},{"cell_type":"markdown","source":["## **2.2 Sequential Model API (Simple)**"],"metadata":{"id":"XmafvkUm4UUo"}},{"cell_type":"markdown","source":["It is referred to as “**sequential**” because it involves defining a [Sequential class](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) and adding layers to the model one by one in a linear manner, from input to output.\n","\n","The example below defines a Sequential MLP model that accepts eight inputs, has one hidden layer with 10 nodes and then an output layer with one node to predict a numerical value."],"metadata":{"id":"_bNb5Gif4pOH"}},{"cell_type":"code","source":["# example of a model defined with the sequential api\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","# define the model\n","model = Sequential()\n","model.add(Dense(10, input_shape=(8,)))\n","model.add(Dense(1))"],"metadata":{"id":"JHDPScGD45H6","executionInfo":{"status":"ok","timestamp":1651161448305,"user_tz":-480,"elapsed":3382,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Note that the visible layer of the network is defined by the “**input_shape**” argument on the first hidden layer. That means in the above example, the model expects the input for one sample to be a vector of eight numbers.\n","\n","The sequential API is easy to use because you keep calling **model.add()** until you have added all of your layers.\n","\n","For example, here is a deep MLP with five hidden layers."],"metadata":{"id":"_SpGvJTr5E3P"}},{"cell_type":"code","source":["# example of a model defined with the sequential api\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","# define the model\n","model = Sequential()\n","model.add(Dense(100, input_shape=(8,)))\n","model.add(Dense(80))\n","model.add(Dense(30))\n","model.add(Dense(10))\n","model.add(Dense(5))\n","model.add(Dense(1))"],"metadata":{"id":"UwrEG43k5O9Y","executionInfo":{"status":"ok","timestamp":1651161499319,"user_tz":-480,"elapsed":318,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## **2.3 Functional Model API (Advanced)**\n","\n","The functional API is more complex but is also more flexible.\n","It involves explicitly connecting the output of one layer to the input of another layer. Each connection is specified."],"metadata":{"id":"DDPAzO0u5ZmF"}},{"cell_type":"markdown","source":["1. First, an input layer must be defined via the Input class, and the shape of an input sample is specified\n","```\n","# define the layers\n","x_in = Input(shape=(8,))\n","```\n","2. Next, a fully connected layer can be connected to the input by calling the layer and passing the input layer. This will return a reference to the output connection in this new layer.\n","```\n","...\n","x = Dense(10)(x_in)\n","```\n","3. We can then connect this to an output layer in the same manner.\n","```\n","...\n","x_out = Dense(1)(x)\n","```\n","4. Once connected, we define a Model object and specify the input and output layers. The complete example is listed below."],"metadata":{"id":"NcuqQfkX51dn"}},{"cell_type":"code","source":["# example of a model defined with the functional api\n","from tensorflow.keras import Model\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import Dense\n","# define the layers\n","x_in = Input(shape=(8,))\n","x = Dense(10)(x_in)\n","x_out = Dense(1)(x)\n","# define the model\n","model = Model(inputs=x_in, outputs=x_out)"],"metadata":{"id":"nVKcksd35uFF","executionInfo":{"status":"ok","timestamp":1651161784028,"user_tz":-480,"elapsed":286,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# 3. How to Develop Deep Learning Models\n"],"metadata":{"id":"EUqd7wPL8o8G"}},{"cell_type":"markdown","source":["## 3.1 **Multilayer Perceptron Models - MLP**\n","There are three predictive modeling problems you may want to explore with an MLP; they are binary classification, multiclass classification, and regression."],"metadata":{"id":"CuT1SCwQ9ggF"}},{"cell_type":"markdown","source":["### 3.1.1 **MLP for Binary Classification**\n","\n","We will use the Ionosphere binary (two-class) classification dataset to demonstrate an MLP for binary classification.  This dataset involves predicting whether a structure is in the atmosphere or not given radar returns.\n","\n","- [Ionosphere Dataset (csv).](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv)\n","- [Ionosphere Dataset Description (csv).](https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.names)\n","\n","We will use a [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to encode the string labels to integer values 0 and 1. The model will be fit on 67 percent of the data, and the remaining 33 percent will be used for evaluation, split using the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function.\n","\n","It is a good practice to use ‘***relu***‘ activation with a ‘***he_normal***‘ weight initialization. This combination goes a long way to overcome the problem of vanishing gradients when training deep neural network models. For more on ReLU, see the tutorial:"],"metadata":{"id":"i3MDO1CQ8_-G"}},{"cell_type":"markdown","source":["The model predicts the probability of class 1 and uses the sigmoid activation function. The model is optimized using the [adam version of stochastic gradient descent](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) and seeks to minimize the [cross-entropy loss](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)."],"metadata":{"id":"hbqnLJKf-_Pc"}},{"cell_type":"code","source":["# mlp for binary classification\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n","\n","# make a prediction\n","row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etCpM9rM_NCr","executionInfo":{"status":"ok","timestamp":1651163215517,"user_tz":-480,"elapsed":2892,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"c9245e49-2551-4e34-e6b1-b8eae451c16f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(235, 34) (116, 34) (235,) (116,)\n","Test Accuracy: 0.974\n","Predicted: 0.996\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"TVpiF087G2ja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.1.2 **MLP for Multiclass Classification**"],"metadata":{"id":"R1aiCt8dGUfE"}},{"cell_type":"markdown","source":["We will use the Iris flowers multiclass classification dataset to demonstrate an MLP for multiclass classification.  This problem involves predicting the species of iris flower given measures of the flower.\n","\n","- [Iris Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv).\n","- [Iris Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.names)."],"metadata":{"id":"E_A10wGEGiIk"}},{"cell_type":"markdown","source":["Given that it is a multiclass classification, the model must have one node for each class in the output layer and use the softmax activation function. The loss function is the ‘***sparse_categorical_crossentropy***‘, which is appropriate for integer encoded class labels (e.g. 0 for one class, 1 for the next class, etc.)"],"metadata":{"id":"k7fuD5yPG3cC"}},{"cell_type":"code","source":["# mlp for multiclass classification\n","from numpy import argmax\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# ensure all data are floating point values\n","X = X.astype('float32')\n","\n","# encode strings to integer\n","y = LabelEncoder().fit_transform(y)\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(3, activation='softmax'))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print('Test Accuracy: %.3f' % acc)\n","\n","# make a prediction\n","row = [5.1,3.5,1.4,0.2]\n","yhat = model.predict([row])\n","print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2FZ0ianG89p","executionInfo":{"status":"ok","timestamp":1651165123522,"user_tz":-480,"elapsed":2238,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"5688e5ec-9f47-4164-ad39-953f98a905c4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 4) (50, 4) (100,) (50,)\n","Test Accuracy: 0.960\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13d4912c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","Predicted: [[0.95480573 0.0392486  0.00594568]] (class=0)\n"]}]},{"cell_type":"markdown","source":["### 3.1.3 **MLP for Regression**\n","\n","The regression problem involves predicting a single numerical value. As such, the output layer has a single node and uses the default or linear activation function (no activation function). The mean squared error (mse) loss is minimized when fitting the model."],"metadata":{"id":"sQgaS-uFHzmK"}},{"cell_type":"markdown","source":["We will use the Boston housing regression dataset to demonstrate an MLP for regression predictive modeling.\n","\n","This problem involves predicting house value based on properties of the house and neighborhood.\n","\n","- [Boston Housing Dataset (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv).\n","- [Boston Housing Dataset Description (csv)](https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.names).\n","\n","\n","[**Difference Between Classification and Regression in Machine Learning**](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)"],"metadata":{"id":"i1u9faXoICRQ"}},{"cell_type":"code","source":["# mlp for regression\n","from numpy import sqrt\n","from pandas import read_csv\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# load the dataset\n","path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n","df = read_csv(path, header=None)\n","\n","# split into input and output columns\n","X, y = df.values[:, :-1], df.values[:, -1]\n","\n","# split into train and test datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# determine the number of input features\n","n_features = X_train.shape[1]\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n","model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n","model.add(Dense(1))\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='mse')\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n","\n","# evaluate the model\n","error = model.evaluate(X_test, y_test, verbose=0)\n","print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))\n","\n","# make a prediction\n","row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n","yhat = model.predict([row])\n","print('Predicted: %.3f' % yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yo2NI9p8IfdK","executionInfo":{"status":"ok","timestamp":1651165540739,"user_tz":-480,"elapsed":3623,"user":{"displayName":"HP Ivan Lin","userId":"15345680110015535826"}},"outputId":"4407a516-d45f-47ae-8b59-b57280dc851a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["(339, 13) (167, 13) (339,) (167,)\n","MSE: 49.623, RMSE: 7.044\n","Predicted: 24.917\n"]}]},{"cell_type":"markdown","source":["#**Further Reading**"],"metadata":{"id":"06FiR25s_vrs"}},{"cell_type":"markdown","source":["## Related Tutorials\n","\n","* [How to Control the Stability of Training Neural Networks With the Batch Size](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/)\n","* [A Gentle Introduction to the Rectified Linear Unit (ReLU)](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/)\n","* [Difference Between Classification and Regression in Machine Learning](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/)\n","* [How to Manually Scale Image Pixel Data for Deep Learning](https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/)\n","* [4 Common Machine Learning Data Transforms for Time Series Forecasting](https://machinelearningmastery.com/machine-learning-data-transforms-for-time-series-forecasting/)\n","* [How to use Learning Curves to Diagnose Machine Learning Model Performance](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/)\n","* [A Gentle Introduction to Dropout for Regularizing Deep Neural Networks](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)\n","* [A Gentle Introduction to Batch Normalization for Deep Neural Networks](https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/)\n","* [A Gentle Introduction to Early Stopping to Avoid Overtraining Neural Networks](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/)"],"metadata":{"id":"Friol9PKBk68"}},{"cell_type":"markdown","source":["# **Summary**"],"metadata":{"id":"d0mQaLJhT1Pz"}},{"cell_type":"markdown","source":["In this tutorial, you discovered a step-by-step guide to developing deep learning models in TensorFlow using the tf.keras API.\n","\n","Specifically, you learned:\n","\n","* The difference between Keras and tf.keras and how to install and confirm TensorFlow is working.\n","* The 5-step life-cycle of tf.keras models and how to use the sequential and functional APIs.\n","* How to develop MLP, CNN, and RNN models with tf.keras for regression, classification, and time series forecasting.\n","* How to use the advanced features of the tf.keras API to inspect and diagnose your model.\n","* How to improve the performance of your tf.keras model by reducing overfitting and accelerating training."],"metadata":{"id":"tu9E1LAqT4tq"}}]}